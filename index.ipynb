{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ba3e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:43:34.655239Z",
     "iopub.status.busy": "2024-06-02T00:43:34.654875Z",
     "iopub.status.idle": "2024-06-02T00:44:03.292903Z",
     "shell.execute_reply": "2024-06-02T00:44:03.291784Z"
    },
    "papermill": {
     "duration": 28.647143,
     "end_time": "2024-06-02T00:44:03.295594",
     "exception": false,
     "start_time": "2024-06-02T00:43:34.648451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\r\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\r\n",
      "\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: split-folders\r\n",
      "Successfully installed split-folders-0.5.1\r\n",
      "Requirement already satisfied: tensorflow==2.15.0 in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.59.3)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.0) (3.1.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed keras-2.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /kaggle/working/*\n",
    "\n",
    "!pip install split-folders\n",
    "!pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e87224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:03.310188Z",
     "iopub.status.busy": "2024-06-02T00:44:03.309853Z",
     "iopub.status.idle": "2024-06-02T00:44:15.942190Z",
     "shell.execute_reply": "2024-06-02T00:44:15.941214Z"
    },
    "id": "MMpVa0OcPGGj",
    "papermill": {
     "duration": 12.642053,
     "end_time": "2024-06-02T00:44:15.944256",
     "exception": false,
     "start_time": "2024-06-02T00:44:03.302203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 00:44:04.993565: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-02 00:44:04.993663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-02 00:44:05.112439: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "\n",
    "from typing import List\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e11773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:15.959011Z",
     "iopub.status.busy": "2024-06-02T00:44:15.958437Z",
     "iopub.status.idle": "2024-06-02T00:44:15.973395Z",
     "shell.execute_reply": "2024-06-02T00:44:15.972525Z"
    },
    "id": "n2c0Ur2eNIbH",
    "papermill": {
     "duration": 0.024372,
     "end_time": "2024-06-02T00:44:15.975385",
     "exception": false,
     "start_time": "2024-06-02T00:44:15.951013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430588ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:15.989376Z",
     "iopub.status.busy": "2024-06-02T00:44:15.989094Z",
     "iopub.status.idle": "2024-06-02T00:44:15.999778Z",
     "shell.execute_reply": "2024-06-02T00:44:15.998916Z"
    },
    "papermill": {
     "duration": 0.019902,
     "end_time": "2024-06-02T00:44:16.001791",
     "exception": false,
     "start_time": "2024-06-02T00:44:15.981889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_rmdir(folder):\n",
    "    for item in os.listdir(folder):\n",
    "        item_path = os.path.join(folder, item)\n",
    "        \n",
    "        if os.path.isdir(item_path):\n",
    "            recursive_rmdir(item_path)\n",
    "            os.rmdir(item_path)\n",
    "        else:\n",
    "            os.remove(item_path)\n",
    "            \n",
    "\n",
    "def organize_dataset(source_folder, destination_folder):    \n",
    "    if os.path.exists(destination_folder):\n",
    "        recursive_rmdir(destination_folder)\n",
    "    \n",
    "    # Discover all classes\n",
    "    classes = set()\n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        current_folder = os.path.join(source_folder, subfolder)\n",
    "        discovered_classes = os.listdir(current_folder)\n",
    "        classes = classes.union(discovered_classes)\n",
    "    classes = list(classes)\n",
    "    classes.sort()\n",
    "\n",
    "    # Create a folder for each class\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.mkdir(destination_folder)\n",
    "    \n",
    "    for _class in classes:\n",
    "        class_directory = os.path.join(destination_folder, _class)\n",
    "        os.mkdir(class_directory)\n",
    "    \n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        current_path = os.path.join(source_folder, subfolder)\n",
    "        for class_folder in os.listdir(current_path):\n",
    "            current_path = os.path.join(source_folder, subfolder, class_folder)\n",
    "            for file in os.listdir(current_path):\n",
    "                \n",
    "                file_source_path = os.path.join(\n",
    "                    source_folder,\n",
    "                    subfolder,\n",
    "                    class_folder,\n",
    "                    file\n",
    "                )\n",
    "                \n",
    "                file_destination_path = os.path.join(\n",
    "                    destination_folder,\n",
    "                    class_folder,\n",
    "                    file\n",
    "                )\n",
    "                \n",
    "                shutil.copy2(\n",
    "                    file_source_path,\n",
    "                    file_destination_path,\n",
    "                )\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adb1ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:16.015661Z",
     "iopub.status.busy": "2024-06-02T00:44:16.015392Z",
     "iopub.status.idle": "2024-06-02T00:44:16.020612Z",
     "shell.execute_reply": "2024-06-02T00:44:16.019787Z"
    },
    "id": "G3-UpbprWm2B",
    "papermill": {
     "duration": 0.014199,
     "end_time": "2024-06-02T00:44:16.022383",
     "exception": false,
     "start_time": "2024-06-02T00:44:16.008184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_validation_split(\n",
    "    source: str,\n",
    "    destination: str,\n",
    "    seed: int | None = None\n",
    "):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(999999)\n",
    "    print(f\"Dataset's split seed is {seed}\")\n",
    "\n",
    "    if not os.path.isdir(destination):\n",
    "        splitfolders.ratio(source, output=destination,\n",
    "            seed=seed, ratio=(.6, .2, .2), move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42209d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:16.036456Z",
     "iopub.status.busy": "2024-06-02T00:44:16.035929Z",
     "iopub.status.idle": "2024-06-02T00:44:16.042906Z",
     "shell.execute_reply": "2024-06-02T00:44:16.042053Z"
    },
    "id": "aNagWAB7IPwC",
    "papermill": {
     "duration": 0.016106,
     "end_time": "2024-06-02T00:44:16.044776",
     "exception": false,
     "start_time": "2024-06-02T00:44:16.028670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_history(history):\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(6, 4.4))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('loss')\n",
    "    ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6bebea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:16.058620Z",
     "iopub.status.busy": "2024-06-02T00:44:16.058364Z",
     "iopub.status.idle": "2024-06-02T00:44:16.063958Z",
     "shell.execute_reply": "2024-06-02T00:44:16.063076Z"
    },
    "id": "7Qo2uteJsmP4",
    "papermill": {
     "duration": 0.014613,
     "end_time": "2024-06-02T00:44:16.065877",
     "exception": false,
     "start_time": "2024-06-02T00:44:16.051264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_true_and_predicted_labels(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for X_batch, y_batch in dataset:\n",
    "        y_batch_pred = np.argmax(model.predict(X_batch, verbose=0), axis=1)\n",
    "        \n",
    "        y_true.append(y_batch)\n",
    "        y_pred.append(y_batch_pred)\n",
    "    \n",
    "    y_true = [y_batch.numpy() for y_batch in y_true]\n",
    "    \n",
    "    return np.concatenate(y_true), np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2bdb2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:44:16.079597Z",
     "iopub.status.busy": "2024-06-02T00:44:16.079346Z",
     "iopub.status.idle": "2024-06-02T00:45:23.317589Z",
     "shell.execute_reply": "2024-06-02T00:45:23.315597Z"
    },
    "id": "ZrBCEYY3kVeL",
    "outputId": "af100c6b-d715-41ad-c463-435d0aa1a173",
    "papermill": {
     "duration": 67.247497,
     "end_time": "2024-06-02T00:45:23.319677",
     "exception": false,
     "start_time": "2024-06-02T00:44:16.072180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's split seed is 892471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7132 files [00:02, 2934.97 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['COVID19', 'NORMAL', 'PNEUMONIA', 'TURBERCULOSIS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = organize_dataset(\n",
    "    os.path.join(\"/\", \"kaggle\", \"input\", \"chest-xray-pneumoniacovid19tuberculosis\"),\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"temp\"),\n",
    ")\n",
    "train_test_validation_split(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"temp\"),\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\"),\n",
    "    seed=892471\n",
    ")\n",
    "\n",
    "print(\"Found classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4287128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:45:23.344226Z",
     "iopub.status.busy": "2024-06-02T00:45:23.343310Z",
     "iopub.status.idle": "2024-06-02T00:45:26.183072Z",
     "shell.execute_reply": "2024-06-02T00:45:26.182008Z"
    },
    "papermill": {
     "duration": 2.85226,
     "end_time": "2024-06-02T00:45:26.185421",
     "exception": false,
     "start_time": "2024-06-02T00:45:23.333161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ TRAIN DATASET ]\n",
      "Found 4277 files belonging to 4 classes.\n",
      "\n",
      "[ VALIDATION DATASET ]\n",
      "Found 1425 files belonging to 4 classes.\n",
      "\n",
      "[ TEST DATASET ]\n",
      "Found 1430 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[ TRAIN DATASET ]\")\n",
    "train_dataset = train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"train\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(\"\\n[ VALIDATION DATASET ]\")\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"val\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(\"\\n[ TEST DATASET ]\")\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"test\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690741ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:45:26.228408Z",
     "iopub.status.busy": "2024-06-02T00:45:26.227857Z",
     "iopub.status.idle": "2024-06-02T00:45:29.218158Z",
     "shell.execute_reply": "2024-06-02T00:45:29.217387Z"
    },
    "papermill": {
     "duration": 3.026208,
     "end_time": "2024-06-02T00:45:29.220392",
     "exception": false,
     "start_time": "2024-06-02T00:45:26.194184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg_16 = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"max\",\n",
    ")\n",
    "\n",
    "for layer in vgg_16.layers:\n",
    "    layer.freeze = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000005, name=\"optimizer\")\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(name=\"loss\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    vgg_16,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\"),\n",
    "], name=\"model\")\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.build((None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a9443b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:45:29.244788Z",
     "iopub.status.busy": "2024-06-02T00:45:29.244494Z",
     "iopub.status.idle": "2024-06-02T00:45:29.249336Z",
     "shell.execute_reply": "2024-06-02T00:45:29.248476Z"
    },
    "papermill": {
     "duration": 0.019395,
     "end_time": "2024-06-02T00:45:29.251139",
     "exception": false,
     "start_time": "2024-06-02T00:45:29.231744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learning_rate_schedule(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return 0.000005\n",
    "    else:\n",
    "        return lr * 0.9 ** ((epoch - 50) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62dd6f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T00:45:29.275252Z",
     "iopub.status.busy": "2024-06-02T00:45:29.274960Z",
     "iopub.status.idle": "2024-06-02T10:49:09.565456Z",
     "shell.execute_reply": "2024-06-02T10:49:09.564677Z"
    },
    "id": "0nd5jsSFmE5J",
    "outputId": "b8a02719-59f6-4e2c-90cd-cbde47d69a46",
    "papermill": {
     "duration": 36220.305359,
     "end_time": "2024-06-02T10:49:09.567532",
     "exception": false,
     "start_time": "2024-06-02T00:45:29.262173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717289138.524295      88 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.8232\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93684, saving model to model.keras\n",
      "134/134 [==============================] - 62s 335ms/step - loss: 0.7927 - accuracy: 0.8232 - val_loss: 15.3844 - val_accuracy: 0.9368 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9467\n",
      "Epoch 2: val_accuracy improved from 0.93684 to 0.94737, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.2398 - accuracy: 0.9467 - val_loss: 11.8194 - val_accuracy: 0.9474 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2112 - accuracy: 0.9649\n",
      "Epoch 3: val_accuracy improved from 0.94737 to 0.95719, saving model to model.keras\n",
      "134/134 [==============================] - 37s 272ms/step - loss: 1.2112 - accuracy: 0.9649 - val_loss: 42.4352 - val_accuracy: 0.9572 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.9773\n",
      "Epoch 4: val_accuracy improved from 0.95719 to 0.96140, saving model to model.keras\n",
      "134/134 [==============================] - 38s 273ms/step - loss: 0.3860 - accuracy: 0.9773 - val_loss: 20.3219 - val_accuracy: 0.9614 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8242 - accuracy: 0.9804\n",
      "Epoch 5: val_accuracy did not improve from 0.96140\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.8242 - accuracy: 0.9804 - val_loss: 20.7693 - val_accuracy: 0.9558 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.9874\n",
      "Epoch 6: val_accuracy improved from 0.96140 to 0.96702, saving model to model.keras\n",
      "134/134 [==============================] - 38s 272ms/step - loss: 0.4143 - accuracy: 0.9874 - val_loss: 35.1609 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.9935\n",
      "Epoch 7: val_accuracy did not improve from 0.96702\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.4900 - accuracy: 0.9935 - val_loss: 29.2695 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.9944\n",
      "Epoch 8: val_accuracy did not improve from 0.96702\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.2882 - accuracy: 0.9944 - val_loss: 16.8918 - val_accuracy: 0.9628 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.9946\n",
      "Epoch 9: val_accuracy did not improve from 0.96702\n",
      "134/134 [==============================] - 35s 258ms/step - loss: 0.3486 - accuracy: 0.9946 - val_loss: 14.2437 - val_accuracy: 0.9467 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.9911\n",
      "Epoch 10: val_accuracy did not improve from 0.96702\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.4170 - accuracy: 0.9911 - val_loss: 23.7936 - val_accuracy: 0.9593 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.9949\n",
      "Epoch 11: val_accuracy improved from 0.96702 to 0.96912, saving model to model.keras\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.2829 - accuracy: 0.9949 - val_loss: 17.0999 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9977\n",
      "Epoch 12: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1450 - accuracy: 0.9977 - val_loss: 22.1833 - val_accuracy: 0.9600 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.9958\n",
      "Epoch 13: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.6518 - accuracy: 0.9958 - val_loss: 10.9187 - val_accuracy: 0.9684 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9981\n",
      "Epoch 14: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.2393 - accuracy: 0.9981 - val_loss: 29.0656 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9979\n",
      "Epoch 15: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 28.4392 - val_accuracy: 0.9607 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9963\n",
      "Epoch 16: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0385 - accuracy: 0.9963 - val_loss: 19.2635 - val_accuracy: 0.9684 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.9977\n",
      "Epoch 17: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.3503 - accuracy: 0.9977 - val_loss: 27.5141 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.9951\n",
      "Epoch 18: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.2826 - accuracy: 0.9951 - val_loss: 32.6994 - val_accuracy: 0.9628 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4652 - accuracy: 0.9984\n",
      "Epoch 19: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.4652 - accuracy: 0.9984 - val_loss: 19.9902 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.9979\n",
      "Epoch 20: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.3532 - accuracy: 0.9979 - val_loss: 20.3569 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9953\n",
      "Epoch 21: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1321 - accuracy: 0.9953 - val_loss: 26.2417 - val_accuracy: 0.9516 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.9918\n",
      "Epoch 22: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.3535 - accuracy: 0.9918 - val_loss: 31.1345 - val_accuracy: 0.9614 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.9970\n",
      "Epoch 23: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.3066 - accuracy: 0.9970 - val_loss: 37.8698 - val_accuracy: 0.9600 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.9974\n",
      "Epoch 24: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.3532 - accuracy: 0.9974 - val_loss: 15.0307 - val_accuracy: 0.9628 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9960\n",
      "Epoch 25: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.1350 - accuracy: 0.9960 - val_loss: 22.8525 - val_accuracy: 0.9621 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8341 - accuracy: 0.9806\n",
      "Epoch 26: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.8341 - accuracy: 0.9806 - val_loss: 18.2587 - val_accuracy: 0.9621 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.9885\n",
      "Epoch 27: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.6042 - accuracy: 0.9885 - val_loss: 8.0504 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4392 - accuracy: 0.9946\n",
      "Epoch 28: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.4392 - accuracy: 0.9946 - val_loss: 3.8110 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9981\n",
      "Epoch 29: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1711 - accuracy: 0.9981 - val_loss: 16.8324 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.9965\n",
      "Epoch 30: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.4968 - accuracy: 0.9965 - val_loss: 22.0436 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.9981\n",
      "Epoch 31: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.2778 - accuracy: 0.9981 - val_loss: 14.8014 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9984\n",
      "Epoch 32: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1063 - accuracy: 0.9984 - val_loss: 12.8715 - val_accuracy: 0.9684 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9984\n",
      "Epoch 33: val_accuracy improved from 0.96912 to 0.97193, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.0306 - accuracy: 0.9984 - val_loss: 4.1207 - val_accuracy: 0.9719 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9981    \n",
      "Epoch 34: val_accuracy improved from 0.97193 to 0.97263, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.1969 - accuracy: 0.9981 - val_loss: 9.9723 - val_accuracy: 0.9726 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9972    \n",
      "Epoch 35: val_accuracy did not improve from 0.97263\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.1925 - accuracy: 0.9972 - val_loss: 14.0104 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9981    \n",
      "Epoch 36: val_accuracy did not improve from 0.97263\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.2152 - accuracy: 0.9981 - val_loss: 22.3897 - val_accuracy: 0.9677 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9951\n",
      "Epoch 37: val_accuracy did not improve from 0.97263\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.2235 - accuracy: 0.9951 - val_loss: 12.5041 - val_accuracy: 0.9614 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2897 - accuracy: 0.9953\n",
      "Epoch 38: val_accuracy did not improve from 0.97263\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2897 - accuracy: 0.9953 - val_loss: 12.2261 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9981\n",
      "Epoch 39: val_accuracy did not improve from 0.97263\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.1463 - accuracy: 0.9981 - val_loss: 16.9790 - val_accuracy: 0.9719 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.9981    \n",
      "Epoch 40: val_accuracy did not improve from 0.97263\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.2806 - accuracy: 0.9981 - val_loss: 10.5154 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9977    \n",
      "Epoch 41: val_accuracy improved from 0.97263 to 0.97333, saving model to model.keras\n",
      "134/134 [==============================] - 37s 272ms/step - loss: 0.0883 - accuracy: 0.9977 - val_loss: 10.9238 - val_accuracy: 0.9733 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9937\n",
      "Epoch 42: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.2175 - accuracy: 0.9937 - val_loss: 7.1243 - val_accuracy: 0.9488 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9974\n",
      "Epoch 43: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0715 - accuracy: 0.9974 - val_loss: 10.2085 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9981    \n",
      "Epoch 44: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.2164 - accuracy: 0.9981 - val_loss: 12.5548 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9970    \n",
      "Epoch 45: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1677 - accuracy: 0.9970 - val_loss: 21.4469 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9977\n",
      "Epoch 46: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.1699 - accuracy: 0.9977 - val_loss: 16.2469 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9967\n",
      "Epoch 47: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1221 - accuracy: 0.9967 - val_loss: 14.9377 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.9974    \n",
      "Epoch 48: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.5582 - accuracy: 0.9974 - val_loss: 20.1940 - val_accuracy: 0.9614 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.9974    \n",
      "Epoch 49: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.1240 - accuracy: 0.9974 - val_loss: 17.0647 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9991    \n",
      "Epoch 50: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.1187 - accuracy: 0.9991 - val_loss: 11.9874 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 4.999999873689376e-06.\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9988    \n",
      "Epoch 51: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0192 - accuracy: 0.9988 - val_loss: 24.2573 - val_accuracy: 0.9565 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 4.947596166044277e-06.\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9925\n",
      "Epoch 52: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1055 - accuracy: 0.9925 - val_loss: 17.3418 - val_accuracy: 0.9116 - lr: 4.9476e-06\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 4.844430671044202e-06.\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9902\n",
      "Epoch 53: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.2339 - accuracy: 0.9902 - val_loss: 7.6856 - val_accuracy: 0.9670 - lr: 4.8444e-06\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 4.693701965794856e-06.\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9965\n",
      "Epoch 54: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.1279 - accuracy: 0.9965 - val_loss: 10.4473 - val_accuracy: 0.9670 - lr: 4.6937e-06\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 4.500000096082007e-06.\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.9979    \n",
      "Epoch 55: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.4056 - accuracy: 0.9979 - val_loss: 11.0684 - val_accuracy: 0.9712 - lr: 4.5000e-06\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 4.26907499222814e-06.\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9981    \n",
      "Epoch 56: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1135 - accuracy: 0.9981 - val_loss: 13.4215 - val_accuracy: 0.9656 - lr: 4.2691e-06\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 4.007553057399035e-06.\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9981    \n",
      "Epoch 57: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0839 - accuracy: 0.9981 - val_loss: 13.4023 - val_accuracy: 0.9712 - lr: 4.0076e-06\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 3.7226226818326107e-06.\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9970    \n",
      "Epoch 58: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.1642 - accuracy: 0.9970 - val_loss: 17.2180 - val_accuracy: 0.9663 - lr: 3.7226e-06\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 3.421708705484507e-06.\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9979    \n",
      "Epoch 59: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0733 - accuracy: 0.9979 - val_loss: 7.4658 - val_accuracy: 0.9705 - lr: 3.4217e-06\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 3.112155526438271e-06.\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9984    \n",
      "Epoch 60: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0565 - accuracy: 0.9984 - val_loss: 6.1501 - val_accuracy: 0.9684 - lr: 3.1122e-06\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 2.8009400239170645e-06.\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9993    \n",
      "Epoch 61: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 13.3845 - val_accuracy: 0.9691 - lr: 2.8009e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 2.4944255840260753e-06.\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9991    \n",
      "Epoch 62: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0262 - accuracy: 0.9991 - val_loss: 9.7592 - val_accuracy: 0.9684 - lr: 2.4944e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 2.1981715057576365e-06.\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 63: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 14.6638 - val_accuracy: 0.9684 - lr: 2.1982e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.916800251511142e-06.\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9988    \n",
      "Epoch 64: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 17.9172 - val_accuracy: 0.9663 - lr: 1.9168e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.6539271960338116e-06.\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9988    \n",
      "Epoch 65: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0336 - accuracy: 0.9988 - val_loss: 18.4285 - val_accuracy: 0.9656 - lr: 1.6539e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.4121477509078099e-06.\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9993    \n",
      "Epoch 66: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0179 - accuracy: 0.9993 - val_loss: 12.6581 - val_accuracy: 0.9663 - lr: 1.4121e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.1930761237568825e-06.\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9993    \n",
      "Epoch 67: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0127 - accuracy: 0.9993 - val_loss: 9.9860 - val_accuracy: 0.9663 - lr: 1.1931e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 9.974254342835336e-07.\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9995    \n",
      "Epoch 68: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 13.2402 - val_accuracy: 0.9705 - lr: 9.9743e-07\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 8.251197078897755e-07.\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9993    \n",
      "Epoch 69: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0118 - accuracy: 0.9993 - val_loss: 12.4052 - val_accuracy: 0.9691 - lr: 8.2512e-07\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 6.754259090616104e-07.\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.1070e-04 - accuracy: 0.9998\n",
      "Epoch 70: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 4.1070e-04 - accuracy: 0.9998 - val_loss: 14.0496 - val_accuracy: 0.9684 - lr: 6.7543e-07\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 5.470949747632403e-07.\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998    \n",
      "Epoch 71: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 15.4124 - val_accuracy: 0.9691 - lr: 5.4709e-07\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.3850244014826917e-07.\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9998    \n",
      "Epoch 72: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0109 - accuracy: 0.9998 - val_loss: 10.9720 - val_accuracy: 0.9712 - lr: 4.3850e-07\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.4778074603009097e-07.\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9991    \n",
      "Epoch 73: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0216 - accuracy: 0.9991 - val_loss: 6.8830 - val_accuracy: 0.9670 - lr: 3.4778e-07\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 2.7293755721371593e-07.\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9993    \n",
      "Epoch 74: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 4.7624 - val_accuracy: 0.9705 - lr: 2.7294e-07\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 2.1195581816349607e-07.\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9998    \n",
      "Epoch 75: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 20.5586 - val_accuracy: 0.9656 - lr: 2.1196e-07\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.6287394792042573e-07.\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9995    \n",
      "Epoch 76: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 16.4784 - val_accuracy: 0.9684 - lr: 1.6287e-07\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.2384604480575998e-07.\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9993    \n",
      "Epoch 77: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 8.7851 - val_accuracy: 0.9656 - lr: 1.2385e-07\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 9.31830528327964e-08.\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.0382e-04 - accuracy: 0.9998\n",
      "Epoch 78: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 3.0382e-04 - accuracy: 0.9998 - val_loss: 22.9800 - val_accuracy: 0.9649 - lr: 9.3183e-08\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 6.937707205075805e-08.\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995    \n",
      "Epoch 79: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 16.1277 - val_accuracy: 0.9663 - lr: 6.9377e-08\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 5.111157340256211e-08.\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 80: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 16.9424 - val_accuracy: 0.9663 - lr: 5.1112e-08\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 3.7260337183653296e-08.\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 81: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 16.5267 - val_accuracy: 0.9656 - lr: 3.7260e-08\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 2.6878100838759215e-08.\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5132e-04 - accuracy: 1.0000\n",
      "Epoch 82: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 2.5132e-04 - accuracy: 1.0000 - val_loss: 7.3679 - val_accuracy: 0.9684 - lr: 2.6878e-08\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.918556618579084e-08.\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9993    \n",
      "Epoch 83: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 16.6232 - val_accuracy: 0.9656 - lr: 1.9186e-08\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.3551111471692345e-08.\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9991    \n",
      "Epoch 84: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 8.6925 - val_accuracy: 0.9663 - lr: 1.3551e-08\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 9.471078709079978e-09.\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9995    \n",
      "Epoch 85: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 12.9414 - val_accuracy: 0.9670 - lr: 9.4711e-09\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 6.550104724901145e-09.\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9995    \n",
      "Epoch 86: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 10.8814 - val_accuracy: 0.9698 - lr: 6.5501e-09\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 4.482510230715509e-09.\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9998    \n",
      "Epoch 87: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 10.6203 - val_accuracy: 0.9677 - lr: 4.4825e-09\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 3.035418573280629e-09.\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9988    \n",
      "Epoch 88: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0255 - accuracy: 0.9988 - val_loss: 10.9546 - val_accuracy: 0.9663 - lr: 3.0354e-09\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 2.0339493063179747e-09.\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9988    \n",
      "Epoch 89: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 40s 287ms/step - loss: 0.0250 - accuracy: 0.9988 - val_loss: 17.5571 - val_accuracy: 0.9663 - lr: 2.0339e-09\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.3486085081858986e-09.\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9993    \n",
      "Epoch 90: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 17.1983 - val_accuracy: 0.9656 - lr: 1.3486e-09\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 8.848220750090619e-10.\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 91: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 10.0380 - val_accuracy: 0.9656 - lr: 8.8482e-10\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.744473429884498e-10.\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 92: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 16.8148 - val_accuracy: 0.9656 - lr: 5.7445e-10\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 3.690360130023517e-10.\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2553e-04 - accuracy: 1.0000\n",
      "Epoch 93: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.2553e-04 - accuracy: 1.0000 - val_loss: 10.9001 - val_accuracy: 0.9670 - lr: 3.6904e-10\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 2.345911115590694e-10.\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9993    \n",
      "Epoch 94: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 14.9455 - val_accuracy: 0.9670 - lr: 2.3459e-10\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.4756338809980254e-10.\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 95: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 6.1912 - val_accuracy: 0.9691 - lr: 1.4756e-10\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 9.184804618910129e-11.\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995    \n",
      "Epoch 96: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 10.0826 - val_accuracy: 0.9635 - lr: 9.1848e-11\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 5.656990520171663e-11.\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9988    \n",
      "Epoch 97: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0139 - accuracy: 0.9988 - val_loss: 15.3073 - val_accuracy: 0.9663 - lr: 5.6570e-11\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.447666459420204e-11.\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5313e-04 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.5313e-04 - accuracy: 1.0000 - val_loss: 12.0369 - val_accuracy: 0.9663 - lr: 3.4477e-11\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.0791665951459024e-11.\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9993    \n",
      "Epoch 99: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 12.9926 - val_accuracy: 0.9677 - lr: 2.0792e-11\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.240730821578518e-11.\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993    \n",
      "Epoch 100: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 22.9174 - val_accuracy: 0.9642 - lr: 1.2407e-11\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 7.326391194655003e-12.\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 101: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 10.3184 - val_accuracy: 0.9670 - lr: 7.3264e-12\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 4.2808193834293864e-12.\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9993    \n",
      "Epoch 102: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 17.8959 - val_accuracy: 0.9649 - lr: 4.2808e-12\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 2.475072550910836e-12.\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9993    \n",
      "Epoch 103: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0138 - accuracy: 0.9993 - val_loss: 16.2742 - val_accuracy: 0.9656 - lr: 2.4751e-12\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 1.4160324819787112e-12.\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998    \n",
      "Epoch 104: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 14.9394 - val_accuracy: 0.9649 - lr: 1.4160e-12\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 8.016462279363985e-13.\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9991    \n",
      "Epoch 105: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 14.6903 - val_accuracy: 0.9656 - lr: 8.0165e-13\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 4.4907260360904133e-13.\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995    \n",
      "Epoch 106: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 10.3501 - val_accuracy: 0.9670 - lr: 4.4907e-13\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 2.489284986069152e-13.\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9993    \n",
      "Epoch 107: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 14.2678 - val_accuracy: 0.9670 - lr: 2.4893e-13\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.3653907043179118e-13.\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9995    \n",
      "Epoch 108: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 19.3631 - val_accuracy: 0.9635 - lr: 1.3654e-13\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 7.410772648433909e-14.\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9993    \n",
      "Epoch 109: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 14.5611 - val_accuracy: 0.9649 - lr: 7.4108e-14\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 3.9801028156641904e-14.\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3343e-04 - accuracy: 1.0000\n",
      "Epoch 110: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.3343e-04 - accuracy: 1.0000 - val_loss: 14.2738 - val_accuracy: 0.9677 - lr: 3.9801e-14\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 2.115189805259281e-14.\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9991    \n",
      "Epoch 111: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 10.5145 - val_accuracy: 0.9642 - lr: 2.1152e-14\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.1123172159499923e-14.\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9998    \n",
      "Epoch 112: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 17.7325 - val_accuracy: 0.9642 - lr: 1.1123e-14\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 5.788049314340766e-15.\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9995    \n",
      "Epoch 113: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 7.4669 - val_accuracy: 0.9684 - lr: 5.7880e-15\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 2.98030032947925e-15.\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9993    \n",
      "Epoch 114: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 13.5011 - val_accuracy: 0.9656 - lr: 2.9803e-15\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.5184905004266115e-15.\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9998    \n",
      "Epoch 115: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0124 - accuracy: 0.9998 - val_loss: 18.5590 - val_accuracy: 0.9649 - lr: 1.5185e-15\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 7.655761263684274e-16.\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.4901e-04 - accuracy: 0.9998\n",
      "Epoch 116: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 9.4901e-04 - accuracy: 0.9998 - val_loss: 14.5650 - val_accuracy: 0.9677 - lr: 7.6558e-16\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 3.8193454377530577e-16.\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9991    \n",
      "Epoch 117: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0233 - accuracy: 0.9991 - val_loss: 22.7446 - val_accuracy: 0.9628 - lr: 3.8193e-16\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.8854444853514813e-16.\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9995    \n",
      "Epoch 118: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 11.1977 - val_accuracy: 0.9670 - lr: 1.8854e-16\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 9.210067677581277e-17.\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993    \n",
      "Epoch 119: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 13.3569 - val_accuracy: 0.9663 - lr: 9.2101e-17\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 4.4518051117358425e-17.\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9986    \n",
      "Epoch 120: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0152 - accuracy: 0.9986 - val_loss: 12.4624 - val_accuracy: 0.9663 - lr: 4.4518e-17\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 2.1292845275852942e-17.\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9993    \n",
      "Epoch 121: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 14.8151 - val_accuracy: 0.9677 - lr: 2.1293e-17\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 1.0077562682004318e-17.\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9995    \n",
      "Epoch 122: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 9.5454 - val_accuracy: 0.9670 - lr: 1.0078e-17\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 4.719560806588151e-18.\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9998    \n",
      "Epoch 123: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0129 - accuracy: 0.9998 - val_loss: 12.6247 - val_accuracy: 0.9656 - lr: 4.7196e-18\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 2.1871164706599007e-18.\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 124: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 10.1635 - val_accuracy: 0.9670 - lr: 2.1871e-18\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 1.002920409234956e-18.\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9993    \n",
      "Epoch 125: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 11.3589 - val_accuracy: 0.9670 - lr: 1.0029e-18\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 4.550774218604091e-19.\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9991    \n",
      "Epoch 126: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 17.7411 - val_accuracy: 0.9642 - lr: 4.5508e-19\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 2.0432823533956509e-19.\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9988    \n",
      "Epoch 127: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 14.0652 - val_accuracy: 0.9670 - lr: 2.0433e-19\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 9.078115287602825e-20.\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9991    \n",
      "Epoch 128: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0116 - accuracy: 0.9991 - val_loss: 13.9467 - val_accuracy: 0.9656 - lr: 9.0781e-20\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 3.99105090873059e-20.\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9986    \n",
      "Epoch 129: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0182 - accuracy: 0.9986 - val_loss: 24.0377 - val_accuracy: 0.9649 - lr: 3.9911e-20\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 1.736213311778248e-20.\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993    \n",
      "Epoch 130: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 21.7448 - val_accuracy: 0.9628 - lr: 1.7362e-20\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 7.473829088434484e-21.\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995    \n",
      "Epoch 131: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 12.6499 - val_accuracy: 0.9656 - lr: 7.4738e-21\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 3.183519216476752e-21.\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9991    \n",
      "Epoch 132: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 10.8994 - val_accuracy: 0.9691 - lr: 3.1835e-21\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 1.3418255703509664e-21.\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995    \n",
      "Epoch 133: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 9.0220 - val_accuracy: 0.9670 - lr: 1.3418e-21\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 5.596401943977592e-22.\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995    \n",
      "Epoch 134: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 11.2105 - val_accuracy: 0.9649 - lr: 5.5964e-22\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 2.3096489507098775e-22.\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9995    \n",
      "Epoch 135: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 9.7105 - val_accuracy: 0.9677 - lr: 2.3096e-22\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 9.432076183047891e-23.\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9991    \n",
      "Epoch 136: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0186 - accuracy: 0.9991 - val_loss: 14.0900 - val_accuracy: 0.9670 - lr: 9.4321e-23\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 3.811473218745875e-23.\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9995    \n",
      "Epoch 137: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 11.1165 - val_accuracy: 0.9663 - lr: 3.8115e-23\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 1.5240622725267754e-23.\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9993    \n",
      "Epoch 138: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0148 - accuracy: 0.9993 - val_loss: 12.2531 - val_accuracy: 0.9656 - lr: 1.5241e-23\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 6.030270354456519e-24.\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9995    \n",
      "Epoch 139: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 17.3747 - val_accuracy: 0.9663 - lr: 6.0303e-24\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 2.360995322498613e-24.\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9993    \n",
      "Epoch 140: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 11.0511 - val_accuracy: 0.9663 - lr: 2.3610e-24\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 9.146979966899196e-25.\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 141: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 6.6788 - val_accuracy: 0.9677 - lr: 9.1470e-25\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 3.506586666503935e-25.\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9993    \n",
      "Epoch 142: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0148 - accuracy: 0.9993 - val_loss: 16.9279 - val_accuracy: 0.9656 - lr: 3.5066e-25\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 1.330196041956612e-25.\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9991    \n",
      "Epoch 143: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 7.0576 - val_accuracy: 0.9670 - lr: 1.3302e-25\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 4.993108154627039e-26.\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9995    \n",
      "Epoch 144: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0144 - accuracy: 0.9995 - val_loss: 9.8921 - val_accuracy: 0.9670 - lr: 4.9931e-26\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 1.8546012673970866e-26.\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9995    \n",
      "Epoch 145: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 17.5867 - val_accuracy: 0.9670 - lr: 1.8546e-26\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 6.816389155231588e-27.\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9991    \n",
      "Epoch 146: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0124 - accuracy: 0.9991 - val_loss: 3.2095 - val_accuracy: 0.9684 - lr: 6.8164e-27\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 2.4790339104165582e-27.\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9993    \n",
      "Epoch 147: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0176 - accuracy: 0.9993 - val_loss: 8.5039 - val_accuracy: 0.9684 - lr: 2.4790e-27\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 8.921436928781615e-28.\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 148: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 14.4874 - val_accuracy: 0.9656 - lr: 8.9214e-28\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 3.1769575506734115e-28.\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9993    \n",
      "Epoch 149: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 260ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 15.8829 - val_accuracy: 0.9663 - lr: 3.1770e-28\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 1.1194694423091733e-28.\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9993    \n",
      "Epoch 150: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 10.6800 - val_accuracy: 0.9677 - lr: 1.1195e-28\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 3.903348475668377e-29.\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 151: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 8.7354 - val_accuracy: 0.9691 - lr: 3.9033e-29\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 1.3467490085636054e-29.\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998    \n",
      "Epoch 152: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 15.5076 - val_accuracy: 0.9649 - lr: 1.3467e-29\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 4.597907606887486e-30.\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9991    \n",
      "Epoch 153: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0160 - accuracy: 0.9991 - val_loss: 16.9411 - val_accuracy: 0.9635 - lr: 4.5979e-30\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 1.5533098145745834e-30.\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9988    \n",
      "Epoch 154: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0100 - accuracy: 0.9988 - val_loss: 11.4576 - val_accuracy: 0.9663 - lr: 1.5533e-30\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 5.192543948667743e-31.\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9991    \n",
      "Epoch 155: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 6.5133 - val_accuracy: 0.9670 - lr: 5.1925e-31\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 1.7176178453296102e-31.\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9993    \n",
      "Epoch 156: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 16.2876 - val_accuracy: 0.9649 - lr: 1.7176e-31\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 5.622081721547939e-32.\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9993    \n",
      "Epoch 157: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0127 - accuracy: 0.9993 - val_loss: 14.1173 - val_accuracy: 0.9677 - lr: 5.6221e-32\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 1.820924704659582e-32.\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9991    \n",
      "Epoch 158: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 20.9002 - val_accuracy: 0.9649 - lr: 1.8209e-32\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 5.835943478250069e-33.\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.2796e-04 - accuracy: 0.9998\n",
      "Epoch 159: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 8.2796e-04 - accuracy: 0.9998 - val_loss: 16.0990 - val_accuracy: 0.9663 - lr: 5.8359e-33\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 1.8507783999108795e-33.\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9993    \n",
      "Epoch 160: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 12.3647 - val_accuracy: 0.9663 - lr: 1.8508e-33\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 5.807938686940553e-34.\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9988    \n",
      "Epoch 161: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0326 - accuracy: 0.9988 - val_loss: 17.0506 - val_accuracy: 0.9670 - lr: 5.8079e-34\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 1.8034905224001128e-34.\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9986    \n",
      "Epoch 162: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0238 - accuracy: 0.9986 - val_loss: 19.9771 - val_accuracy: 0.9628 - lr: 1.8035e-34\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 5.541533517848434e-35.\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998    \n",
      "Epoch 163: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 17.3297 - val_accuracy: 0.9635 - lr: 5.5415e-35\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 1.6848852136446157e-35.\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9993    \n",
      "Epoch 164: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 16.3113 - val_accuracy: 0.9635 - lr: 1.6849e-35\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 5.069147393636971e-36.\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9995    \n",
      "Epoch 165: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 16.2735 - val_accuracy: 0.9670 - lr: 5.0691e-36\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 1.5091200585929946e-36.\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9995    \n",
      "Epoch 166: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 21.7776 - val_accuracy: 0.9642 - lr: 1.5091e-36\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 4.445666463178443e-37.\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9995    \n",
      "Epoch 167: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 17.9041 - val_accuracy: 0.9663 - lr: 4.4457e-37\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 1.295908262223595e-37.\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995    \n",
      "Epoch 168: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 8.9630 - val_accuracy: 0.9670 - lr: 1.2959e-37\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 3.7379705103101083e-38.\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9995    \n",
      "Epoch 169: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 13.2161 - val_accuracy: 0.9670 - lr: 3.7380e-38\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 1.0668950937506675e-38.\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 170: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 14.1645 - val_accuracy: 0.9677 - lr: 1.0669e-38\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 3.013226945361619e-39.\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9998    \n",
      "Epoch 171: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 5.7112 - val_accuracy: 0.9684 - lr: 3.0132e-39\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 8.421050792493317e-40.\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 172: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 19.5065 - val_accuracy: 0.9670 - lr: 8.4210e-40\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 2.328759877651186e-40.\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4797e-04 - accuracy: 1.0000\n",
      "Epoch 173: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.4797e-04 - accuracy: 1.0000 - val_loss: 11.0782 - val_accuracy: 0.9663 - lr: 2.3288e-40\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 6.372472161537501e-41.\n",
      "Epoch 174/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9991    \n",
      "Epoch 174: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0150 - accuracy: 0.9991 - val_loss: 13.3369 - val_accuracy: 0.9670 - lr: 6.3724e-41\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 1.7254821497903062e-41.\n",
      "Epoch 175/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9991    \n",
      "Epoch 175: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0232 - accuracy: 0.9991 - val_loss: 12.2525 - val_accuracy: 0.9670 - lr: 1.7254e-41\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 4.623021290730115e-42.\n",
      "Epoch 176/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9995    \n",
      "Epoch 176: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 16.5622 - val_accuracy: 0.9642 - lr: 4.6229e-42\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 1.2256559575821134e-42.\n",
      "Epoch 177/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4748e-04 - accuracy: 1.0000\n",
      "Epoch 177: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.4748e-04 - accuracy: 1.0000 - val_loss: 8.3291 - val_accuracy: 0.9663 - lr: 1.2261e-42\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 3.2167593277276306e-43.\n",
      "Epoch 178/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 178: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 21.3970 - val_accuracy: 0.9656 - lr: 3.2230e-43\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 8.366861941419681e-44.\n",
      "Epoch 179/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9988    \n",
      "Epoch 179: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 17.8202 - val_accuracy: 0.9663 - lr: 8.4078e-44\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 2.1597837448141065e-44.\n",
      "Epoch 180/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993    \n",
      "Epoch 180: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 20.2222 - val_accuracy: 0.9649 - lr: 2.1019e-44\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 5.342869022635737e-45.\n",
      "Epoch 181/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9991    \n",
      "Epoch 181: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0160 - accuracy: 0.9991 - val_loss: 17.8275 - val_accuracy: 0.9656 - lr: 5.6052e-45\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 1.4098324778590603e-45.\n",
      "Epoch 182/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9995    \n",
      "Epoch 182: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 15.9385 - val_accuracy: 0.9670 - lr: 1.4013e-45\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 3.4876409692153165e-46.\n",
      "Epoch 183/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9995    \n",
      "Epoch 183: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0096 - accuracy: 0.9995 - val_loss: 29.0266 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 184/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9988    \n",
      "Epoch 184: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0111 - accuracy: 0.9988 - val_loss: 22.1598 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 185/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9995    \n",
      "Epoch 185: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 10.6609 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 186/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9995    \n",
      "Epoch 186: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 20.7505 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 187/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9993    \n",
      "Epoch 187: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 261ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 16.7273 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 188/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9991    \n",
      "Epoch 188: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0154 - accuracy: 0.9991 - val_loss: 12.2938 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 189/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9993    \n",
      "Epoch 189: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0248 - accuracy: 0.9993 - val_loss: 10.2340 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 190/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9991    \n",
      "Epoch 190: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 10.7527 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 191/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5540e-04 - accuracy: 1.0000\n",
      "Epoch 191: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.5540e-04 - accuracy: 1.0000 - val_loss: 17.1609 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 192/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993    \n",
      "Epoch 192: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 23.4361 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 193/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998    \n",
      "Epoch 193: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 11.3551 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 194/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9998    \n",
      "Epoch 194: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 13.2325 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 195/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993    \n",
      "Epoch 195: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 12.2411 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 196/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9991    \n",
      "Epoch 196: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 16.9147 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 197/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9993    \n",
      "Epoch 197: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 13.4600 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 198/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9991    \n",
      "Epoch 198: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0212 - accuracy: 0.9991 - val_loss: 13.6427 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 199/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998    \n",
      "Epoch 199: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 7.6312 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 200/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995    \n",
      "Epoch 200: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 16.6530 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 201/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9988    \n",
      "Epoch 201: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0148 - accuracy: 0.9988 - val_loss: 14.4785 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 202/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 202: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 12.0990 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 203/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9993    \n",
      "Epoch 203: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0228 - accuracy: 0.9993 - val_loss: 19.9409 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 204/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9993    \n",
      "Epoch 204: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 18.0018 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 205/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9995    \n",
      "Epoch 205: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 15.1496 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 206/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9986    \n",
      "Epoch 206: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0132 - accuracy: 0.9986 - val_loss: 10.7831 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 207/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993    \n",
      "Epoch 207: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 17.1701 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 208/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9993    \n",
      "Epoch 208: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0191 - accuracy: 0.9993 - val_loss: 20.1537 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 209/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 209: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 8.9589 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 210/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9991    \n",
      "Epoch 210: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0129 - accuracy: 0.9991 - val_loss: 18.7798 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 211/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9028e-04 - accuracy: 1.0000\n",
      "Epoch 211: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.9028e-04 - accuracy: 1.0000 - val_loss: 23.6190 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 212/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9988    \n",
      "Epoch 212: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0120 - accuracy: 0.9988 - val_loss: 11.9991 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 213/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993    \n",
      "Epoch 213: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 15.7146 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 214/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9998    \n",
      "Epoch 214: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0091 - accuracy: 0.9998 - val_loss: 13.9721 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 215/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1272e-04 - accuracy: 1.0000\n",
      "Epoch 215: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.1272e-04 - accuracy: 1.0000 - val_loss: 13.9850 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 216/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 216: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 11.7720 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 217/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9988    \n",
      "Epoch 217: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 261ms/step - loss: 0.0120 - accuracy: 0.9988 - val_loss: 17.0749 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 218/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995    \n",
      "Epoch 218: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 15.4235 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 219/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995    \n",
      "Epoch 219: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 9.4015 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 220/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991    \n",
      "Epoch 220: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 9.4140 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 221/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9993    \n",
      "Epoch 221: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 27.6575 - val_accuracy: 0.9628 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 222/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9995    \n",
      "Epoch 222: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 13.1985 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 223/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995    \n",
      "Epoch 223: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 23.4043 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 224/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993    \n",
      "Epoch 224: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 11.1188 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 225/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9986    \n",
      "Epoch 225: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0291 - accuracy: 0.9986 - val_loss: 14.2428 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 226/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9993    \n",
      "Epoch 226: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0116 - accuracy: 0.9993 - val_loss: 12.8243 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 227/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9995    \n",
      "Epoch 227: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 7.7750 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 228/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995    \n",
      "Epoch 228: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 19.3692 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 229/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9998    \n",
      "Epoch 229: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 12.5445 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 230/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993    \n",
      "Epoch 230: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 10.4024 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 231/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9986    \n",
      "Epoch 231: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0249 - accuracy: 0.9986 - val_loss: 13.7034 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 232/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.9427e-04 - accuracy: 0.9995\n",
      "Epoch 232: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 7.9427e-04 - accuracy: 0.9995 - val_loss: 11.6184 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 233/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4585e-04 - accuracy: 1.0000\n",
      "Epoch 233: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.4585e-04 - accuracy: 1.0000 - val_loss: 15.5217 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 234/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9991    \n",
      "Epoch 234: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 19.4163 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 235/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 235: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 23.7100 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 236/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9986    \n",
      "Epoch 236: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0148 - accuracy: 0.9986 - val_loss: 7.7710 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 237/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9991    \n",
      "Epoch 237: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0215 - accuracy: 0.9991 - val_loss: 15.7479 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 238/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3000e-04 - accuracy: 1.0000\n",
      "Epoch 238: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.3000e-04 - accuracy: 1.0000 - val_loss: 7.7189 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 239/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9991    \n",
      "Epoch 239: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 18.1504 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 240/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9995    \n",
      "Epoch 240: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 13.3595 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 241/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.9298e-04 - accuracy: 0.9998\n",
      "Epoch 241: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 3.9298e-04 - accuracy: 0.9998 - val_loss: 11.6418 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 242/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9993    \n",
      "Epoch 242: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0100 - accuracy: 0.9993 - val_loss: 9.7841 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 243/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9993    \n",
      "Epoch 243: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 9.8046 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 244/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993    \n",
      "Epoch 244: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 15.5918 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 245/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9984    \n",
      "Epoch 245: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0277 - accuracy: 0.9984 - val_loss: 7.3473 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 246/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9993    \n",
      "Epoch 246: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 22.7976 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 247/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9993    \n",
      "Epoch 247: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 9.1585 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 248/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9995    \n",
      "Epoch 248: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 9.4357 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 249/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 249: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 19.9241 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 250/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.7157e-04 - accuracy: 1.0000\n",
      "Epoch 250: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.7157e-04 - accuracy: 1.0000 - val_loss: 17.7588 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 251/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9993    \n",
      "Epoch 251: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 16.0368 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 252/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995    \n",
      "Epoch 252: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 6.6308 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 253/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1477e-04 - accuracy: 1.0000\n",
      "Epoch 253: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1477e-04 - accuracy: 1.0000 - val_loss: 8.3038 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 254/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995    \n",
      "Epoch 254: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 14.6389 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 255/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9991    \n",
      "Epoch 255: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0116 - accuracy: 0.9991 - val_loss: 12.9059 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 256/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9995    \n",
      "Epoch 256: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 14.1111 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 257/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9995    \n",
      "Epoch 257: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 13.1474 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 258/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9991    \n",
      "Epoch 258: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 21.8852 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 259/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9991    \n",
      "Epoch 259: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0220 - accuracy: 0.9991 - val_loss: 5.1733 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 260/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995    \n",
      "Epoch 260: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 13.4268 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 261/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993    \n",
      "Epoch 261: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 14.2443 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 262/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9993    \n",
      "Epoch 262: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0136 - accuracy: 0.9993 - val_loss: 14.0689 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 263/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995    \n",
      "Epoch 263: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 18.8275 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 264/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9984    \n",
      "Epoch 264: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0199 - accuracy: 0.9984 - val_loss: 14.7400 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 265/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9991    \n",
      "Epoch 265: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 11.3691 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 266/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993    \n",
      "Epoch 266: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 14.1057 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 267/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9991    \n",
      "Epoch 267: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0243 - accuracy: 0.9991 - val_loss: 16.6966 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 268/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9993    \n",
      "Epoch 268: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 12.2100 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 269/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9988    \n",
      "Epoch 269: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0128 - accuracy: 0.9988 - val_loss: 10.5729 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 270/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995    \n",
      "Epoch 270: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 8.2742 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 271/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 271: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 12.0005 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 272/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995    \n",
      "Epoch 272: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 16.3902 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 273/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9986    \n",
      "Epoch 273: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0220 - accuracy: 0.9986 - val_loss: 12.6823 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 274/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9991    \n",
      "Epoch 274: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0200 - accuracy: 0.9991 - val_loss: 2.6627 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 275/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1213e-04 - accuracy: 1.0000\n",
      "Epoch 275: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.1213e-04 - accuracy: 1.0000 - val_loss: 9.0034 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 276/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9044e-04 - accuracy: 1.0000\n",
      "Epoch 276: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.9044e-04 - accuracy: 1.0000 - val_loss: 18.7497 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 277/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9986    \n",
      "Epoch 277: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 11.1895 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 278/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9991    \n",
      "Epoch 278: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0152 - accuracy: 0.9991 - val_loss: 16.1221 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 279/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9991    \n",
      "Epoch 279: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0178 - accuracy: 0.9991 - val_loss: 15.3380 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 280/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9991    \n",
      "Epoch 280: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 17.7039 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 281/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9988    \n",
      "Epoch 281: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 16.4006 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 282/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3028e-04 - accuracy: 1.0000\n",
      "Epoch 282: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.3028e-04 - accuracy: 1.0000 - val_loss: 10.9226 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 283/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995    \n",
      "Epoch 283: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 12.7569 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 284/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 284: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 17.0510 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 285/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9993    \n",
      "Epoch 285: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 11.8367 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 286/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9984    \n",
      "Epoch 286: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0149 - accuracy: 0.9984 - val_loss: 9.7619 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 287/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 287: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 14.3784 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 288/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9995    \n",
      "Epoch 288: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 11.2866 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 289/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9988    \n",
      "Epoch 289: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 14.4107 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 290/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993    \n",
      "Epoch 290: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 8.6098 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 291/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9998    \n",
      "Epoch 291: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 24.2075 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 292/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993    \n",
      "Epoch 292: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 19.9480 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 293/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995    \n",
      "Epoch 293: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 6.2459 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 294/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995    \n",
      "Epoch 294: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 22.3564 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 295/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9991    \n",
      "Epoch 295: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 13.2544 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 296/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998    \n",
      "Epoch 296: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 9.8051 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 297/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9995    \n",
      "Epoch 297: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 17.8261 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 298/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9988    \n",
      "Epoch 298: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 13.2113 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 299/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9993    \n",
      "Epoch 299: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 10.5442 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 300/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9993    \n",
      "Epoch 300: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 6.7826 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 301: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 301/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9993    \n",
      "Epoch 301: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 13.5763 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 302: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 302/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1325e-04 - accuracy: 1.0000\n",
      "Epoch 302: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1325e-04 - accuracy: 1.0000 - val_loss: 18.7498 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 303: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 303/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9988    \n",
      "Epoch 303: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0198 - accuracy: 0.9988 - val_loss: 19.3608 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 304: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 304/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9988    \n",
      "Epoch 304: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 40s 287ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 10.9045 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 305: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 305/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9995    \n",
      "Epoch 305: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 16.2005 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 306: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 306/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9998    \n",
      "Epoch 306: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 12.8142 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 307: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 307/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9993    \n",
      "Epoch 307: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 15.0371 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 308: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 308/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9995    \n",
      "Epoch 308: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 16.1579 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 309: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 309/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2717e-04 - accuracy: 1.0000\n",
      "Epoch 309: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.2717e-04 - accuracy: 1.0000 - val_loss: 14.3078 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 310: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 310/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9995    \n",
      "Epoch 310: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 10.9348 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 311: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 311/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9995    \n",
      "Epoch 311: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0155 - accuracy: 0.9995 - val_loss: 8.8187 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 312: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 312/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995    \n",
      "Epoch 312: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 10.1662 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 313: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 313/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.9410e-04 - accuracy: 0.9998\n",
      "Epoch 313: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 5.9410e-04 - accuracy: 0.9998 - val_loss: 12.5217 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 314: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 314/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9993    \n",
      "Epoch 314: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 17.3455 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 315: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 315/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9995    \n",
      "Epoch 315: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 14.2298 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 316: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 316/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9993    \n",
      "Epoch 316: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 5.0867 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 317: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 317/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.5995e-04 - accuracy: 0.9998\n",
      "Epoch 317: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 3.5995e-04 - accuracy: 0.9998 - val_loss: 16.2350 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 318: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 318/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998    \n",
      "Epoch 318: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 14.7816 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 319: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 319/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9993    \n",
      "Epoch 319: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 19.5624 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 320: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 320/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9998    \n",
      "Epoch 320: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0129 - accuracy: 0.9998 - val_loss: 13.2716 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 321: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 321/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9988    \n",
      "Epoch 321: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 261ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 11.1368 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 322: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 322/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9995    \n",
      "Epoch 322: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 15.0448 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 323: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 323/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9991    \n",
      "Epoch 323: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 22.2273 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 324: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 324/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9993    \n",
      "Epoch 324: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 9.8570 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 325: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 325/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 325: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 8.9696 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 326: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 326/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993    \n",
      "Epoch 326: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 6.2964 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 327: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 327/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 327: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 13.2502 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 328: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 328/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9991    \n",
      "Epoch 328: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 19.3658 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 329: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 329/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9993    \n",
      "Epoch 329: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 19.8704 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 330: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 330/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993    \n",
      "Epoch 330: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 16.3352 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 331: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 331/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9991    \n",
      "Epoch 331: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 15.8151 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 332: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 332/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9995    \n",
      "Epoch 332: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 11.7663 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 333: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 333/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9991    \n",
      "Epoch 333: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 9.0115 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 334: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 334/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9998    \n",
      "Epoch 334: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 14.7639 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 335: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 335/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993    \n",
      "Epoch 335: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 10.6160 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 336: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 336/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995    \n",
      "Epoch 336: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 10.9109 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 337: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 337/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 337: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 15.4498 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 338: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 338/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9993    \n",
      "Epoch 338: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 17.3143 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 339: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 339/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9991    \n",
      "Epoch 339: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 9.6904 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 340: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 340/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 340: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 17.7247 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 341: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 341/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9998    \n",
      "Epoch 341: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 20.4026 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 342: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 342/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 342: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 11.4577 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 343: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 343/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 343: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 17.1389 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 344: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 344/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998    \n",
      "Epoch 344: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 21.0958 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 345: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 345/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993    \n",
      "Epoch 345: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 4.9716 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 346: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 346/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9993    \n",
      "Epoch 346: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0101 - accuracy: 0.9993 - val_loss: 15.5366 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 347: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 347/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995    \n",
      "Epoch 347: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 11.1249 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 348: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 348/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9988    \n",
      "Epoch 348: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0108 - accuracy: 0.9988 - val_loss: 15.2011 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 349: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 349/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9991    \n",
      "Epoch 349: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0158 - accuracy: 0.9991 - val_loss: 16.3825 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 350: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 350/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9991    \n",
      "Epoch 350: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 19.8058 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 351: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 351/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998    \n",
      "Epoch 351: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 19.8988 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 352: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 352/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9988    \n",
      "Epoch 352: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0120 - accuracy: 0.9988 - val_loss: 10.1509 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 353: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 353/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9988    \n",
      "Epoch 353: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0140 - accuracy: 0.9988 - val_loss: 6.1215 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 354: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 354/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9988    \n",
      "Epoch 354: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 20.4004 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 355: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 355/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995    \n",
      "Epoch 355: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 16.5282 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 356: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 356/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9988    \n",
      "Epoch 356: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0180 - accuracy: 0.9988 - val_loss: 17.5009 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 357: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 357/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 357: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 24.7154 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 358: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 358/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1298e-04 - accuracy: 1.0000\n",
      "Epoch 358: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1298e-04 - accuracy: 1.0000 - val_loss: 11.6533 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 359: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 359/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9991    \n",
      "Epoch 359: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 20.2312 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 360: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 360/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9998    \n",
      "Epoch 360: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 15.4689 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 361: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 361/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 361: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 11.1727 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 362: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 362/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9995    \n",
      "Epoch 362: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 20.2210 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 363: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 363/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9988    \n",
      "Epoch 363: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 8.7318 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 364: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 364/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9998    \n",
      "Epoch 364: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 16.6414 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 365: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 365/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9995    \n",
      "Epoch 365: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 20.2668 - val_accuracy: 0.9628 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 366: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 366/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9993    \n",
      "Epoch 366: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 15.7599 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 367: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 367/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9995    \n",
      "Epoch 367: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 16.5508 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 368: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 368/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9993    \n",
      "Epoch 368: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0146 - accuracy: 0.9993 - val_loss: 15.8034 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 369: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 369/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993    \n",
      "Epoch 369: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 8.1945 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 370: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 370/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993    \n",
      "Epoch 370: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 16.6115 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 371: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 371/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9986    \n",
      "Epoch 371: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 11.7336 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 372: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 372/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9993    \n",
      "Epoch 372: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 15.4999 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 373: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 373/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9998    \n",
      "Epoch 373: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0149 - accuracy: 0.9998 - val_loss: 14.1400 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 374: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 374/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9998    \n",
      "Epoch 374: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 9.9379 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 375: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 375/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9991    \n",
      "Epoch 375: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0107 - accuracy: 0.9991 - val_loss: 15.2729 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 376: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 376/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 376: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 10.3423 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 377: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 377/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9993    \n",
      "Epoch 377: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 16.9520 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 378: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 378/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9998    \n",
      "Epoch 378: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 14.2845 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 379: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 379/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9998    \n",
      "Epoch 379: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 15.1284 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 380: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 380/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1222e-04 - accuracy: 1.0000\n",
      "Epoch 380: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.1222e-04 - accuracy: 1.0000 - val_loss: 11.0504 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 381: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 381/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9995    \n",
      "Epoch 381: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 9.0168 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 382: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 382/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9995    \n",
      "Epoch 382: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0166 - accuracy: 0.9995 - val_loss: 11.9202 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 383: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 383/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.0482e-04 - accuracy: 0.9998\n",
      "Epoch 383: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 8.0482e-04 - accuracy: 0.9998 - val_loss: 9.0205 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 384: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 384/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9993    \n",
      "Epoch 384: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0224 - accuracy: 0.9993 - val_loss: 7.7780 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 385: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 385/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9993    \n",
      "Epoch 385: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 14.2433 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 386: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 386/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9998    \n",
      "Epoch 386: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 4.3432 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 387: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 387/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9995    \n",
      "Epoch 387: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 9.4004 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 388: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 388/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9993    \n",
      "Epoch 388: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0149 - accuracy: 0.9993 - val_loss: 11.8573 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 389: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 389/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9993    \n",
      "Epoch 389: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0288 - accuracy: 0.9993 - val_loss: 12.0461 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 390: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 390/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9993    \n",
      "Epoch 390: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 13.5333 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 391: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 391/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9998    \n",
      "Epoch 391: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 17.6101 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 392: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 392/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.4875e-04 - accuracy: 0.9998\n",
      "Epoch 392: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 9.4875e-04 - accuracy: 0.9998 - val_loss: 11.6869 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 393: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 393/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9998    \n",
      "Epoch 393: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 15.1523 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 394: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 394/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9993    \n",
      "Epoch 394: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0143 - accuracy: 0.9993 - val_loss: 5.1484 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 395: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 395/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 395: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 12.9182 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 396: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 396/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9988    \n",
      "Epoch 396: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 16.9990 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 397: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 397/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9995    \n",
      "Epoch 397: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 9.7399 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 398: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 398/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9988    \n",
      "Epoch 398: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0220 - accuracy: 0.9988 - val_loss: 14.8486 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 399: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 399/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9993    \n",
      "Epoch 399: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0178 - accuracy: 0.9993 - val_loss: 25.8945 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 400: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 400/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9988    \n",
      "Epoch 400: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0199 - accuracy: 0.9988 - val_loss: 7.5895 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 401: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 401/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998    \n",
      "Epoch 401: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 17.9507 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 402: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 402/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9993    \n",
      "Epoch 402: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 12.2680 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 403: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 403/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9993    \n",
      "Epoch 403: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0107 - accuracy: 0.9993 - val_loss: 21.0863 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 404: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 404/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 404: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 13.1017 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 405: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 405/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9991    \n",
      "Epoch 405: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0208 - accuracy: 0.9991 - val_loss: 12.9354 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 406: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 406/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1776e-04 - accuracy: 1.0000\n",
      "Epoch 406: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.1776e-04 - accuracy: 1.0000 - val_loss: 7.3822 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 407: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 407/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9988    \n",
      "Epoch 407: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0116 - accuracy: 0.9988 - val_loss: 16.9501 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 408: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 408/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9986    \n",
      "Epoch 408: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0182 - accuracy: 0.9986 - val_loss: 9.9068 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 409: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 409/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9991    \n",
      "Epoch 409: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 10.7313 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 410: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 410/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9988    \n",
      "Epoch 410: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0169 - accuracy: 0.9988 - val_loss: 13.8927 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 411: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 411/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995    \n",
      "Epoch 411: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 14.0340 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 412: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 412/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9995    \n",
      "Epoch 412: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 12.1339 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 413: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 413/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9991    \n",
      "Epoch 413: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 16.6620 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 414: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 414/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995    \n",
      "Epoch 414: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 14.3964 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 415: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 415/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9995    \n",
      "Epoch 415: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0170 - accuracy: 0.9995 - val_loss: 10.0224 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 416: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 416/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 416: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 11.8483 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 417: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 417/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9991    \n",
      "Epoch 417: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0190 - accuracy: 0.9991 - val_loss: 16.2390 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 418: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 418/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993    \n",
      "Epoch 418: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 16.2406 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 419: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 419/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9988    \n",
      "Epoch 419: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 14.0004 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 420: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 420/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9993    \n",
      "Epoch 420: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0191 - accuracy: 0.9993 - val_loss: 17.9971 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 421: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 421/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9993    \n",
      "Epoch 421: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0110 - accuracy: 0.9993 - val_loss: 10.9488 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 422: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 422/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9993    \n",
      "Epoch 422: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0111 - accuracy: 0.9993 - val_loss: 14.5452 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 423: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 423/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9986    \n",
      "Epoch 423: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 0.0233 - accuracy: 0.9986 - val_loss: 18.4043 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 424: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 424/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.3841e-04 - accuracy: 0.9998\n",
      "Epoch 424: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 4.3841e-04 - accuracy: 0.9998 - val_loss: 8.8748 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 425: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 425/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9998    \n",
      "Epoch 425: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 10.4139 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 426: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 426/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9993    \n",
      "Epoch 426: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0161 - accuracy: 0.9993 - val_loss: 13.8080 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 427: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 427/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9986    \n",
      "Epoch 427: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0134 - accuracy: 0.9986 - val_loss: 18.6583 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 428: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 428/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9995    \n",
      "Epoch 428: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 3.7401 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 429: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 429/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9998    \n",
      "Epoch 429: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 15.0037 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 430: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 430/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.5988e-04 - accuracy: 0.9998\n",
      "Epoch 430: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.5988e-04 - accuracy: 0.9998 - val_loss: 17.7389 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 431: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 431/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9993    \n",
      "Epoch 431: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 9.6753 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 432: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 432/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 432: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 18.2309 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 433: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 433/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9986    \n",
      "Epoch 433: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0159 - accuracy: 0.9986 - val_loss: 10.9328 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 434: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 434/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9993    \n",
      "Epoch 434: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 14.4109 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 435: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 435/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9993    \n",
      "Epoch 435: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0100 - accuracy: 0.9993 - val_loss: 10.9365 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 436: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 436/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4798e-04 - accuracy: 1.0000\n",
      "Epoch 436: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 2.4798e-04 - accuracy: 1.0000 - val_loss: 17.2861 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 437: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 437/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995    \n",
      "Epoch 437: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 10.4230 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 438: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 438/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9993    \n",
      "Epoch 438: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 13.5063 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 439: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 439/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9993    \n",
      "Epoch 439: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 16.7908 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 440: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 440/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9988    \n",
      "Epoch 440: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 16.3693 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 441: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 441/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3128e-04 - accuracy: 1.0000\n",
      "Epoch 441: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.3128e-04 - accuracy: 1.0000 - val_loss: 3.1298 - val_accuracy: 0.9705 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 442: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 442/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993    \n",
      "Epoch 442: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 12.1959 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 443: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 443/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995    \n",
      "Epoch 443: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 9.7453 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 444: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 444/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9991    \n",
      "Epoch 444: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0193 - accuracy: 0.9991 - val_loss: 18.0008 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 445: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 445/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9995    \n",
      "Epoch 445: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 20.0461 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 446: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 446/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9993    \n",
      "Epoch 446: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0110 - accuracy: 0.9993 - val_loss: 10.7358 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 447: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 447/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9995    \n",
      "Epoch 447: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 14.9368 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 448: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 448/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9986    \n",
      "Epoch 448: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0157 - accuracy: 0.9986 - val_loss: 11.8971 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 449: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 449/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993    \n",
      "Epoch 449: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 15.7561 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 450: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 450/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9998    \n",
      "Epoch 450: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 12.8290 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 451: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 451/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9991    \n",
      "Epoch 451: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 12.1536 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 452: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 452/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9993    \n",
      "Epoch 452: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0108 - accuracy: 0.9993 - val_loss: 16.2360 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 453: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 453/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995    \n",
      "Epoch 453: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 15.2221 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 454: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 454/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9993    \n",
      "Epoch 454: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0118 - accuracy: 0.9993 - val_loss: 3.5146 - val_accuracy: 0.9712 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 455: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 455/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5432e-04 - accuracy: 1.0000\n",
      "Epoch 455: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 1.5432e-04 - accuracy: 1.0000 - val_loss: 16.2461 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 456: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 456/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9993    \n",
      "Epoch 456: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 10.5433 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 457: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 457/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9991    \n",
      "Epoch 457: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 9.8582 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 458: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 458/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.3747e-04 - accuracy: 0.9998\n",
      "Epoch 458: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 5.3747e-04 - accuracy: 0.9998 - val_loss: 14.6080 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 459: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 459/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9991    \n",
      "Epoch 459: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 21.6610 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 460: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 460/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991    \n",
      "Epoch 460: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 12.5747 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 461: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 461/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9993    \n",
      "Epoch 461: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 21.1516 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 462: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 462/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9991    \n",
      "Epoch 462: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 11.4044 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 463: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 463/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 463: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 5.8892 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 464: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 464/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993    \n",
      "Epoch 464: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 10.0485 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 465: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 465/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9993    \n",
      "Epoch 465: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 0.0126 - accuracy: 0.9993 - val_loss: 10.4473 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 466: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 466/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 466: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 14.1205 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 467: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 467/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9995    \n",
      "Epoch 467: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 16.5577 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 468: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 468/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9991    \n",
      "Epoch 468: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0171 - accuracy: 0.9991 - val_loss: 18.2669 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 469: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 469/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5454e-04 - accuracy: 1.0000\n",
      "Epoch 469: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 2.5454e-04 - accuracy: 1.0000 - val_loss: 21.8630 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 470: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 470/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9995    \n",
      "Epoch 470: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 16.4138 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 471: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 471/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 471: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 13.3558 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 472: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 472/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9988    \n",
      "Epoch 472: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0112 - accuracy: 0.9988 - val_loss: 19.7068 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 473: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 473/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9991    \n",
      "Epoch 473: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 9.8064 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 474: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 474/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9998    \n",
      "Epoch 474: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 28.2109 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 475: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 475/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995    \n",
      "Epoch 475: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 15.2412 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 476: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 476/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995    \n",
      "Epoch 476: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 21.9469 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 477: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 477/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9993    \n",
      "Epoch 477: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0120 - accuracy: 0.9993 - val_loss: 12.2907 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 478: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 478/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 478: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 16.9813 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 479: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 479/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995    \n",
      "Epoch 479: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 15.2823 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 480: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 480/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9986    \n",
      "Epoch 480: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0257 - accuracy: 0.9986 - val_loss: 19.6355 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 481: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 481/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995    \n",
      "Epoch 481: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 8.3367 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 482: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 482/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9995    \n",
      "Epoch 482: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 10.8206 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 483: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 483/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 483: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 18.5620 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 484: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 484/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9998    \n",
      "Epoch 484: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0152 - accuracy: 0.9998 - val_loss: 16.1154 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 485: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 485/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993    \n",
      "Epoch 485: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 8.7070 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 486: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 486/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9986    \n",
      "Epoch 486: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0233 - accuracy: 0.9986 - val_loss: 16.7820 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 487: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 487/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9988    \n",
      "Epoch 487: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0230 - accuracy: 0.9988 - val_loss: 13.5794 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 488: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 488/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993    \n",
      "Epoch 488: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 14.3755 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 489: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 489/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9995    \n",
      "Epoch 489: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 15.3916 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 490: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 490/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9995    \n",
      "Epoch 490: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 22.3617 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 491: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 491/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9993    \n",
      "Epoch 491: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 9.5205 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 492: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 492/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998    \n",
      "Epoch 492: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 13.9028 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 493: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 493/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9991    \n",
      "Epoch 493: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 18.9476 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 494: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 494/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995    \n",
      "Epoch 494: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 8.6181 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 495: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 495/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9988    \n",
      "Epoch 495: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0123 - accuracy: 0.9988 - val_loss: 11.8500 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 496: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 496/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 496: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 14.2284 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 497: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 497/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9995    \n",
      "Epoch 497: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0094 - accuracy: 0.9995 - val_loss: 7.0708 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 498: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 498/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.4869e-04 - accuracy: 0.9998\n",
      "Epoch 498: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 4.4869e-04 - accuracy: 0.9998 - val_loss: 16.5428 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 499: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 499/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4731e-04 - accuracy: 1.0000\n",
      "Epoch 499: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.4731e-04 - accuracy: 1.0000 - val_loss: 19.3141 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 500: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 500/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9995    \n",
      "Epoch 500: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0164 - accuracy: 0.9995 - val_loss: 7.4603 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 501: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 501/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993    \n",
      "Epoch 501: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 9.8233 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 502: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 502/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 502: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 14.7751 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 503: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 503/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9991    \n",
      "Epoch 503: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 15.1758 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 504: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 504/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9995    \n",
      "Epoch 504: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 23.7370 - val_accuracy: 0.9628 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 505: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 505/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9993    \n",
      "Epoch 505: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 35s 257ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 15.5480 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 506: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 506/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9995    \n",
      "Epoch 506: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0096 - accuracy: 0.9995 - val_loss: 16.3496 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 507: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 507/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 507: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 12.3730 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 508: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 508/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9991    \n",
      "Epoch 508: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0146 - accuracy: 0.9991 - val_loss: 10.9548 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 509: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 509/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995    \n",
      "Epoch 509: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 16.3388 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 510: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 510/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9993    \n",
      "Epoch 510: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 10.8855 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 511: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 511/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9993    \n",
      "Epoch 511: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 13.7871 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 512: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 512/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9991    \n",
      "Epoch 512: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0160 - accuracy: 0.9991 - val_loss: 16.6782 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 513: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 513/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9993    \n",
      "Epoch 513: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 10.9726 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 514: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 514/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 514: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 14.0376 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 515: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 515/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9993    \n",
      "Epoch 515: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 22.3335 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 516: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 516/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9993    \n",
      "Epoch 516: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 19.6546 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 517: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 517/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9995    \n",
      "Epoch 517: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 14.3656 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 518: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 518/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9993    \n",
      "Epoch 518: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 10.1609 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 519: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 519/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9991    \n",
      "Epoch 519: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 15.3731 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 520: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 520/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.6107e-04 - accuracy: 0.9998\n",
      "Epoch 520: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 5.6107e-04 - accuracy: 0.9998 - val_loss: 8.5847 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 521: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 521/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998    \n",
      "Epoch 521: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 15.5736 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 522: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 522/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993    \n",
      "Epoch 522: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 17.6025 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 523: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 523/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9988    \n",
      "Epoch 523: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0168 - accuracy: 0.9988 - val_loss: 10.1581 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 524: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 524/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9995    \n",
      "Epoch 524: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 8.0935 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 525: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 525/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9993    \n",
      "Epoch 525: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 14.9804 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 526: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 526/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.0852e-04 - accuracy: 0.9998\n",
      "Epoch 526: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.0852e-04 - accuracy: 0.9998 - val_loss: 10.6388 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 527: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 527/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9991    \n",
      "Epoch 527: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0119 - accuracy: 0.9991 - val_loss: 17.5066 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 528: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 528/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993    \n",
      "Epoch 528: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 257ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 7.1274 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 529: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 529/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9993    \n",
      "Epoch 529: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 19.7631 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 530: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 530/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9993    \n",
      "Epoch 530: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 12.1402 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 531: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 531/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993    \n",
      "Epoch 531: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 22.8986 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 532: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 532/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993    \n",
      "Epoch 532: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 13.5513 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 533: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 533/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993    \n",
      "Epoch 533: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 12.1340 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 534: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 534/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9998    \n",
      "Epoch 534: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0122 - accuracy: 0.9998 - val_loss: 7.2020 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 535: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 535/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995    \n",
      "Epoch 535: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 9.8559 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 536: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 536/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9995    \n",
      "Epoch 536: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 22.4067 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 537: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 537/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995    \n",
      "Epoch 537: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 11.4224 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 538: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 538/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.7330e-04 - accuracy: 0.9995\n",
      "Epoch 538: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 8.7330e-04 - accuracy: 0.9995 - val_loss: 16.9319 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 539: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 539/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998    \n",
      "Epoch 539: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 15.4920 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 540: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 540/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995    \n",
      "Epoch 540: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 11.7259 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 541: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 541/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9998    \n",
      "Epoch 541: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 17.1425 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 542: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 542/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9991    \n",
      "Epoch 542: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0152 - accuracy: 0.9991 - val_loss: 14.9181 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 543: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 543/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9991    \n",
      "Epoch 543: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 9.3920 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 544: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 544/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9988    \n",
      "Epoch 544: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 7.7898 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 545: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 545/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9993    \n",
      "Epoch 545: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 10.0556 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 546: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 546/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9991    \n",
      "Epoch 546: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0140 - accuracy: 0.9991 - val_loss: 5.4719 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 547: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 547/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9993    \n",
      "Epoch 547: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 13.2444 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 548: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 548/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9988    \n",
      "Epoch 548: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0178 - accuracy: 0.9988 - val_loss: 21.1271 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 549: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 549/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993    \n",
      "Epoch 549: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 14.0738 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 550: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 550/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1301e-04 - accuracy: 1.0000\n",
      "Epoch 550: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1301e-04 - accuracy: 1.0000 - val_loss: 11.7380 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 551: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 551/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9988    \n",
      "Epoch 551: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 8.9441 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 552: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 552/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9998    \n",
      "Epoch 552: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 11.7116 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 553: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 553/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9993    \n",
      "Epoch 553: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0175 - accuracy: 0.9993 - val_loss: 8.9481 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 554: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 554/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995    \n",
      "Epoch 554: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 11.7426 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 555: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 555/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 555: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 18.8798 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 556: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 556/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998    \n",
      "Epoch 556: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 13.0316 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 557: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 557/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 557: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 17.5193 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 558: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 558/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9995    \n",
      "Epoch 558: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 9.4361 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 559: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 559/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9995    \n",
      "Epoch 559: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0126 - accuracy: 0.9995 - val_loss: 11.8491 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 560: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 560/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9991    \n",
      "Epoch 560: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0183 - accuracy: 0.9991 - val_loss: 20.8506 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 561: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 561/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998    \n",
      "Epoch 561: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 13.7610 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 562: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 562/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9991    \n",
      "Epoch 562: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 15.8417 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 563: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 563/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9988    \n",
      "Epoch 563: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0218 - accuracy: 0.9988 - val_loss: 7.5146 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 564: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 564/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9991    \n",
      "Epoch 564: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 12.5763 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 565: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 565/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1535e-04 - accuracy: 1.0000\n",
      "Epoch 565: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1535e-04 - accuracy: 1.0000 - val_loss: 16.2350 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 566: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 566/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9991    \n",
      "Epoch 566: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 11.7362 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 567: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 567/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 567: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 19.5985 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 568: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 568/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 568: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 11.5150 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 569: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 569/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9998    \n",
      "Epoch 569: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0093 - accuracy: 0.9998 - val_loss: 13.2546 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 570: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 570/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9988    \n",
      "Epoch 570: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 13.2283 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 571: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 571/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9991    \n",
      "Epoch 571: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0192 - accuracy: 0.9991 - val_loss: 16.0981 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 572: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 572/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998    \n",
      "Epoch 572: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 15.1497 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 573: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 573/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9991    \n",
      "Epoch 573: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 11.1648 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 574: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 574/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9995    \n",
      "Epoch 574: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 22.1376 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 575: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 575/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9998    \n",
      "Epoch 575: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 20.3531 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 576: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 576/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2221e-04 - accuracy: 1.0000\n",
      "Epoch 576: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.2221e-04 - accuracy: 1.0000 - val_loss: 16.0828 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 577: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 577/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9993    \n",
      "Epoch 577: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 12.6466 - val_accuracy: 0.9628 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 578: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 578/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9988    \n",
      "Epoch 578: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0170 - accuracy: 0.9988 - val_loss: 15.2530 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 579: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 579/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9986    \n",
      "Epoch 579: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0168 - accuracy: 0.9986 - val_loss: 11.8754 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 580: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 580/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9993    \n",
      "Epoch 580: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0133 - accuracy: 0.9993 - val_loss: 15.1235 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 581: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 581/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9993    \n",
      "Epoch 581: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 17.4871 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 582: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 582/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9993    \n",
      "Epoch 582: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 15.7531 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 583: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 583/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9991    \n",
      "Epoch 583: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 9.2836 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 584: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 584/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.1548e-04 - accuracy: 1.0000\n",
      "Epoch 584: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.1548e-04 - accuracy: 1.0000 - val_loss: 7.0899 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 585: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 585/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9995    \n",
      "Epoch 585: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 11.3239 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 586: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 586/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.0690e-04 - accuracy: 0.9998\n",
      "Epoch 586: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.0690e-04 - accuracy: 0.9998 - val_loss: 12.7717 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 587: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 587/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9995    \n",
      "Epoch 587: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 11.5312 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 588: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 588/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9995    \n",
      "Epoch 588: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 22.6818 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 589: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 589/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9991    \n",
      "Epoch 589: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0107 - accuracy: 0.9991 - val_loss: 8.0627 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 590: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 590/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 590: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 13.6175 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 591: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 591/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9991    \n",
      "Epoch 591: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0157 - accuracy: 0.9991 - val_loss: 13.2284 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 592: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 592/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9993    \n",
      "Epoch 592: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0124 - accuracy: 0.9993 - val_loss: 10.2298 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 593: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 593/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9995    \n",
      "Epoch 593: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 10.7146 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 594: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 594/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9986    \n",
      "Epoch 594: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0197 - accuracy: 0.9986 - val_loss: 11.4231 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 595: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 595/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 595: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 18.3828 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 596: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 596/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9995    \n",
      "Epoch 596: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 15.4847 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 597: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 597/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.9462e-04 - accuracy: 0.9995\n",
      "Epoch 597: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 8.9462e-04 - accuracy: 0.9995 - val_loss: 9.9310 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 598: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 598/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.6307e-04 - accuracy: 0.9998\n",
      "Epoch 598: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.6307e-04 - accuracy: 0.9998 - val_loss: 15.0269 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 599: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 599/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995    \n",
      "Epoch 599: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 17.9835 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 600: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 600/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993    \n",
      "Epoch 600: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 7.8576 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 601: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 601/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9995    \n",
      "Epoch 601: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 30.0335 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 602: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 602/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9991    \n",
      "Epoch 602: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0176 - accuracy: 0.9991 - val_loss: 13.5938 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 603: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 603/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993    \n",
      "Epoch 603: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 14.8987 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 604: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 604/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9991    \n",
      "Epoch 604: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0356 - accuracy: 0.9991 - val_loss: 11.1103 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 605: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 605/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995    \n",
      "Epoch 605: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 10.9730 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 606: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 606/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9988    \n",
      "Epoch 606: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0248 - accuracy: 0.9988 - val_loss: 20.3870 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 607: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 607/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995    \n",
      "Epoch 607: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 13.7538 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 608: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 608/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 608: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 11.5863 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 609: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 609/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993    \n",
      "Epoch 609: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 12.3701 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 610: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 610/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9988    \n",
      "Epoch 610: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0200 - accuracy: 0.9988 - val_loss: 11.5442 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 611: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 611/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9991    \n",
      "Epoch 611: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0173 - accuracy: 0.9991 - val_loss: 18.1712 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 612: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 612/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 612: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 15.0904 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 613: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 613/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9988    \n",
      "Epoch 613: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0094 - accuracy: 0.9988 - val_loss: 8.8281 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 614: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 614/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9995    \n",
      "Epoch 614: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 20.9830 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 615: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 615/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9993    \n",
      "Epoch 615: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 17.9070 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 616: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 616/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9993    \n",
      "Epoch 616: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 11.8971 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 617: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 617/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9995    \n",
      "Epoch 617: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 11.1115 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 618: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 618/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9995    \n",
      "Epoch 618: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 11.1572 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 619: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 619/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9993    \n",
      "Epoch 619: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 25.1458 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 620: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 620/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9995    \n",
      "Epoch 620: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 15.6208 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 621: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 621/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9376e-04 - accuracy: 1.0000\n",
      "Epoch 621: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.9376e-04 - accuracy: 1.0000 - val_loss: 15.1586 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 622: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 622/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9993    \n",
      "Epoch 622: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0177 - accuracy: 0.9993 - val_loss: 5.9052 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 623: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 623/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.4740e-04 - accuracy: 0.9998\n",
      "Epoch 623: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 8.4740e-04 - accuracy: 0.9998 - val_loss: 8.2114 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 624: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 624/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9991    \n",
      "Epoch 624: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0124 - accuracy: 0.9991 - val_loss: 15.5281 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 625: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 625/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9991    \n",
      "Epoch 625: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 39s 286ms/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 20.0307 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 626: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 626/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9993    \n",
      "Epoch 626: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0114 - accuracy: 0.9993 - val_loss: 14.3260 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 627: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 627/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1590e-04 - accuracy: 1.0000\n",
      "Epoch 627: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1590e-04 - accuracy: 1.0000 - val_loss: 15.5467 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 628: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 628/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9995    \n",
      "Epoch 628: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 21.4083 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 629: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 629/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995    \n",
      "Epoch 629: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 22.8917 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 630: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 630/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9993    \n",
      "Epoch 630: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 13.7486 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 631: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 631/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9993    \n",
      "Epoch 631: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 14.6374 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 632: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 632/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998    \n",
      "Epoch 632: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 17.7588 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 633: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 633/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.4811e-04 - accuracy: 0.9995\n",
      "Epoch 633: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 8.4811e-04 - accuracy: 0.9995 - val_loss: 12.8889 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 634: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 634/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9993    \n",
      "Epoch 634: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0166 - accuracy: 0.9993 - val_loss: 9.9592 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 635: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 635/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 635: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 9.2861 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 636: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 636/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993    \n",
      "Epoch 636: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 18.1241 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 637: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 637/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9995    \n",
      "Epoch 637: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 16.0049 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 638: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 638/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9988    \n",
      "Epoch 638: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 20.8022 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 639: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 639/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9993    \n",
      "Epoch 639: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0182 - accuracy: 0.9993 - val_loss: 11.9013 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 640: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 640/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995    \n",
      "Epoch 640: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 11.8284 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 641: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 641/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9986    \n",
      "Epoch 641: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0098 - accuracy: 0.9986 - val_loss: 18.1795 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 642: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 642/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9991    \n",
      "Epoch 642: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 19.7593 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 643: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 643/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993    \n",
      "Epoch 643: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 22.4063 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 644: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 644/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9995    \n",
      "Epoch 644: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 10.5178 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 645: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 645/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9991    \n",
      "Epoch 645: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0210 - accuracy: 0.9991 - val_loss: 13.3609 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 646: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 646/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 646: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 10.8469 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 647: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 647/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1658e-04 - accuracy: 1.0000\n",
      "Epoch 647: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.1658e-04 - accuracy: 1.0000 - val_loss: 11.1601 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 648: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 648/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2480e-04 - accuracy: 1.0000\n",
      "Epoch 648: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.2480e-04 - accuracy: 1.0000 - val_loss: 12.6433 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 649: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 649/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 649: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 10.7805 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 650: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 650/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9993    \n",
      "Epoch 650: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 12.2675 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 651: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 651/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995    \n",
      "Epoch 651: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 13.5071 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 652: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 652/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993    \n",
      "Epoch 652: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 10.5360 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 653: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 653/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9993    \n",
      "Epoch 653: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 19.2515 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 654: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 654/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9998    \n",
      "Epoch 654: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 17.8422 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 655: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 655/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9991    \n",
      "Epoch 655: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0179 - accuracy: 0.9991 - val_loss: 14.0969 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 656: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 656/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993    \n",
      "Epoch 656: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 14.0488 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 657: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 657/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9993    \n",
      "Epoch 657: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 14.1019 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 658: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 658/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9991    \n",
      "Epoch 658: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0167 - accuracy: 0.9991 - val_loss: 15.0057 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 659: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 659/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9993    \n",
      "Epoch 659: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 18.4005 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 660: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 660/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9998    \n",
      "Epoch 660: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 10.3503 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 661: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 661/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.6177e-04 - accuracy: 0.9998\n",
      "Epoch 661: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 6.6177e-04 - accuracy: 0.9998 - val_loss: 14.5599 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 662: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 662/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9991    \n",
      "Epoch 662: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 9.3662 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 663: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 663/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9993    \n",
      "Epoch 663: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0110 - accuracy: 0.9993 - val_loss: 9.3204 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 664: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 664/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9991    \n",
      "Epoch 664: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0127 - accuracy: 0.9991 - val_loss: 5.7752 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 665: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 665/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9993    \n",
      "Epoch 665: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0122 - accuracy: 0.9993 - val_loss: 6.6247 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 666: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 666/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9993    \n",
      "Epoch 666: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0198 - accuracy: 0.9993 - val_loss: 11.2547 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 667: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 667/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9988    \n",
      "Epoch 667: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 11.6798 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 668: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 668/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9995    \n",
      "Epoch 668: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 8.0372 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 669: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 669/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9995    \n",
      "Epoch 669: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 18.4912 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 670: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 670/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9995    \n",
      "Epoch 670: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 18.6888 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 671: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 671/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9986    \n",
      "Epoch 671: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 19.2374 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 672: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 672/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 672: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 15.7992 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 673: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 673/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9988    \n",
      "Epoch 673: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 22.1201 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 674: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 674/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9991    \n",
      "Epoch 674: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0172 - accuracy: 0.9991 - val_loss: 7.9837 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 675: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 675/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9995    \n",
      "Epoch 675: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 17.2716 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 676: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 676/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1300e-04 - accuracy: 1.0000\n",
      "Epoch 676: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 1.1300e-04 - accuracy: 1.0000 - val_loss: 14.9682 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 677: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 677/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9991    \n",
      "Epoch 677: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0151 - accuracy: 0.9991 - val_loss: 14.3284 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 678: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 678/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9993    \n",
      "Epoch 678: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0116 - accuracy: 0.9993 - val_loss: 19.7791 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 679: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 679/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9991    \n",
      "Epoch 679: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 18.7497 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 680: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 680/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995    \n",
      "Epoch 680: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 15.8190 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 681: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 681/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9988    \n",
      "Epoch 681: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 8.4515 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 682: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 682/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9993    \n",
      "Epoch 682: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0108 - accuracy: 0.9993 - val_loss: 18.0033 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 683: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 683/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9995    \n",
      "Epoch 683: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 17.6383 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 684: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 684/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 684: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 12.2023 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 685: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 685/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991    \n",
      "Epoch 685: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 11.2189 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 686: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 686/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9984    \n",
      "Epoch 686: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0307 - accuracy: 0.9984 - val_loss: 12.1217 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 687: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 687/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 687: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 15.5308 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 688: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 688/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9993    \n",
      "Epoch 688: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 14.5869 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 689: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 689/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9993    \n",
      "Epoch 689: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0164 - accuracy: 0.9993 - val_loss: 10.1342 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 690: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 690/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9995    \n",
      "Epoch 690: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 18.8382 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 691: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 691/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993    \n",
      "Epoch 691: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 15.1506 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 692: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 692/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9988    \n",
      "Epoch 692: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 19.4579 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 693: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 693/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988    \n",
      "Epoch 693: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 6.2214 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 694: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 694/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1241e-04 - accuracy: 1.0000\n",
      "Epoch 694: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.1241e-04 - accuracy: 1.0000 - val_loss: 8.1926 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 695: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 695/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9993    \n",
      "Epoch 695: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0145 - accuracy: 0.9993 - val_loss: 14.4306 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 696: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 696/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9998    \n",
      "Epoch 696: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 12.9152 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 697: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 697/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9995    \n",
      "Epoch 697: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 14.5446 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 698: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 698/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995    \n",
      "Epoch 698: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 12.9136 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 699: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 699/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9993    \n",
      "Epoch 699: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0127 - accuracy: 0.9993 - val_loss: 14.3724 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 700: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 700/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9998    \n",
      "Epoch 700: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 13.6535 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 701: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 701/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9995    \n",
      "Epoch 701: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 11.9910 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 702: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 702/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9991    \n",
      "Epoch 702: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 16.8680 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 703: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 703/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9991    \n",
      "Epoch 703: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 19.4873 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 704: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 704/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9988    \n",
      "Epoch 704: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0093 - accuracy: 0.9988 - val_loss: 21.0343 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 705: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 705/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.3831e-04 - accuracy: 1.0000\n",
      "Epoch 705: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 2.3831e-04 - accuracy: 1.0000 - val_loss: 29.7410 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 706: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 706/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9995    \n",
      "Epoch 706: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 17.2115 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 707: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 707/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9991    \n",
      "Epoch 707: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 21.6959 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 708: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 708/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9993    \n",
      "Epoch 708: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0159 - accuracy: 0.9993 - val_loss: 16.2975 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 709: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 709/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993    \n",
      "Epoch 709: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 4.4968 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 710: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 710/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 710: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 18.2304 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 711: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 711/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9995    \n",
      "Epoch 711: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 13.2232 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 712: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 712/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998    \n",
      "Epoch 712: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 20.5910 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 713: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 713/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9998    \n",
      "Epoch 713: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 16.4233 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 714: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 714/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9995    \n",
      "Epoch 714: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 19.3705 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 715: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 715/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9995    \n",
      "Epoch 715: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 11.0029 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 716: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 716/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9991    \n",
      "Epoch 716: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 14.5676 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 717: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 717/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998    \n",
      "Epoch 717: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 10.8892 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 718: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 718/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9993    \n",
      "Epoch 718: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 27.2177 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 719: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 719/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4782e-04 - accuracy: 1.0000\n",
      "Epoch 719: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.4782e-04 - accuracy: 1.0000 - val_loss: 11.5572 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 720: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 720/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995    \n",
      "Epoch 720: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 8.9490 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 721: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 721/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9991    \n",
      "Epoch 721: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0155 - accuracy: 0.9991 - val_loss: 7.9552 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 722: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 722/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9993    \n",
      "Epoch 722: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 15.1663 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 723: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 723/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998    \n",
      "Epoch 723: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 8.5510 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 724: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 724/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.5147e-04 - accuracy: 0.9998\n",
      "Epoch 724: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 6.5147e-04 - accuracy: 0.9998 - val_loss: 16.9934 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 725: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 725/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9995    \n",
      "Epoch 725: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0112 - accuracy: 0.9995 - val_loss: 13.3695 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 726: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 726/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9995    \n",
      "Epoch 726: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 13.8652 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 727: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 727/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9995    \n",
      "Epoch 727: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 17.5284 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 728: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 728/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9993    \n",
      "Epoch 728: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0125 - accuracy: 0.9993 - val_loss: 16.1388 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 729: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 729/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9993    \n",
      "Epoch 729: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0129 - accuracy: 0.9993 - val_loss: 12.9271 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 730: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 730/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.1063e-04 - accuracy: 0.9995\n",
      "Epoch 730: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 8.1063e-04 - accuracy: 0.9995 - val_loss: 19.8784 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 731: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 731/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.5884e-04 - accuracy: 0.9998\n",
      "Epoch 731: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 3.5884e-04 - accuracy: 0.9998 - val_loss: 13.8546 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 732: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 732/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1942e-04 - accuracy: 1.0000\n",
      "Epoch 732: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.1942e-04 - accuracy: 1.0000 - val_loss: 10.8891 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 733: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 733/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9986    \n",
      "Epoch 733: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0164 - accuracy: 0.9986 - val_loss: 9.8209 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 734: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 734/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9998    \n",
      "Epoch 734: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0080 - accuracy: 0.9998 - val_loss: 14.5538 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 735: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 735/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9993    \n",
      "Epoch 735: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0209 - accuracy: 0.9993 - val_loss: 20.1282 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 736: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 736/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9998    \n",
      "Epoch 736: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 15.8163 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 737: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 737/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9995    \n",
      "Epoch 737: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0128 - accuracy: 0.9995 - val_loss: 12.7912 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 738: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 738/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9988    \n",
      "Epoch 738: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0239 - accuracy: 0.9988 - val_loss: 16.0928 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 739: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 739/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9995    \n",
      "Epoch 739: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 11.5999 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 740: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 740/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 740: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 17.8364 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 741: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 741/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9988    \n",
      "Epoch 741: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0221 - accuracy: 0.9988 - val_loss: 8.1882 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 742: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 742/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9988    \n",
      "Epoch 742: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0096 - accuracy: 0.9988 - val_loss: 8.8990 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 743: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 743/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9993    \n",
      "Epoch 743: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 13.8884 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 744: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 744/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9995    \n",
      "Epoch 744: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 12.8293 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 745: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 745/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9991    \n",
      "Epoch 745: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0187 - accuracy: 0.9991 - val_loss: 22.2203 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 746: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 746/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9995    \n",
      "Epoch 746: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 8.2963 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 747: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 747/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9991    \n",
      "Epoch 747: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0114 - accuracy: 0.9991 - val_loss: 10.3404 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 748: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 748/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 748: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 11.6707 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 749: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 749/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9986    \n",
      "Epoch 749: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0205 - accuracy: 0.9986 - val_loss: 21.6741 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 750: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 750/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9991    \n",
      "Epoch 750: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0191 - accuracy: 0.9991 - val_loss: 8.0157 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 751: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 751/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3762e-04 - accuracy: 1.0000\n",
      "Epoch 751: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.3762e-04 - accuracy: 1.0000 - val_loss: 14.0019 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 752: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 752/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4597e-04 - accuracy: 1.0000\n",
      "Epoch 752: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.4597e-04 - accuracy: 1.0000 - val_loss: 7.7991 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 753: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 753/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993    \n",
      "Epoch 753: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 21.1593 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 754: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 754/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9998    \n",
      "Epoch 754: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 16.2322 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 755: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 755/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9988    \n",
      "Epoch 755: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0172 - accuracy: 0.9988 - val_loss: 10.4711 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 756: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 756/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9995    \n",
      "Epoch 756: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 13.1849 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 757: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 757/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9988    \n",
      "Epoch 757: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 14.2206 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 758: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 758/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9995    \n",
      "Epoch 758: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 8.1758 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 759: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 759/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9979    \n",
      "Epoch 759: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0223 - accuracy: 0.9979 - val_loss: 16.2771 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 760: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 760/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993    \n",
      "Epoch 760: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 11.2269 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 761: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 761/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 761: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 6.7541 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 762: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 762/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9993    \n",
      "Epoch 762: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 15.5096 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 763: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 763/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9995    \n",
      "Epoch 763: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 11.1218 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 764: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 764/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 764: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 16.0420 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 765: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 765/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9991    \n",
      "Epoch 765: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 15.2720 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 766: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 766/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9988    \n",
      "Epoch 766: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0188 - accuracy: 0.9988 - val_loss: 8.7685 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 767: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 767/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9988    \n",
      "Epoch 767: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0399 - accuracy: 0.9988 - val_loss: 14.2059 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 768: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 768/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9993    \n",
      "Epoch 768: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 17.4192 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 769: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 769/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9995    \n",
      "Epoch 769: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 11.0585 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 770: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 770/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9993    \n",
      "Epoch 770: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 17.1008 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 771: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 771/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995    \n",
      "Epoch 771: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 11.0184 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 772: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 772/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9988    \n",
      "Epoch 772: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0206 - accuracy: 0.9988 - val_loss: 20.6696 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 773: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 773/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.7805e-04 - accuracy: 0.9998\n",
      "Epoch 773: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 2.7805e-04 - accuracy: 0.9998 - val_loss: 11.7916 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 774: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 774/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.4942e-04 - accuracy: 0.9998\n",
      "Epoch 774: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 9.4942e-04 - accuracy: 0.9998 - val_loss: 11.1625 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 775: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 775/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9988    \n",
      "Epoch 775: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0129 - accuracy: 0.9988 - val_loss: 10.8556 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 776: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 776/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.5694e-04 - accuracy: 0.9998\n",
      "Epoch 776: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 5.5694e-04 - accuracy: 0.9998 - val_loss: 14.7177 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 777: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 777/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9995    \n",
      "Epoch 777: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 257ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 17.0668 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 778: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 778/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995    \n",
      "Epoch 778: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 9.5896 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 779: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 779/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9993    \n",
      "Epoch 779: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 8.3144 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 780: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 780/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9991    \n",
      "Epoch 780: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 16.2586 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 781: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 781/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9993    \n",
      "Epoch 781: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 12.3194 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 782: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 782/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 782: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 11.1224 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 783: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 783/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993    \n",
      "Epoch 783: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 14.8547 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 784: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 784/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998    \n",
      "Epoch 784: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 12.4093 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 785: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 785/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9991    \n",
      "Epoch 785: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0118 - accuracy: 0.9991 - val_loss: 8.4051 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 786: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 786/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9995    \n",
      "Epoch 786: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 17.4765 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 787: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 787/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9993    \n",
      "Epoch 787: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 16.3157 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 788: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 788/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993    \n",
      "Epoch 788: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 11.6600 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 789: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 789/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9993    \n",
      "Epoch 789: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0123 - accuracy: 0.9993 - val_loss: 17.7784 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 790: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 790/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993    \n",
      "Epoch 790: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 13.8104 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 791: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 791/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9993    \n",
      "Epoch 791: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 23.7376 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 792: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 792/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9986    \n",
      "Epoch 792: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 16.0089 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 793: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 793/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9993    \n",
      "Epoch 793: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0121 - accuracy: 0.9993 - val_loss: 9.9649 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 794: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 794/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9993    \n",
      "Epoch 794: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0172 - accuracy: 0.9993 - val_loss: 9.8238 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 795: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 795/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9993    \n",
      "Epoch 795: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0111 - accuracy: 0.9993 - val_loss: 10.8993 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 796: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 796/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995    \n",
      "Epoch 796: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 19.8626 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 797: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 797/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.0841e-04 - accuracy: 0.9998\n",
      "Epoch 797: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 5.0841e-04 - accuracy: 0.9998 - val_loss: 18.0053 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 798: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 798/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9998    \n",
      "Epoch 798: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 17.2716 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 799: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 799/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993    \n",
      "Epoch 799: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 12.2167 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 800: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 800/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9998    \n",
      "Epoch 800: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0122 - accuracy: 0.9998 - val_loss: 13.4701 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 801: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 801/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9991    \n",
      "Epoch 801: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 19.4542 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 802: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 802/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9991    \n",
      "Epoch 802: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 13.4601 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 803: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 803/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9991    \n",
      "Epoch 803: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0159 - accuracy: 0.9991 - val_loss: 15.1016 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 804: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 804/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993    \n",
      "Epoch 804: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 14.1246 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 805: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 805/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9993    \n",
      "Epoch 805: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 14.3809 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 806: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 806/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9995    \n",
      "Epoch 806: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 13.6214 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 807: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 807/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 807: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 13.3367 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 808: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 808/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 808: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 17.0775 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 809: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 809/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9988    \n",
      "Epoch 809: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 12.7463 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 810: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 810/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9991    \n",
      "Epoch 810: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 14.1653 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 811: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 811/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995    \n",
      "Epoch 811: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 9.3053 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 812: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 812/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9986    \n",
      "Epoch 812: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 0.0231 - accuracy: 0.9986 - val_loss: 23.7016 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 813: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 813/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9993    \n",
      "Epoch 813: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0149 - accuracy: 0.9993 - val_loss: 11.7624 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 814: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 814/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9993    \n",
      "Epoch 814: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 17.6515 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 815: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 815/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9988    \n",
      "Epoch 815: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 11.6522 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 816: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 816/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.6157e-04 - accuracy: 1.0000\n",
      "Epoch 816: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 2.6157e-04 - accuracy: 1.0000 - val_loss: 8.6855 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 817: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 817/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9988    \n",
      "Epoch 817: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0162 - accuracy: 0.9988 - val_loss: 11.8950 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 818: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 818/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9993    \n",
      "Epoch 818: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 13.8317 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 819: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 819/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9986    \n",
      "Epoch 819: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0163 - accuracy: 0.9986 - val_loss: 14.3553 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 820: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 820/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9993    \n",
      "Epoch 820: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0213 - accuracy: 0.9993 - val_loss: 15.2908 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 821: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 821/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9991    \n",
      "Epoch 821: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 11.5660 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 822: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 822/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9988    \n",
      "Epoch 822: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0139 - accuracy: 0.9988 - val_loss: 13.3304 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 823: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 823/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9993    \n",
      "Epoch 823: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0111 - accuracy: 0.9993 - val_loss: 10.0497 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 824: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 824/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9991    \n",
      "Epoch 824: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0162 - accuracy: 0.9991 - val_loss: 17.5783 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 825: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 825/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1352e-04 - accuracy: 1.0000\n",
      "Epoch 825: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.1352e-04 - accuracy: 1.0000 - val_loss: 11.5265 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 826: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 826/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9988    \n",
      "Epoch 826: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0094 - accuracy: 0.9988 - val_loss: 8.9767 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 827: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 827/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993    \n",
      "Epoch 827: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 18.6960 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 828: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 828/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9991    \n",
      "Epoch 828: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 14.7452 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 829: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 829/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9986    \n",
      "Epoch 829: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0235 - accuracy: 0.9986 - val_loss: 19.6349 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 830: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 830/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9995    \n",
      "Epoch 830: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 13.4841 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 831: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 831/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9995    \n",
      "Epoch 831: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 18.6533 - val_accuracy: 0.9628 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 832: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 832/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9988    \n",
      "Epoch 832: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0108 - accuracy: 0.9988 - val_loss: 11.1155 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 833: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 833/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6592e-04 - accuracy: 1.0000\n",
      "Epoch 833: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.6592e-04 - accuracy: 1.0000 - val_loss: 17.9407 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 834: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 834/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9991    \n",
      "Epoch 834: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0111 - accuracy: 0.9991 - val_loss: 10.9931 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 835: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 835/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9993    \n",
      "Epoch 835: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0143 - accuracy: 0.9993 - val_loss: 15.9641 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 836: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 836/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9995    \n",
      "Epoch 836: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 9.3552 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 837: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 837/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9991    \n",
      "Epoch 837: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 12.4970 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 838: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 838/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995    \n",
      "Epoch 838: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 10.8186 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 839: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 839/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993    \n",
      "Epoch 839: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 14.1463 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 840: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 840/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9988    \n",
      "Epoch 840: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 0.0201 - accuracy: 0.9988 - val_loss: 11.3164 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 841: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 841/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9995    \n",
      "Epoch 841: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 9.4827 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 842: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 842/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9991    \n",
      "Epoch 842: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 19.4981 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 843: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 843/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9993    \n",
      "Epoch 843: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0194 - accuracy: 0.9993 - val_loss: 13.3255 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 844: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 844/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 844: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 14.7334 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 845: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 845/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995    \n",
      "Epoch 845: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 15.6013 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 846: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 846/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9991    \n",
      "Epoch 846: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 12.7562 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 847: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 847/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993    \n",
      "Epoch 847: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 9.1370 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 848: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 848/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995    \n",
      "Epoch 848: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 16.9247 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 849: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 849/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9993    \n",
      "Epoch 849: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0119 - accuracy: 0.9993 - val_loss: 12.4915 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 850: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 850/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9993    \n",
      "Epoch 850: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 13.3483 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 851: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 851/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9993    \n",
      "Epoch 851: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0184 - accuracy: 0.9993 - val_loss: 15.7035 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 852: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 852/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9991    \n",
      "Epoch 852: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0124 - accuracy: 0.9991 - val_loss: 5.2330 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 853: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 853/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 853: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 20.3435 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 854: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 854/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9988    \n",
      "Epoch 854: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0162 - accuracy: 0.9988 - val_loss: 14.8890 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 855: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 855/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993    \n",
      "Epoch 855: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 28.1187 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 856: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 856/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6346e-04 - accuracy: 1.0000\n",
      "Epoch 856: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.6346e-04 - accuracy: 1.0000 - val_loss: 5.7999 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 857: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 857/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9991    \n",
      "Epoch 857: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 17.7467 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 858: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 858/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 858: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 12.5348 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 859: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 859/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9993    \n",
      "Epoch 859: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0180 - accuracy: 0.9993 - val_loss: 7.8453 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 860: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 860/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9998    \n",
      "Epoch 860: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0095 - accuracy: 0.9998 - val_loss: 11.8619 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 861: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 861/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9998    \n",
      "Epoch 861: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 39s 286ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 10.2736 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 862: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 862/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.9999e-04 - accuracy: 0.9998\n",
      "Epoch 862: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 6.9999e-04 - accuracy: 0.9998 - val_loss: 19.1467 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 863: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 863/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9988    \n",
      "Epoch 863: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0178 - accuracy: 0.9988 - val_loss: 17.8796 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 864: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 864/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9995    \n",
      "Epoch 864: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 11.2372 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 865: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 865/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9993    \n",
      "Epoch 865: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 21.4178 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 866: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 866/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9995    \n",
      "Epoch 866: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 13.1794 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 867: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 867/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9993    \n",
      "Epoch 867: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0101 - accuracy: 0.9993 - val_loss: 10.3552 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 868: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 868/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.7842e-04 - accuracy: 0.9998\n",
      "Epoch 868: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 4.7842e-04 - accuracy: 0.9998 - val_loss: 15.1108 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 869: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 869/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9995    \n",
      "Epoch 869: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0154 - accuracy: 0.9995 - val_loss: 6.7417 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 870: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 870/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9995    \n",
      "Epoch 870: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 8.4565 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 871: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 871/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9988    \n",
      "Epoch 871: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0160 - accuracy: 0.9988 - val_loss: 13.2691 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 872: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 872/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9986    \n",
      "Epoch 872: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0225 - accuracy: 0.9986 - val_loss: 11.0145 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 873: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 873/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9995    \n",
      "Epoch 873: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 7.1132 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 874: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 874/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9991    \n",
      "Epoch 874: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 16.9211 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 875: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 875/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9998    \n",
      "Epoch 875: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 15.3093 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 876: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 876/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9995    \n",
      "Epoch 876: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 272ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 8.1429 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 877: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 877/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1342e-04 - accuracy: 1.0000\n",
      "Epoch 877: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1342e-04 - accuracy: 1.0000 - val_loss: 18.1125 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 878: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 878/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993    \n",
      "Epoch 878: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 14.7820 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 879: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 879/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9995    \n",
      "Epoch 879: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 15.1930 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 880: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 880/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9993    \n",
      "Epoch 880: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 13.7238 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 881: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 881/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993    \n",
      "Epoch 881: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 11.5923 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 882: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 882/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9991    \n",
      "Epoch 882: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 14.6511 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 883: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 883/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9988    \n",
      "Epoch 883: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0126 - accuracy: 0.9988 - val_loss: 15.0506 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 884: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 884/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5124e-04 - accuracy: 1.0000\n",
      "Epoch 884: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.5124e-04 - accuracy: 1.0000 - val_loss: 17.1735 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 885: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 885/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9991    \n",
      "Epoch 885: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 17.3638 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 886: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 886/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.5181e-04 - accuracy: 0.9998\n",
      "Epoch 886: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 6.5181e-04 - accuracy: 0.9998 - val_loss: 4.8902 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 887: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 887/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9991    \n",
      "Epoch 887: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 7.0721 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 888: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 888/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998    \n",
      "Epoch 888: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 12.6150 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 889: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 889/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 889: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 11.1948 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 890: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 890/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9993    \n",
      "Epoch 890: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 14.5652 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 891: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 891/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995    \n",
      "Epoch 891: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 17.5529 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 892: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 892/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993    \n",
      "Epoch 892: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 19.3748 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 893: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 893/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9998    \n",
      "Epoch 893: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 7.5317 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 894: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 894/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9988    \n",
      "Epoch 894: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0181 - accuracy: 0.9988 - val_loss: 15.0719 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 895: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 895/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9988    \n",
      "Epoch 895: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0215 - accuracy: 0.9988 - val_loss: 13.1993 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 896: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 896/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995    \n",
      "Epoch 896: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 39s 286ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 16.1156 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 897: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 897/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993    \n",
      "Epoch 897: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 6.5134 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 898: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 898/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9995    \n",
      "Epoch 898: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 19.1980 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 899: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 899/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9993    \n",
      "Epoch 899: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0178 - accuracy: 0.9993 - val_loss: 11.0049 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 900: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 900/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998    \n",
      "Epoch 900: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 11.5118 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 901: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 901/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995    \n",
      "Epoch 901: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 20.3332 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 902: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 902/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9991    \n",
      "Epoch 902: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 10.1711 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 903: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 903/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9049e-04 - accuracy: 1.0000\n",
      "Epoch 903: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.9049e-04 - accuracy: 1.0000 - val_loss: 14.5250 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 904: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 904/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9995    \n",
      "Epoch 904: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 16.4206 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 905: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 905/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9988    \n",
      "Epoch 905: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 19.8388 - val_accuracy: 0.9628 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 906: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 906/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9998    \n",
      "Epoch 906: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 13.2847 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 907: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 907/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9998    \n",
      "Epoch 907: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 22.6732 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 908: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 908/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995    \n",
      "Epoch 908: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 20.1153 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 909: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 909/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9991    \n",
      "Epoch 909: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0152 - accuracy: 0.9991 - val_loss: 17.5417 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 910: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 910/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9993    \n",
      "Epoch 910: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 13.5655 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 911: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 911/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9993    \n",
      "Epoch 911: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0136 - accuracy: 0.9993 - val_loss: 5.4651 - val_accuracy: 0.9705 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 912: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 912/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1531e-04 - accuracy: 1.0000\n",
      "Epoch 912: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.1531e-04 - accuracy: 1.0000 - val_loss: 11.5055 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 913: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 913/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9988    \n",
      "Epoch 913: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0108 - accuracy: 0.9988 - val_loss: 18.3246 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 914: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 914/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 914: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 11.1167 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 915: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 915/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9993    \n",
      "Epoch 915: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0189 - accuracy: 0.9993 - val_loss: 18.5399 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 916: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 916/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9995    \n",
      "Epoch 916: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 16.7446 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 917: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 917/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 917: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 18.2444 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 918: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 918/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9993    \n",
      "Epoch 918: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0146 - accuracy: 0.9993 - val_loss: 12.4292 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 919: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 919/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9991    \n",
      "Epoch 919: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 10.8873 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 920: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 920/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9995    \n",
      "Epoch 920: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 20.4248 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 921: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 921/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9993    \n",
      "Epoch 921: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0110 - accuracy: 0.9993 - val_loss: 9.4655 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 922: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 922/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9995    \n",
      "Epoch 922: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 12.3078 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 923: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 923/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9998    \n",
      "Epoch 923: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 10.5449 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 924: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 924/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 924: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 14.4397 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 925: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 925/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 925: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 10.9167 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 926: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 926/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995    \n",
      "Epoch 926: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 7.1157 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 927: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 927/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9995    \n",
      "Epoch 927: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0110 - accuracy: 0.9995 - val_loss: 16.5673 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 928: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 928/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9998    \n",
      "Epoch 928: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 20.5124 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 929: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 929/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9995    \n",
      "Epoch 929: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0099 - accuracy: 0.9995 - val_loss: 13.1979 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 930: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 930/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9988    \n",
      "Epoch 930: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0315 - accuracy: 0.9988 - val_loss: 13.0956 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 931: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 931/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998    \n",
      "Epoch 931: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 17.2277 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 932: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 932/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9988    \n",
      "Epoch 932: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0261 - accuracy: 0.9988 - val_loss: 14.4080 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 933: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 933/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9995    \n",
      "Epoch 933: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 15.0731 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 934: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 934/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9991    \n",
      "Epoch 934: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 18.7251 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 935: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 935/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9993    \n",
      "Epoch 935: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0197 - accuracy: 0.9993 - val_loss: 11.7639 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 936: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 936/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9991    \n",
      "Epoch 936: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0102 - accuracy: 0.9991 - val_loss: 14.6068 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 937: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 937/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2342e-04 - accuracy: 1.0000\n",
      "Epoch 937: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.2342e-04 - accuracy: 1.0000 - val_loss: 21.4838 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 938: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 938/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995    \n",
      "Epoch 938: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 12.6372 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 939: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 939/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9995    \n",
      "Epoch 939: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 35s 258ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 14.1596 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 940: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 940/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.0774e-04 - accuracy: 0.9998\n",
      "Epoch 940: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.0774e-04 - accuracy: 0.9998 - val_loss: 10.8716 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 941: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 941/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9993    \n",
      "Epoch 941: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 11.8515 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 942: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 942/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9991    \n",
      "Epoch 942: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 13.4634 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 943: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 943/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9998    \n",
      "Epoch 943: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 10.7172 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 944: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 944/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995    \n",
      "Epoch 944: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 18.0049 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 945: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 945/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9991    \n",
      "Epoch 945: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0111 - accuracy: 0.9991 - val_loss: 11.9880 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 946: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 946/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9993    \n",
      "Epoch 946: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0134 - accuracy: 0.9993 - val_loss: 19.0588 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 947: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 947/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9995    \n",
      "Epoch 947: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 13.4615 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 948: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 948/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9993    \n",
      "Epoch 948: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0173 - accuracy: 0.9993 - val_loss: 20.6880 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 949: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 949/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9995    \n",
      "Epoch 949: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0154 - accuracy: 0.9995 - val_loss: 20.8852 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 950: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 950/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9995    \n",
      "Epoch 950: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 17.1255 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 951: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 951/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9988    \n",
      "Epoch 951: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 10.5476 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 952: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 952/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9995    \n",
      "Epoch 952: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 18.9488 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 953: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 953/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9993    \n",
      "Epoch 953: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 14.8329 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 954: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 954/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995    \n",
      "Epoch 954: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 16.0839 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 955: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 955/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.3383e-04 - accuracy: 1.0000\n",
      "Epoch 955: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.3383e-04 - accuracy: 1.0000 - val_loss: 9.0277 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 956: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 956/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9986    \n",
      "Epoch 956: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0263 - accuracy: 0.9986 - val_loss: 16.2540 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 957: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 957/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9986    \n",
      "Epoch 957: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0200 - accuracy: 0.9986 - val_loss: 16.8371 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 958: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 958/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 958: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 17.2704 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 959: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 959/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9993    \n",
      "Epoch 959: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 14.0364 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 960: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 960/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9995    \n",
      "Epoch 960: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0127 - accuracy: 0.9995 - val_loss: 19.6623 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 961: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 961/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9998    \n",
      "Epoch 961: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 16.6378 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 962: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 962/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9993    \n",
      "Epoch 962: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 16.6610 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 963: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 963/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9993    \n",
      "Epoch 963: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 35s 257ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 13.4089 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 964: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 964/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9993    \n",
      "Epoch 964: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 35s 258ms/step - loss: 0.0188 - accuracy: 0.9993 - val_loss: 14.5329 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 965: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 965/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9995    \n",
      "Epoch 965: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 22.2759 - val_accuracy: 0.9642 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 966: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 966/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9995    \n",
      "Epoch 966: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 9.5430 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 967: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 967/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9993    \n",
      "Epoch 967: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0137 - accuracy: 0.9993 - val_loss: 3.9709 - val_accuracy: 0.9705 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 968: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 968/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9991    \n",
      "Epoch 968: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0152 - accuracy: 0.9991 - val_loss: 10.3699 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 969: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 969/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1388e-04 - accuracy: 1.0000\n",
      "Epoch 969: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1388e-04 - accuracy: 1.0000 - val_loss: 3.9035 - val_accuracy: 0.9698 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 970: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 970/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1274e-04 - accuracy: 1.0000\n",
      "Epoch 970: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.1274e-04 - accuracy: 1.0000 - val_loss: 17.0584 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 971: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 971/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9991    \n",
      "Epoch 971: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 16.6382 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 972: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 972/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4504e-04 - accuracy: 1.0000\n",
      "Epoch 972: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.4504e-04 - accuracy: 1.0000 - val_loss: 11.2387 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 973: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 973/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9991    \n",
      "Epoch 973: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0129 - accuracy: 0.9991 - val_loss: 16.6976 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 974: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 974/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993    \n",
      "Epoch 974: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 13.0445 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 975: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 975/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9993    \n",
      "Epoch 975: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0187 - accuracy: 0.9993 - val_loss: 17.6405 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 976: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 976/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9995    \n",
      "Epoch 976: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 9.1247 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 977: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 977/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995    \n",
      "Epoch 977: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 11.6389 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 978: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 978/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9988    \n",
      "Epoch 978: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 6.3191 - val_accuracy: 0.9684 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 979: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 979/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995    \n",
      "Epoch 979: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 9.4789 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 980: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 980/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9993    \n",
      "Epoch 980: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 13.3143 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 981: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 981/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9993    \n",
      "Epoch 981: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0247 - accuracy: 0.9993 - val_loss: 12.4088 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 982: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 982/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9991    \n",
      "Epoch 982: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0184 - accuracy: 0.9991 - val_loss: 20.1815 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 983: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 983/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9986    \n",
      "Epoch 983: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0177 - accuracy: 0.9986 - val_loss: 13.6763 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 984: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 984/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993    \n",
      "Epoch 984: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 13.9888 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 985: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 985/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9993    \n",
      "Epoch 985: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0106 - accuracy: 0.9993 - val_loss: 5.9141 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 986: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 986/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9995    \n",
      "Epoch 986: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0138 - accuracy: 0.9995 - val_loss: 16.4298 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 987: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 987/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9991    \n",
      "Epoch 987: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 20.3638 - val_accuracy: 0.9635 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 988: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 988/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9993    \n",
      "Epoch 988: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 16.1530 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 989: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 989/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9993    \n",
      "Epoch 989: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 17.1461 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 990: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 990/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9986    \n",
      "Epoch 990: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: 7.9715 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 991: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 991/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995    \n",
      "Epoch 991: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 17.4020 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 992: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 992/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9998    \n",
      "Epoch 992: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 4.3456 - val_accuracy: 0.9691 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 993: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 993/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9993    \n",
      "Epoch 993: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 16.1890 - val_accuracy: 0.9677 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 994: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 994/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9991    \n",
      "Epoch 994: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0182 - accuracy: 0.9991 - val_loss: 18.0633 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 995: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 995/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9993    \n",
      "Epoch 995: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 12.3589 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 996: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 996/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9991    \n",
      "Epoch 996: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0189 - accuracy: 0.9991 - val_loss: 22.3209 - val_accuracy: 0.9649 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 997: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 997/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9988    \n",
      "Epoch 997: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 17.0003 - val_accuracy: 0.9656 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 998: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 998/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9995    \n",
      "Epoch 998: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0115 - accuracy: 0.9995 - val_loss: 6.5233 - val_accuracy: 0.9663 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 999: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 999/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9991    \n",
      "Epoch 999: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0105 - accuracy: 0.9991 - val_loss: 10.9624 - val_accuracy: 0.9670 - lr: 0.0000e+00\n",
      "\n",
      "Epoch 1000: LearningRateScheduler setting learning rate to 0.0.\n",
      "Epoch 1000/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9993    \n",
      "Epoch 1000: val_accuracy did not improve from 0.97333\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 8.9389 - val_accuracy: 0.9684 - lr: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            model.name + '.keras',\n",
    "            monitor='val_accuracy',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            learning_rate_schedule,\n",
    "            verbose=1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Save history\n",
    "dataframe = pd.DataFrame(model_history.history)\n",
    "dataframe.to_csv(\"history.csv\", index_label=\"model_name\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748bb5a",
   "metadata": {
    "papermill": {
     "duration": 11.777827,
     "end_time": "2024-06-02T10:49:32.779023",
     "exception": false,
     "start_time": "2024-06-02T10:49:21.001196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testando o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51a92fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T10:49:56.333378Z",
     "iopub.status.busy": "2024-06-02T10:49:56.332903Z",
     "iopub.status.idle": "2024-06-02T10:50:24.843934Z",
     "shell.execute_reply": "2024-06-02T10:50:24.843007Z"
    },
    "papermill": {
     "duration": 40.327992,
     "end_time": "2024-06-02T10:50:24.845963",
     "exception": false,
     "start_time": "2024-06-02T10:49:44.517971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      COVID19       0.99      0.98      0.99       116\n",
      "       NORMAL       0.95      0.93      0.94       318\n",
      "    PNEUMONIA       0.97      0.98      0.98       856\n",
      "TURBERCULOSIS       0.99      0.99      0.99       140\n",
      "\n",
      "     accuracy                           0.97      1430\n",
      "    macro avg       0.98      0.97      0.97      1430\n",
      " weighted avg       0.97      0.97      0.97      1430\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGoCAYAAAC37rTiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACUC0lEQVR4nOzdd3xT5f7A8U/SNmlLF9DSAWUje8koQwERrYAVkasIKFO4CFWhTpQlXsWJoILo/TEcIIgMlXmhAipLKSAyZZfVMttCS1dyfn+EhqZN2jRNmqT9vl+vvJqc85znPCfNyfnmWUelKIqCEEIIIYSbUTu7AEIIIYQQtpAgRgghhBBuSYIYIYQQQrglCWKEEEII4ZYkiBFCCCGEW5IgRgghhBBuSYIYIYQQQrglCWKEEEII4ZYkiBFCCCGEW5IgRjiMSqVi6tSpJd7u9OnTqFQqFi5caPcyCSHcj6O/S7Zs2YJKpWLLli02lU84jwQx5dzChQtRqVSoVCp+//33QusVRSEyMhKVSsXDDz/shBIKIdyBfJcIVyRBTAXh7e3N4sWLCy3funUr586dQ6vVOqFUQgh3I98lwpVIEFNB9OrVi2XLlpGbm2uyfPHixbRp04awsDAnlaziSE9Pd3YRhCg1+S4RrkSCmApiwIABXL16lY0bNxqXZWdn88MPPzBw4ECz26Snp/Piiy8SGRmJVqulYcOGfPjhhxS88XlWVhbjx48nJCQEf39/HnnkEc6dO2c2z/PnzzN8+HBCQ0PRarU0bdqU+fPn23RM165d46WXXqJ58+b4+fkREBBAz549+euvvwqlzczMZOrUqdx11114e3sTHh7OY489xokTJ4xp9Ho9s2bNonnz5nh7exMSEsJDDz3E7t27gaLb1wu22U+dOhWVSsWhQ4cYOHAglStX5p577gFg//79DB06lLp16+Lt7U1YWBjDhw/n6tWrZt+vESNGEBERgVarpU6dOjz77LNkZ2dz8uRJVCoVH3/8caHttm/fjkql4rvvvivp2ypEkcrjd4kly5Yto02bNvj4+BAcHMxTTz3F+fPnTdIkJSUxbNgwatSogVarJTw8nD59+nD69Gljmt27dxMdHU1wcDA+Pj7UqVOH4cOH27WsFZWnswsgykbt2rXp2LEj3333HT179gRg3bp1pKam8uSTT/LJJ5+YpFcUhUceeYTNmzczYsQIWrVqxYYNG3j55Zc5f/68yYXzmWee4dtvv2XgwIF06tSJX375hd69excqQ3JyMh06dEClUhEbG0tISAjr1q1jxIgRpKWlMW7cuBId08mTJ1m1ahWPP/44derUITk5mS+++IKuXbty6NAhIiIiANDpdDz88MPEx8fz5JNP8sILL3Djxg02btzIgQMHqFevHgAjRoxg4cKF9OzZk2eeeYbc3Fx+++03du7cSdu2bUtUtjyPP/44DRo04J133jF+YW/cuJGTJ08ybNgwwsLCOHjwIF9++SUHDx5k586dqFQqAC5cuED79u1JSUlh1KhRNGrUiPPnz/PDDz+QkZFB3bp16dy5M4sWLWL8+PEm+120aBH+/v706dPHpnILYUl5/C4xZ+HChQwbNox27doxffp0kpOTmTVrFtu2bWPv3r0EBQUB0K9fPw4ePMhzzz1H7dq1uXTpEhs3biQxMdH4+sEHHyQkJITXXnuNoKAgTp8+zYoVK0pdRgEoolxbsGCBAih//vmn8tlnnyn+/v5KRkaGoiiK8vjjjyv33XefoiiKUqtWLaV3797G7VatWqUAyn/+8x+T/P71r38pKpVKOX78uKIoirJv3z4FUMaMGWOSbuDAgQqgTJkyxbhsxIgRSnh4uHLlyhWTtE8++aQSGBhoLNepU6cUQFmwYEGRx5aZmanodDqTZadOnVK0Wq0ybdo047L58+crgDJjxoxCeej1ekVRFOWXX35RAOX555+3mKaochU81ilTpiiAMmDAgEJp844zv++++04BlF9//dW4bPDgwYparVb+/PNPi2X64osvFEA5fPiwcV12drYSHBysDBkypNB2QtiqPH+XbN68WQGUzZs3K4piOIeqVaumNGvWTLl165Yx3erVqxVAmTx5sqIoinL9+nUFUD744AOLea9cudL4vgn7k+akCuSJJ57g1q1brF69mhs3brB69WqL1b9r167Fw8OD559/3mT5iy++iKIorFu3zpgOKJSu4C8hRVFYvnw5MTExKIrClStXjI/o6GhSU1PZs2dPiY5Hq9WiVhs+wjqdjqtXr+Ln50fDhg1N8lq+fDnBwcE899xzhfLIq/VYvnw5KpWKKVOmWExji9GjRxda5uPjY3yemZnJlStX6NChA4Cx3Hq9nlWrVhETE2O2FiivTE888QTe3t4sWrTIuG7Dhg1cuXKFp556yuZyC1GU8vZdUtDu3bu5dOkSY8aMwdvb27i8d+/eNGrUiDVr1gCGc1mj0bBlyxauX79uNq+8GpvVq1eTk5NTqnKJwiSIqUBCQkLo0aMHixcvZsWKFeh0Ov71r3+ZTXvmzBkiIiLw9/c3Wd64cWPj+ry/arXa2CSTp2HDhiavL1++TEpKCl9++SUhISEmj2HDhgFw6dKlEh2PXq/n448/pkGDBmi1WoKDgwkJCWH//v2kpqYa0504cYKGDRvi6Wm59fTEiRNERERQpUqVEpWhOHXq1Cm07Nq1a7zwwguEhobi4+NDSEiIMV1euS9fvkxaWhrNmjUrMv+goCBiYmJMRossWrSI6tWr0717dzseiRB3lLfvEnNlNrdvgEaNGhnXa7Va3nvvPdatW0doaChdunTh/fffJykpyZi+a9eu9OvXjzfffJPg4GD69OnDggULyMrKKlUZhYH0ialgBg4cyMiRI0lKSqJnz57GXwmOptfrAXjqqacYMmSI2TQtWrQoUZ7vvPMOkyZNYvjw4bz11ltUqVIFtVrNuHHjjPuzJ0s1MjqdzuI2+Wtd8jzxxBNs376dl19+mVatWuHn54der+ehhx6yqdyDBw9m2bJlbN++nebNm/PTTz8xZswYYy2VEI5Qnr5LSmPcuHHExMSwatUqNmzYwKRJk5g+fTq//PILrVu3RqVS8cMPP7Bz505+/vlnNmzYwPDhw/noo4/YuXMnfn5+ZVbW8kiCmAqmb9++/Pvf/2bnzp0sXbrUYrpatWqxadMmbty4YfIL6siRI8b1eX/1er2xtiPP0aNHTfLLG22g0+no0aOHXY7lhx9+4L777mPevHkmy1NSUggODja+rlevHrt27SInJwcvLy+zedWrV48NGzZw7do1i7UxlStXNuafX96vMmtcv36d+Ph43nzzTSZPnmxcfuzYMZN0ISEhBAQEcODAgWLzfOihhwgJCWHRokVERUWRkZHB008/bXWZhLBFefouMVfmvH0XrNE8evSocX2eevXq8eKLL/Liiy9y7NgxWrVqxUcffcS3335rTNOhQwc6dOjA22+/zeLFixk0aBBLlizhmWeeccgxVBTyU62C8fPz4/PPP2fq1KnExMRYTNerVy90Oh2fffaZyfKPP/4YlUplHJWQ97fgiISZM2eavPbw8KBfv34sX77c7IX58uXLJT4WDw+PQkM0ly1bVmgIZL9+/bhy5UqhYwGM2/fr1w9FUXjzzTctpgkICCA4OJhff/3VZP2cOXNKVOb8eeYp+H6p1WoeffRRfv75Z+MQb3NlAvD09GTAgAF8//33LFy4kObNm5fpL1FRMZWn75KC2rZtS7Vq1Zg7d65Js8+6des4fPiwccRURkYGmZmZJtvWq1cPf39/43bXr18vdL63atUKQJqU7EBqYiogS1Ww+cXExHDffffxxhtvcPr0aVq2bMn//vc/fvzxR8aNG2dst27VqhUDBgxgzpw5pKam0qlTJ+Lj4zl+/HihPN999102b95MVFQUI0eOpEmTJly7do09e/awadMmrl27VqLjePjhh5k2bRrDhg2jU6dO/P333yxatIi6deuapBs8eDBff/01cXFx/PHHH9x7772kp6ezadMmxowZQ58+fbjvvvt4+umn+eSTTzh27Jixaee3337jvvvuIzY2FjAMAX333Xd55plnaNu2Lb/++iv//POP1WUOCAgwtpvn5ORQvXp1/ve//3Hq1KlCad955x3+97//0bVrV0aNGkXjxo25ePEiy5Yt4/fffzepvh88eDCffPIJmzdv5r333ivR+yiErcrLd0lBXl5evPfeewwbNoyuXbsyYMAA4xDr2rVrG6c0+Oeff7j//vt54oknaNKkCZ6enqxcuZLk5GSefPJJAL766ivmzJlD3759qVevHjdu3OC///0vAQEB9OrVq1TlFMgQ6/Iu/7DIohQcFqkoinLjxg1l/PjxSkREhOLl5aU0aNBA+eCDD4zDe/PcunVLef7555WqVasqlSpVUmJiYpSzZ88WGhapKIqSnJysjB07VomMjFS8vLyUsLAw5f7771e+/PJLY5qSDLF+8cUXlfDwcMXHx0fp3LmzsmPHDqVr165K165dTdJmZGQob7zxhlKnTh3jfv/1r38pJ06cMKbJzc1VPvjgA6VRo0aKRqNRQkJClJ49eyoJCQkm+YwYMUIJDAxU/P39lSeeeEK5dOmSxSHWly9fLlTuc+fOKX379lWCgoKUwMBA5fHHH1cuXLhg9v06c+aMMnjwYCUkJETRarVK3bp1lbFjxypZWVmF8m3atKmiVquVc+fOFfm+CWGL8vxdUnCIdZ6lS5cqrVu3VrRarVKlShVl0KBBJufXlStXlLFjxyqNGjVSKlWqpAQGBipRUVHK999/b0yzZ88eZcCAAUrNmjUVrVarVKtWTXn44YeV3bt3F1kmYR2VohSo5xJCuKXWrVtTpUoV4uPjnV0UIYQoE9InRohyYPfu3ezbt4/Bgwc7uyhCCFFmpCZGCDd24MABEhIS+Oijj7hy5QonT540mZxLCCHKM6mJEcKN/fDDDwwbNoycnBy+++47CWCEEBWK1MQIIYQQwi1JTYwQQggh3JIEMUIIIYRwSzLZnY30ej0XLlzA39+/VHc5FqKiUxSFGzduEBER4dL3e5JzXgj7sdd5L0GMjS5cuEBkZKSziyFEuXH27Flq1Kjh7GJYJOe8EPZX2vNeghgb5d3I7OzZswQEBDi5NEK4r7S0NCIjI01uDuiK5JwXwn7sdd5LEGOjvOrkgIAA+UITwg5cvYlGznkh7K+0573rNkALIYQQQhRBghghhBBCuCUJYoQQQgjhlqRPjIPpdDpycnKcXQxhBxqNxqWHAAvXIOd8+eHl5YWHh4eziyGKIEGMgyiKQlJSEikpKc4uirATtVpNnTp10Gg0zi6KcEFyzpdPQUFBhIWFuXzH84pKghgHyfsyq1atGr6+vnICuLm8ic4uXrxIzZo15f8pCpFzvnxRFIWMjAwuXboEQHh4uJNLJMyRIMYBdDqd8cusatWqzi6OsJOQkBAuXLhAbm4uXl5ezi6OcCFyzpdPPj4+AFy6dIlq1apJ05ILkgZ+B8hrD/f19XVySYQ95TUj6XQ6J5dEuBo558uvvP+p9HNyTU4NYn799VdiYmKIiIhApVKxatWqYrfZsmULd999N1qtlvr167Nw4cJCaWbPnk3t2rXx9vYmKiqKP/74w2R9ZmYmY8eOpWrVqvj5+dGvXz+Sk5PtdFR3SHVy+SL/T1Ec+YyUP/I/dW1ODWLS09Np2bIls2fPtir9qVOn6N27N/fddx/79u1j3LhxPPPMM2zYsMGYZunSpcTFxTFlyhT27NlDy5YtiY6ONrZrAowfP56ff/6ZZcuWsXXrVi5cuMBjjz1m9+MTQgghhAMpLgJQVq5cWWSaV155RWnatKnJsv79+yvR0dHG1+3bt1fGjh1rfK3T6ZSIiAhl+vTpiqIoSkpKiuLl5aUsW7bMmObw4cMKoOzYscPq8qampiqAkpqaWmjdrVu3lEOHDim3bt2yOr/yqFatWsrHH3/s7GLYjfxfHaOoc8mVyDlfvPJ2ziuK/G8dxV7nvVt17N2xYwc9evQwWRYdHc24ceMAyM7OJiEhgQkTJhjXq9VqevTowY4dOwBISEggJyfHJJ9GjRpRs2ZNduzYQYcOHczuOysri6ysLOPrtLQ0ex2WkU6vkJWrQ1HgVraOlFs5VNJ4oFarSE7LpJLGk0BfL67ezCbEX4u3lxoPlQqtlwc6vUJ2rh4vDxWZuXo8VCpy9HpUwKkr6QT6eFGjsi/JaZlk5+qN2/+TfBO9olAvxA9PDxX33NuV+o2b8c57HxLkq+H01XRqVPalSiUNOr3CxdRb3MrWoQDhgd6oVSpu5ehIychBQSHA2wtPtQpvLw927NwFXt6kZmTj4aFGrYK0W7nczMqlRmVDh7nz12+hAFUrafD0UKH19CD1Vg5ZuTqq+XujVxT0isKtbB03MnNJz84lxE+Ln7cnSamZ+Gg88PHy4PKNLKr5a/HReJKj0+OhVnH5RhY5Oj01q/ji6aEmV6fnVo4OD7UKD5WKrFw9KhWkZ+m4kZVDiJ+Wa+nZqG9XH2u91GRk6wgLMJQjNzsXnV7h7LV0qlX24Pnv9nLqSjoxLcPp0iCEOsGVmLb6EI3DA+jSIISsXB3NawTy2S/HSc/S0btFOBdSbvFDwjnqhfiRnJZJgI8nVSpp2HzkMsPvqUPi1XT+dyiZib2b0CDUjwkr/qZZRACta1WmepAP2bl6Tly+SdvaVVCroGolLav3X6BJRACNwgJYseccB86noVZBrl7hRmYuL0c3JCzQG51e4cXv93E+5RZv9G6Cj5cH09cdxsfLg50nr/LREy2pWaUSr6/8G42HmptZuXSoW5W7awZx8ko6vhoPNh5K5qFmYTzRNpK31xzm1JV0Rnetx4D/7qRmFV+2vNQNtVrFuesZANSoXAH7iGRnQMZl8A8HD9cfjt+tWzdatWrFzJkzS53Xn3/+SaVKlUpfKCGs5FZBTFJSEqGhoSbLQkNDSUtL49atW1y/fh2dTmc2zZEjR4x5aDQagoKCCqVJSkqyuO/p06fz5ptv2udAClAUBYCDF1ILrcvIzjU+T882XMQB40XCWqm3cki9dSf/tEzTTmr/JN8ADIEUQMqtHFJu5Rj3lbc/RVHQ6XR4enpy6kp6of3cys7f6VULuQrcKlzWvP3lyX+cea6lZ5s9lqS0TLgdQ97MurPdmWvm35NDF60LOBMLbp9p+HPi8k0AlNxsLqVmMnXVn5y/cec4Z28+wezNJ4yvV++/yAcbjhbKf/62U8bnW/+5XGj9S8v+Mj5/at4u4/NfjlwqlLYklu85V2jZo7O3FVo2fOHuQsv2nU0ptOy3Y1d4Y+UB4+u8Y0m8lkHd19cWSr/6uXtoVj2wJEV2b1du/+9zcyC4vnPLYgf5z/nihISElEGJhLhDRidZacKECaSmphofZ8+etUu+uTo9hy/e4KSZgKCsTRo/ht07t7Fo3lxaRlamZWRlfvx+MS0jK/P75o082asbbeuFsvfPnZw9fYoXhg/kvtZ30aFhDQb27s7O37aY5NezYwu+/b/Pja9bRlZmxXdfM+6Zp4hqEEHMvW3Y8r/CFz1RvpgLmCqE3Exnl6BYQ4cOZevWrcyaNQuVSoVKpWLhwoWoVCrWrVtHmzZt0Gq1/P7775w4cYI+ffoQGhqKn58f7dq1Y9OmTSb51a5d26RGR6VS8X//93/07dsXX19fGjRowE8//VTGRynKM7eqiQkLCys0iig5OZmAgAB8fHzw8PDAw8PDbJqwsDBjHtnZ2aSkpJjUxuRPY45Wq0Wr1dpUbkVRSL6RycWUTCr7agxNI1k5eKhUeHioyM7VczOr8HZqlQr97VoaW2k91Vb3rn/lzemcOXWc+g2bMOZFQ5PciX8MNVizpr9J3MS3qFGzNgGBQSRdPMc93R8g9pWJaLRafv5hCc8PG8CPW/8gvHqkxX3M/fg9xr/+JnFvTOO7hV8y4fl/szXhIN5+gaU+1pLw8fJAATJzXGe4tKdaRa6+7N6DsrJiTCdnF8EpFEXhlpkaxrLg4+Vh1Xk/a9Ys/vnnH5o1a8a0adMAOHjwIACvvfYaH374IXXr1qVy5cqcPXuWXr168fbbb6PVavn666+JiYnh6NGj1KxZ0+I+3nzzTd5//30++OADPv30UwYNGsSZM2eoUqWKfQ5WVGhuFcR07NiRtWtNf7lv3LiRjh07AoZ5PNq0aUN8fDyPPvooYJhpNT4+ntjYWADatGmDl5cX8fHx9OvXD4CjR4+SmJhozMfertzMosM7vzgk7+Lsn/IA/t5e3MjMRacoBHh74qFWcyMzh6TUTHw1nvhoDBM4XfXywMtLg4+PDxHh4WTr9GRdMTRFxL78Oh273GfMN7ByZRo2aU7d4Erk6hXuadOc7fHrOPbnVu5pNRoPtQovDzURQT60qBFEVq4hWHhy0NOMfWYIOr1C3ZrTWDz/C66cOsRDDz1Erk7P+ZRb+Gk9uXIzmyBfQ/+a8ym3AMMXc5CvxtC3JjOX6kE+aDwNlYm3snVk5eq4fDOLXJ1CWIA3HmoVft6exj4uAOlZuWg81Hjd3i49K5e0zBx8NZ74az25kZWLh0qFgsLVm9lU89eiAJduZFFF64UuTUPf1tXpdFc4neoHG/NdtvssX/x6krlP3U39av4AZOXqeHnZfn766wIrxnTisTnbAZjWpyn/alODP05d4+5alQnwvjNx3rc7z/DdH4m0q12Fyr4a/jqXYmxOalkjkPsaVSOysi+P3V2do8k3eGftEeIeuItWkUF89L+jfPrLcQCqB/lwPuUWo7vWo3ujatSq6kuAtxc7T12lTtVKnLmWwf8OJlGzii/dG1UjR6dQSevB4YtptIwM4kjSDbzUamoH+1Kjsi97E6+z4WAy43o0wNvLgxOXbzL1p4N4eaiZ9WQr/L29uHwji3fXHeH45ZtoPdU80DiU+xqFGN+PiuZWrkKTyRuKT+gAh6ZF46sp/us9MDAQjUaDr6+v8UdcXtP7tGnTeOCBB4xpq1SpQsuWLY2v33rrLVauXMlPP/1k/H41Z+jQoQwYMACAd955h08++YQ//viDhx56yKZjEyI/pwYxN2/e5Pjx48bXp06dYt++fVSpUoWaNWsyYcIEzp8/z9dffw3A6NGj+eyzz3jllVcYPnw4v/zyC99//z1r1qwx5hEXF8eQIUNo27Yt7du3Z+bMmaSnpzNs2DDAcNKOGDGCuLg4qlSpQkBAAM899xwdO3a02Km3tMz1HSkrnh6GmpgAH9MZZv29vfD3Nl1WpZKGSlpPqvppaRjmT45O4dpxQ4DzyP33UiMiAI/bN0BMu3GDqVOmsm7dWi5evEhubi63bt0iMTGRStrCHyutpyGfzu3b4Hd7v4G1qhEQEGAc/u7poaZWVUOnwKp+d2q98j+3tMxH44GPxhDkFKVg2SppPU2WBeZ7n/K/P3W0nmRmZuLj5UFs9zp4e3ub5PN420geb2taA6X19OCTAa35ZEBrAA5Pe4ibWbmE+BvK3q1htULle6pDLZ7qUMtk2Rsr/2bL0ct8PTyKQN87ZWoUFsDXw9sbX7/4YENefLBhkcd/3+191g6uRNe7CvdfyHv/wwN9TJa3rlmZ1jUrG1/XC/HjmxFRJmlC/LV89ERLRPnQtm1bk9c3b95k6tSprFmzptA5X5QWLVoYn1eqVMnknBeitJwaxOzevZv77rvz6z4uLg6AIUOGsHDhQi5evGhygtSpU4c1a9Ywfvx4Zs2aRY0aNfi///s/oqOjjWn69+/P5cuXmTx5MklJSbRq1Yr169ebdPb9+OOPUavV9OvXj6ysLKKjo5kzZ47DjlPrqeb7f1sXIFXx1RBR2af4hFby8bJtmmyVSoXG804NRmCAvzGAAXjl5ZfZuHEjH374IfXr18fHx4d//etfZGeb74ybp+B0/SqVCr1eb1MZ3U1eoFVSb/dtjqIoMumWm/HxVHFoWnTxCR2xbxvP+/wKjjJ66aWX5JwXLsepQUy3bt2MI3PMMTcbb7du3di7d2+R+cbGxhZZvent7c3s2bOtnmSvtFQqw5Bja9QJqWQSLJQ1jUZj1bT627ZtY+jQofTt2xcw/Eo7ffq0g0tXcUkA435UKpVVTTrOJue8cGcyOsmF+Gk9nRrAgGF0wa5duzh9+jRXrlyx+IupQYMGrFixgn379vHXX38xcOBA+XUlhBuSc164MwliyoCXh/u8zS+99BIeHh40adKEkJAQi+3dM2bMoHLlynTq1ImYmBiio6O5++67y7i0QojSknNeuDOVUlR7jrAoLS2NwMBAUlNTCQgIMFmXmZnJqVOnqFOnDnh4FZrYzRI/rSd1Q/wcUVxhB/n/rwU79grbFXUuuRJrz3nva4cNC9VeENbMCSUV9iTnvWPY67x3nyoCN1VwZtw8gQVGCwkhhBCiZCSIcTBdEZOXeTq5/4sQQgjhzuQq6mCWGutUqLgr1E+aj4QQQggbuf74PzdncWSsyjC5m58bdfoVQgghXIlcQR3Mck1MYeXwtjlCOMW7776LSqVi3LhxxmWZmZmMHTuWqlWr4ufnR79+/QrdZ00I4V4kiClD1YOKnolXBooJUXp//vknX3zxhcl09wDjx4/n559/ZtmyZWzdupULFy7w2GOPOamUQgh7kCDGwfIHJlUqFX1fHwlhhCidmzdvMmjQIP773/9SufKdez2lpqYyb948ZsyYQffu3WnTpg0LFixg+/bt7Ny500GlkTNaCEeTIMbB8r7GwgK8TaaOz9+clHcnZn9v6aIkRGmMHTuW3r1706NHD5PlCQkJ5OTkmCxv1KgRNWvWZMeOHWbzysrKIi0tzeQhhHAtctV0MGNFTMFOMPle1wvx40ZmLkEyd4wQNluyZAl79uzhzz//LLQuKSkJjUZDUFCQyfLQ0FCSkpLM5jd9+nTefPNNRxRVCGEnUhNTRlRmu/IaeHmoqVJJg1rt/jf5q127NjNnzjS+VqlUrFq1ymL606dPo1Kp2LdvX6n2a698hHs6e/YsL7zwAosWLbLbrKoTJkwgNTXV+Dh79qxd8i1v5JwXziQ1MQ6WVxNTcKi1+4cr1rl48aJJ3wR7GDp0KCkpKSZflJGRkVy8eJHg4GC77ku4h4SEBC5dumRyLx+dTsevv/7KZ599xoYNG8jOziYlJcWkNiY5OZmwsDCzeWq1WrRaraOLXu7IOS/KkgQxDqbc7hVTKGixOIFM+WLpAmFvHh4eZbYv4Xruv/9+/v77b5Nlw4YNo1GjRrz66qtERkbi5eVFfHw8/fr1A+Do0aMkJibSsWNHZxS53JJzXpQlaU5ysJLME+NsX375JREREej1epPlffr0Yfjw4Zw4cYI+ffoQGhqKn58f7dq1Y9OmTUXmWbBq+Y8//qB169Z4e3vTtm1b9u7da5Jep9MxYsQI6tSpg4+PDw0bNmTWrFnG9VOnTuWrr77ixx9/RKVSoVKp2LJli9mq5a1bt9K+fXu0Wi3h4eG89tpr5ObmGtd369aN559/nldeeYUqVaoQFhbG1KlTS/7GCafz9/enWbNmJo9KlSpRtWpVmjVrRmBgICNGjCAuLo7NmzeTkJDAsGHD6NixIx06dHB28Z1Gznk5592d1MSUBUVBlZMB2bmGv4AqJxey9cVsaAdevlbX+jz++OM899xzbN68mfvvvx+Aa9eusX79etauXcvNmzfp1asXb7/9Nlqtlq+//pqYmBiOHj1KzZo1i83/5s2bPPzwwzzwwAN8++23nDp1ihdeeMEkjV6vp0aNGixbtoyqVauyfft2Ro0aRXh4OE888QQvvfQShw8fJi0tjQULFgBQpUoVLly4YJLP+fPn6dWrF0OHDuXrr7/myJEjjBw5Em9vb5Mvra+++oq4uDh27drFjh07GDp0KJ07d+aBBx6w6j0T7uPjjz9GrVbTr18/srKyiI6OZs6cOY7boaJAdrrj8i+Klee9nPNyzrs7CWIcTK8oqHJvUWVWYwCal3UBXr8AmkpWJa1cuTI9e/Zk8eLFxi+0H374geDgYO677z7UajUtW7Y0pn/rrbdYuXIlP/30E7GxscXmv3jxYvR6PfPmzcPb25umTZty7tw5nn32WWMaLy8vkxEhderUYceOHXz//fc88cQT+Pn54ePjQ1ZWVpFVyXPmzCEyMpLPPvsMlUpFo0aNuHDhAq+++iqTJ09Gffvmmy1atGDKlCkANGjQgM8++4z4+Hj5QisHtmzZYvLa29ub2bNnM3v27LIpQG4mvBNRNvsqyMrzXs55OefdnTQnCRODBg1i+fLlZGVlAbBo0SKefPJJ1Go1N2/e5KWXXqJx48YEBQXh5+fH4cOHSUxMtCrvw4cP06JFC5PRI+b6I8yePZs2bdoQEhKCn58fX375pdX7yL+vjh07mszN07lzZ27evMm5c+eMywrO6hoeHs6lS5dKtC8h3Jmc83LOuzOpiXEwBVA8fUgdd5pAXw1/n08FIMRfQ1hA0bchsAsv3xIlj4mJQVEU1qxZQ7t27fjtt9/4+OOPAXjppZfYuHEjH374IfXr18fHx4d//etfZGdn2624S5Ys4aWXXuKjjz6iY8eO+Pv788EHH7Br1y677SM/Ly/TuXlUKlWh/gFC2MTT21Aj4gwlOO/lnJdz3p1JEONgioKhbVpbCTReKF45hhVeWtCUQRBTQt7e3jz22GMsWrSI48eP07BhQ+Ow1W3btjF06FD69u0LGNq7T58+bXXejRs35ptvviEzM9P4y6zglO/btm2jU6dOjBkzxrjsxIkTJmk0Gg06na7YfS1fvhxFUYy/zLZt24a/vz81atSwusxC2Eylsrop15nknBfuTJqTHM7CEGuXHJ9kMGjQINasWcP8+fMZNGiQcXmDBg1YsWIF+/bt46+//mLgwIEl+gUzcOBAVCoVI0eO5NChQ6xdu5YPP/zQJE2DBg3YvXs3GzZs4J9//mHSpEmFZmCtXbs2+/fv5+jRo1y5coWcnJxC+xozZgxnz57lueee48iRI/z4449MmTKFuLg4Y9u4EMJAznnhruQ/62CWJrtz4RiG7t27U6VKFY4ePcrAgQONy2fMmEHlypXp1KkTMTExREdHm0wuVhw/Pz9+/vln/v77b1q3bs0bb7zBe++9Z5Lm3//+N4899hj9+/cnKiqKq1evmvxCAxg5ciQNGzakbdu2hISEsG3btkL7ql69OmvXruWPP/6gZcuWjB49mhEjRjBx4sQSvhtClH9yzgt3pVIUSzOZiKKkpaURGBhIamoqAQEBJusyMzM5deoUderUITE1h8wcHXWDK+Hn7cX+cykAhAZ4Expgn+nRRdnI/3+119T2ouhzyZVYe857XztsWKj2hLAyH48o7EzOe8ew13kvNTEOducGkC5c9SKEEEK4IQliHM58nxgJaYSoILLT4Way5em7hRA2k9FJDuaOfWKEEHZ05R/DX5UaKoU4tyxClDNSE+Ngxtak2399NYa4MdDHy2x6IUQ5lZPp7BIIUe5ITYwDKYqC/nZVTN68BfVCKqHTK3h6SPzobqQPvCiOfEbKH/mfuja5kjpA3oyQGRkZxuYk9e2qGJVKJQGMm8qbpdTDw8PJJRGuJv85b5E0IbulvP9pwZl+hWuQmhgH8PDwICgoiEuXLpHr6YfKU0NWlgZ9rgQv7kqv13P58mV8fX3x9JTTRpjKf87jpeDrBSq1ApmZkHv7l0y2zvBauAVFUcjIyODSpUsEBQXJjxcXJd/GDhIWFkauTs+pUxfx8lDhecsHtQyzdmtqtZqaNWua3GBOiDx5d1i+dOI4eGhA5QE3vSDlsiGBNhN8bjmxhMIWQUFBRd49WziXBDEOolKp8K8SQtzcv6jsrWbj+C7SjOTmNBqNTF8uLFKpVISHh1Pt/0aS410VfKvCiP/BZ48bErQYAF1edG4hRYl4eXlJDYyLc3oQM3v2bD744AOSkpJo2bIln376Ke3btzebNicnh+nTp/PVV19x/vx5GjZsyHvvvcdDDz1kTFO7dm3OnDlTaNsxY8Ywe/ZsALp168bWrVtN1v/73/9m7ty5djwyyNUrZOYqXLypw69Sye4mLYRwTx66W3iknwOywNsbbp41rNDfNLwWQtiNU39WLl26lLi4OKZMmcKePXto2bIl0dHRhnZlMyZOnMgXX3zBp59+yqFDhxg9ejR9+/Zl7969xjR//vknFy9eND42btwIwOOPP26S18iRI03Svf/++3Y/vjsjk+yetRDC5cmJL4SjOTWImTFjBiNHjmTYsGE0adKEuXPn4uvry/z5882m/+abb3j99dfp1asXdevW5dlnn6VXr1589NFHxjQhISGEhYUZH6tXr6ZevXp07drVJC9fX1+TdI64Z8udkUnyZSZExVNgaK5KmiKFsDennVXZ2dkkJCTQo0ePO4VRq+nRowc7duwwu01WVlahG3D5+Pjw+++/W9zHt99+y/Dhwwt1xly0aBHBwcE0a9aMCRMmFD008va+09LSTB7FKTi8WgghhBD247Q+MVeuXEGn0xEaGmqyPDQ0lCNHjpjdJjo6mhkzZtClSxfq1atHfHw8K1asQKfTmU2/atUqUlJSGDp0qMnygQMHUqtWLSIiIti/fz+vvvoqR48eZcWKFRbLO336dN58880SHWPBie6EEEIIYT9O79hbErNmzWLkyJE0atQIlUpFvXr1GDZsmMXmp3nz5tGzZ08iIiJMlo8aNcr4vHnz5oSHh3P//fdz4sQJ6tWrZzavCRMmEBcXZ3ydlpZGZGRkkeXNC2Is1sTcSoGcWxAQXmQ+Qgh3VODElx8zQtid05qTgoOD8fDwIDk52WR5cnKyxTH5ISEhrFq1ivT0dM6cOcORI0fw8/Ojbt26hdKeOXOGTZs28cwzzxRblqioKACOHz9uMY1WqyUgIMDkUZwi+8QoCrxXC2Y0MgQzQohypuB09RLECGFvTgtiNBoNbdq0IT4+3rhMr9cTHx9Px44di9zW29ub6tWrk5uby/Lly+nTp0+hNAsWLKBatWr07t272LLs27cPgPBw+9aIGJuTCq64fgbezxd4XTtp1/0KIYQQFYFTm5Pi4uIYMmQIbdu2pX379sycOZP09HSGDRsGwODBg6levTrTp08HYNeuXZw/f55WrVpx/vx5pk6dil6v55VXXjHJV6/Xs2DBAoYMGVJoivgTJ06wePFievXqRdWqVdm/fz/jx4+nS5cutGjRwq7Hp7dUE/O/N+DWtTuvNX523a8QwgVJc5IQdufUIKZ///5cvnyZyZMnk5SURKtWrVi/fr2xs29iYqLJDKmZmZlMnDiRkydP4ufnR69evfjmm28ICgoyyXfTpk0kJiYyfPjwQvvUaDRs2rTJGDBFRkbSr18/Jk6caPfjszhPTPpV09fXTsD/JoJ3IDz2JRxZDdnp0PJJu5ep3LiRDHu+gtZPS58i4R5kiLUQduf0jr2xsbHExsaaXbdlyxaT1127duXQoUPF5vnggw9avH16ZGRkodl6HcXYJ6Zgz151gWmsv8sXrNTpAj/dfj9q3wuB1R1XQHd0+R9Q9LB6PCRuh0M/wbPmh9iLUshOh3N/Qq17wKOYr4kbSZByFiLblU3Z3JbUxAhhb/LTwIEU4+ikYoKY/H7KF9BtnAxZN+5EQ+4gJxNys+2fb9YN0OXA7HYwJ8oQwAAk/23/fVkrOx30esfk7Yj/uy7XMBrOGkufgq/7wK8fGMqRdcNy2o8awrwecD7BPuUUQggrSRDjQHpLk92prLyh2IEfYHoNWPWsXcvlMLnZ8OFdMKuFfS/A+74zvA/bP7FfnqV1IxneiYCvH7F/3kl/3/6/j7FvvrPbwbu1rAtkTvxi+Lt7Pvz8vKE8F/YVvc2ix4teX9GkXzZ9LX1ihLA7CWIcKK9PzCP6X2DuvZB2wbDiRHwRW5nx13cwpxOc2114XdLf8HlnOLre8Hr7Z/DlfXDreilKDqRdhC+6QMJXsPwZWDbUNDD5bQb8Xw/Iunln2YKHICsVblyE3Ezr93VsI3zSGg4UmGxwxSjDfleNNryOn2Z++8xU+G93WPeaocy7F1jeV8Y1+LIb7PoCsjNg3oOw+R3rynlhr+H/8Fk7+Oguw7LTvxUo87/h+8GGWo9v+sJXj1iumbqwz5DfMcP9vVAUw/HOvcfw+q/Fhv/thb3mtwfY8AZ8/ahhf8W5dhJ0WZB80HT5pSOG/fz5f4b378//u7NO7QF7vjY8/31G0flnXM13HMPghxHuVYvoCNnp+V5IECOEvTm9T0x5lhfETNbPgSRgRmN4I8m2zC4dhMX94ZUTsPUD8A+FuwcbLhRXjsJ3/WHwj4aRT2C4EHV5GfZ8A2nnodtrhqaejZOgYS9D35uNk6FmB8Mv8xUjoVk/OLAcIlrfuXD+/PydMjwwzZBflboQf3v24t3zDfnvKnAHcF02nN4Gx/4HUf+GbbMMHZe9fCG8peHi/8Bbhv4Wa+IgJRF+GGZokmjwAPy1BPYvte69+fP/DNvlNWesHgcX/4K7n4bqbfKVKRfer2N4fmEvVAqGs7sMj0uHwScItAHgUxm6vGQIcjZOBq2/4WK0bzFkm2lW0eWAh5fh/d2/xLAs+L07tRlJf0ONNvDbR+AdBO1GGJYv7g83k2DRv2BqqqFvycGVpnknHzAEXS8eBf/b8ycdXQ8nt8CDb8GOzwzLfn4BHp1t/v35bYZpLcCG16FWJ0g9B6jg7+8Ny9e8aPoXTDujelpxB+bV46HTc3DwdkB6/TS0HgRtC3eyrxAUBzU3CiEACWIcyuyP0G2zbM8w4wqc2Ayb/2N4nXXz9oXotq/zzZez7zuIGn2nj03jGFj5b8MF9Y8v4cnvDBfAvIsgGAIYsPzLf2bzwss2TjKfdnaUoUYG4I8vzKfZOQdeOWUIYPIULJM1zNXQJCwwPKJGG4KsTi/AxX2maVaNvfP88E+m63TZkJkGf/63+P1vnGzohJ3/gv9rvruib5gA7UfdKWfdbnB+jyGAyXPtJGwoYoTcRw3hqeVwZgf89qFh2alf76zf960hiEk9b2h2S0mEak0MtVQFjyEvcLNGToF7iv04FsJaQtQoQw1SwkLT9bvnGx55zu+GGtLhF5DRSUI4gAQxDqRXFDwocF+nS4dLl+k3j955vmGC5XTXTsCn+Wohfv/YEMDkObOtdOUoTl4AU5y8mhFHyashOvxz4XW5RfQN2fqe9fvYOcfwsKRg0PDp3YXTfNK6+P1828/09aUCzULZGfBxkzuvj64tPs/i5G+WNNaMfQt+IYamL2v4Vi19OdxV/l8y0idGCLuTnwYOpCjwmVeBzqiHVpVdAW7mu6XD38tM15W0tkO4vnfKcL4cawMYAN/KDiuGEKJikyDGgfSKQk+PP51dDCGcK6i2s0vgRPnblKUmRgh7kyDGgfQVfGCGEAAEN3B2CZxHmpOEcCgJYhzI0qzBQlQogZHOLoETyXeAEI4kQYwDlbgmpssr8Ox2eD1fp9gHphmGJVtj2PoS7tDONP7Q6inbt/cOtF9ZSsrLF0Zvg6dXFp/W3Xn6wD1xjsm7fo/Cy9TyNWMgNTFC2Jt8uziQvqQ1MX7VILQpaHxh9O/w6Fzo9LzpXCeWtHoKanWEStVsK6w9hLeERz41zE9zV0/DXDT5NYguvE1svqnqG8Xcef7ANMMjZpZhmLQ5UaPhoSJGET1mxfDoak2h90fw3B4Iawb1uhcfyAxYapgLpdvr0OBBw7Jur5tPG2bmzujWBGvdXoeXTxqOP4+598+cQT+Yvu4YCw+9e+d11L+h8cOmaaJGG+YPGvtH4fy6T4QmfQovB4iMuvM8ZpZpeVs9BWOsHMpdXpk0J8nXrRD2JkOsHahUrUlhzQ0PsG6Sseq3h+36h0H6JdN1D71rmF+mUjDUvufObQwe/8ow18jV43DKxptitv83tBkC2z+Frq8YfnV3zzffyZxOd4YCD1gC61+7M29MpWoQXN8QFPyzzhCQBEQYgrn2I033U3AyPYCetwOYgAjYNNUwrDyPTxVo8YRhEr88fqGmI7bAMLFfu2dMl9Xrbvq6+0TY/z1c+Qd6fgANHzI8Cmr4kGHG2zyTrkJmiqEMJ36BkMYw5GfD8OS0i4Yya/0Nc8QUnMW526uGv22GGtKc2WE43mlVCu83NsEwwV/e7ME1O8DwDTD/dtDTdrhhgsLd8w376vaa4TMVGXVn6PeD/zFM2FfQM/FQo63h+YV9hrut55+leOhaWPeKIWBt+qjpLQ3uGVex+8MUJBUxQtidBDEOZLc+MT3fg+8SofPzcHAVHN9YOE3e9OZ9v4DvnzYEJnk6PGt4gGF22T1fQ2gzw0Wn6aOGmWPzdH0VjqyFoasNM9geWQM/PW+YaK/7JAhvZbho9ZltqPnJ09dMkAHw6BxYPsKwrVoNvd6/E8TkXTTzBwXd37DwHrxv2G9AdcOst0373lnX5BHDAwwz157+3RAs5NdvHjT/F5xLgJWjoHJtw8RwlvaX54Fp0PkFQ+1SccJbGmbeza9SsPmanYBweCzfJICrxsKxDYYZg7sXmPSuWT/DA2Dg97B+guH93/qeIf/g+objXTLIcJsAjZ/h/5SfSgWxBUbKDVkNC3tDRCvzAczdg+8EMGBIN3T17VsqPApV6hhmXH443+0IvHwMZc26AVXrF85TCCHsSKVI71ObpKWlERgYSGpqKgEBAWbT/H7sCvcsqmd9pr0+LFwDYU7iLpj/IDR/3PCL/szvMO4ABOXrQLnpTcO9bgYthwZm+imYze8J6GdFE0xpbZxsmLn4ia8tN1PYy2ftDbdlePmE4YJvrfkPQeIOGH8QAms4rnyOoijwbk1DcPvGRfDUWr/tdwMME+X9+zcIN9McZmfWnEuuwOpyTs3XXPjySfigruF590mG21kIIex23ktNjAOVuE+MtUMwa0YZpuv3qWy4N0tWmuF5fvdPNvSFqGTFbKn58ysLPd6EzuPA10zTiL09u80wdX5JOw0PWQ3ZNw21Ue5IpYKX/jF8PkoSwAD0X2RoBiuL/095l//eSTLEWgi7kyDGgTwyrzou87wLjMrDfPChUlkXwBTMryyoVGW3Pw8v8LBh1JOHp/sGMHm8fGzbTq2WAMZupKJbCEeS7vIO5HmriCBmlLmOtPJLTYhyRUYnCeFQclY5kKLXW14Z0arMyiGEcBa57YAQjiRBjCMpRQQx5kibuRDly+a3nV0CIco1CWIcSNHrzK9oO9zCBtJ+LkS5sufrO8/lR4oQdidBjCPpciyssPRlJkGMEOWXBDFC2JsEMQ6k0mdbWGHhy0xqYoQov6QmRgi7kyDGkXQWghhLv8gkiBGiHJMgRgh7kyDGgVSWmpMs1sSUsCOwEMJ9SE2MEHYnQYwDKRaDEukTI0TFI0GMEPYmQYwDqRQLo5OEEEIIUWoSxDiQxSHWUq0sRMUj570QdidBjCNZCmKkWlmICkjOeyHsTYIYB7LYJ0Z+kQkhhBClJkGMI1m8d5IEMUJUOHIDSCHsTs4qR1JyzS+XmhghKh4574WwO6cHMbNnz6Z27dp4e3sTFRXFH3/8YTFtTk4O06ZNo169enh7e9OyZUvWr19vkmbq1KmoVCqTR6NGjUzSZGZmMnbsWKpWrYqfnx/9+vUjOTnZ/gdX1F2shRBCCFEqTg1ili5dSlxcHFOmTGHPnj20bNmS6OhoLl26ZDb9xIkT+eKLL/j00085dOgQo0ePpm/fvuzdu9ckXdOmTbl48aLx8fvvv5usHz9+PD///DPLli1j69atXLhwgccee8wBR2ghiPEPd8C+hBBCiIrFqUHMjBkzGDlyJMOGDaNJkybMnTsXX19f5s+fbzb9N998w+uvv06vXr2oW7cuzz77LL169eKjjz4ySefp6UlYWJjxERwcbFyXmprKvHnzmDFjBt27d6dNmzYsWLCA7du3s3PnTvseYMHRSY/9H9w9GNqPNJ9ebjsgRPklzUlC2J3Tgpjs7GwSEhLo0aPHncKo1fTo0YMdO3aY3SYrKwtvb2+TZT4+PoVqWo4dO0ZERAR169Zl0KBBJCYmGtclJCSQk5Njst9GjRpRs2ZNi/vN23daWprJo1gFJ7trHAOPfAqe2uK3FUJY7fPPP6dFixYEBAQQEBBAx44dWbdunXF9mTUhF0mCGCHszWlBzJUrV9DpdISGhposDw0NJSkpyew20dHRzJgxg2PHjqHX69m4cSMrVqzg4sWLxjRRUVEsXLiQ9evX8/nnn3Pq1Cnuvfdebty4AUBSUhIajYagoCCr9wswffp0AgMDjY/IyMjiD7JgTYzao/hthBAlVqNGDd59910SEhLYvXs33bt3p0+fPhw8eBAoyybkIkhNjBB25/SOvSUxa9YsGjRoQKNGjdBoNMTGxjJs2DDU6juH0bNnTx5//HFatGhBdHQ0a9euJSUlhe+//75U+54wYQKpqanGx9mzZ4vfqGDHXhliKYRDxMTE0KtXLxo0aMBdd93F22+/jZ+fHzt37izbJuQiSRAjhL057aoaHByMh4dHoSrd5ORkwsLCzG4TEhLCqlWrSE9P58yZMxw5cgQ/Pz/q1q1rcT9BQUHcddddHD9+HICwsDCys7NJSUmxer8AWq3WWFWd9yhWwcnuJIgRwuF0Oh1LliwhPT2djh072tyEbHdSE+N+kg7AT89B2gVnl0RY4LSrqkajoU2bNsTHxxuX6fV64uPj6dixY5Hbent7U716dXJzc1m+fDl9+vSxmPbmzZucOHGC8HDDiKA2bdrg5eVlst+jR4+SmJhY7H5LqtANIAt+iY3YBF1etus+haio/v77b/z8/NBqtYwePZqVK1fSpEkTm5uQbeoHJ8qXuZ1hz9fwwwhnl0RY4NSqgbi4OP773//y1VdfcfjwYZ599lnS09MZNmwYAIMHD2bChAnG9Lt27WLFihWcPHmS3377jYceegi9Xs8rr7xiTPPSSy+xdetWTp8+zfbt2+nbty8eHh4MGDAAgMDAQEaMGEFcXBybN28mISGBYcOG0bFjRzp06GDfAyzuLtaR7eC+N+y7TyEqqIYNG7Jv3z527drFs88+y5AhQzh06JDN+dnUD65IUhPjti4dtE8+KYnw6weQcc0++Qk8nbnz/v37c/nyZSZPnkxSUhKtWrVi/fr1xs6+iYmJJv1dMjMzmThxIidPnsTPz49evXrxzTffmPzCOnfuHAMGDODq1auEhIRwzz33sHPnTkJCQoxpPv74Y9RqNf369SMrK4vo6GjmzJlj/wO0dO8kIYTdaTQa6tevDxhqXP/8809mzZpF//79jU3I+b8rimtCnjBhAnFxccbXaWlppQtkpDnJfdlr9ov/6wE3k+HCPnhykZ0yrdicGsQAxMbGEhsba3bdli1bTF537dq12F9WS5YsKXaf3t7ezJ49m9mzZ1tdTptYE8SYfLHJPDFC2IterycrK8ukCblfv36AdU3IWq0Wrdae0yFIEFPh3bzdB/TUr84tRzni9CCmPMvrE/NPpbbc9WzxwZUQwjYTJkygZ8+e1KxZkxs3brB48WK2bNnChg0bTJqQq1SpQkBAAM8995xjmpCLIjUx7svu/zr5LNiLBDEOpL5dE3NFU4O7/EKKSS2EsNWlS5cYPHgwFy9eJDAwkBYtWrBhwwYeeOABoAybkIskFy63JZXkLkuCGAdSYaiJUeQXmBAONW/evCLXl1kTclGc8T2QfBB0ORDRquz3LUQZkCDGkW7fC0nvXnMKCiHKA10ufN7J8Py1RPAOdG55hHAAubo6UF6fGEUltxsQQpRxTYw+587z9Ctlu29RNKmctxsJYhwor0+MIjP1CiHKvGOFXCldlvSxsRu5ujqQ6nYQI81JQgghhP3J1dWBVNyuibH2bVYkPBdC2IkMKHBd8q+xGwliHEhlbE6SPjFCCCcqrz+QTv9ueDhcOX3/ygEJYhwob4i1NCcJIco8kCivgUue7HRY2NvwyLnl7NKUUBlWxRxcBd8NhFspZbfPMiRXVweSjr1CCNdQDgOa7PQ7z90uiClDy4bA0TWw5V1nl8Qh5OrqQHlDrKUmRghR9sph4GJJea91soeM8jnMXq6ujiQ1MUIIIydeaM1d5NMuwt8/GGb0FcJNyYy9DiTNSUIIpymudmJOB8hMgZREuDeuTIokbpORY3YjV1cHyhtiLc1JQgjnMhPQZKYY/h7fVKYlsR8JBIQEMQ4ltx0QQhiVeb8NK/cn/UmK54j3KPU8ZFyzf74Wlc+gT5qTHEglN4AUQrgCCVRcy60U+LiJ4fnUVKcWxd1JEONAB8P68NXFGgT7tXJ2UYQQFY0ELvZj9z4s8r+xF6kicKCzlTvwre4Bkn3qWbmFfLCFEI5Q3r9bHHx85SEgLKediSWIEUKIMuGifWLK6cVNVAwSxAghRHlXVE1CeahlEBWWBDEOdOerQX7pCCHKmAQnogKQIEYIIcqCU4OKchjQ5G8Gk4DNCuXzx7QEMUIIUS7JhV2UfxLECCFEeSS1E6ICkCDGgeQ7RAhxh3whmHUjGda9BpePOrskwg1JEFMGrB7BKFGPEMJurP0+cfL3zoqRsOtz+KKLc8sh3JIEMUIIUd658g+kC3sNf3MzS7hhWXZUdeH3r4KTIEYIIcpCWQcSrhy45Ocu5XR35XRSQwlihBCi3JNAQZRPEsQ4kHL7i6N8xr9CCOEqyihIu3kJstPLZl/CKjYFMZs3b7Z3OYQQQjiKNNmU3s3L8GEDeL+us0si8rEpiHnooYeoV68e//nPfzh79qy9yySEEOWQ9Ikxz03Kee4Pw98Sd0B2FeWzTcCmIOb8+fPExsbyww8/ULduXaKjo/n+++/Jzs4ucV6zZ8+mdu3aeHt7ExUVxR9//GExbU5ODtOmTaNevXp4e3vTsmVL1q9fb5Jm+vTptGvXDn9/f6pVq8ajjz7K0aOm8w9069YNlUpl8hg9enSJyy6EEO7ByYFCbpZz9y/KLZuCmODgYMaPH8++ffvYtWsXd911F2PGjCEiIoLnn3+ev/76y6p8li5dSlxcHFOmTGHPnj20bNmS6OhoLl26ZDb9xIkT+eKLL/j00085dOgQo0ePpm/fvuzdu9eYZuvWrYwdO5adO3eyceNGcnJyePDBB0lPN23HHDlyJBcvXjQ+3n//fVveiiLl/RCyvlO4m/wiEUK4ASu/TxxdY7N3EfynGvy1xM4Zy/elsEPH3rvvvpsJEyYQGxvLzZs3mT9/Pm3atOHee+/l4MGDRW47Y8YMRo4cybBhw2jSpAlz587F19eX+fPnm03/zTff8Prrr9OrVy/q1q3Ls88+S69evfjoo4+MadavX8/QoUNp2rQpLVu2ZOHChSQmJpKQkGCSl6+vL2FhYcZHQEBAad8KIYSwzJnNO87c949jDH9X/ttx+3CbpjMz3LnsLsDmICYnJ4cffviBXr16UatWLTZs2MBnn31GcnIyx48fp1atWjz++OMWt8/OziYhIYEePXrcKYxaTY8ePdixY4fZbbKysvD29jZZ5uPjw++//25xP6mpqQBUqVLFZPmiRYsIDg6mWbNmTJgwgYyMjCKPNysri7S0NJOHEEK4LGsvjs6eP8TWi7hc/AXgactGzz33HN999x2KovD000/z/vvv06xZM+P6SpUq8eGHHxIREWExjytXrqDT6QgNDTVZHhoaypEjR8xuEx0dzYwZM+jSpQv16tUjPj6eFStWoNPpzKbX6/WMGzeOzp07m5Rv4MCB1KpVi4iICPbv38+rr77K0aNHWbFihcXyTp8+nTfffNPieiGEsNqNJFj7MrR7Bup2LYMd2vGCf3wTVG0AlWvZL89Sc3BAoyg4rGOsojg/kHRjNgUxhw4d4tNPP+Wxxx5Dq9WaTRMcHGz3odizZs1i5MiRNGrUCJVKRb169Rg2bJjF5qexY8dy4MCBQjU1o0aNMj5v3rw54eHh3H///Zw4cYJ69eqZzWvChAnExcUZX6elpREZGVlkeeV3ghDijnzfCKvj4OgaOPwTTE0teVY3L0Ol4GIufvn2Z69ai5Nb4dt+hue2lNuduXug4e7lt8Cm5qT4+HgGDBhgMYAB8PT0pGtXy78wgoOD8fDwIDk52WR5cnIyYWFhZrcJCQlh1apVpKenc+bMGY4cOYKfnx916xYetx8bG8vq1avZvHkzNWrUKPJ4oqKiADh+/LjFNFqtloCAAJOHtVTldGibEMJGqYm2b3t0HXxYH36MLcFGRQQxJQlwzloePVr2HBCkOYU7l935bApipk+fbrb2Y/78+bz33ntW5aHRaGjTpg3x8fHGZXq9nvj4eDp27Fjktt7e3lSvXp3c3FyWL19Onz59jOsURSE2NpaVK1fyyy+/UKdOnWLLsm/fPgDCw8OtKrsQQpROKX7YbJlu+Lvv26LT5b+w2+s66S6/x9w6qClGeT42G9gUxHzxxRc0atSo0PKmTZsyd+5cq/OJi4vjv//9L1999RWHDx/m2WefJT09nWHDhgEwePBgJkyYYEy/a9cuVqxYwcmTJ/ntt9946KGH0Ov1vPLKK8Y0Y8eO5dtvv2Xx4sX4+/uTlJREUlISt27dAuDEiRO89dZbJCQkcPr0aX766ScGDx5Mly5daNGihS1vhxBClB2Vhw0bFbjwZRYYmBD/Fqx7zZqd27Dv4tjjopwvj/QrMKsF/PIfO+TrYvR6mP8QLMo3aObXD2GLNZUH7hKBloxNfWKSkpLM1lqEhIRw8eJFq/Pp378/ly9fZvLkySQlJdGqVSvWr19v7OybmJiIWn0nzsrMzGTixImcPHkSPz8/evXqxTfffENQUJAxzeeffw4YJrTLb8GCBQwdOhSNRsOmTZuYOXMm6enpREZG0q9fPyZOnFiCd8BBJMIWovyy1/mtsva3p4Xmll/ehl/zzYuly4bfPjQ87xQLgUU0v1u97zJg6f3cNgtSEuHXD6C7C3yvF6ckn4vrp+DsTsPz3GzD/+6Xtwyv248E3yqWty2nbApiIiMj2bZtW6Gmmm3bthU5Ismc2NhYYmPNt+1u2bLF5HXXrl05dOhQkfkpxXwgIiMj2bp1a4nKaLPbZSmn/amEEM5gSyDx3ZMQ/Ta0fNI0gAG4cGeyUHQ5xezbRb/MTJrO9M4rR1lSqUCf7/+lK/mM+eWBTUHMyJEjGTduHDk5OXTv3h0wdPZ95ZVXePHFF+1awArFVb8ghBCuQ21lc1L+C3vGFcNkcy2fNJfwztNiv4Mc8B3lNjXQjvp+dpfjd002BTEvv/wyV69eZcyYMcb7JXl7e/Pqq6+a9GERQghhRml+sDiySae4vF3qh5Zi4XkFUTD4Ky4YdKV/nR3ZFMSoVCree+89Jk2axOHDh/Hx8aFBgwZFDrkWQghRjP3fQ/BdENHK8FpRDI98fQNt6hNjNSfUxFR0NtdEVcDAzYxShfR+fn60a9eOZs2aSQBjRt5HzPr7P8qHUohy68qxotef+hVWjIQv882v9c2jMLu9aV8VR9aG6HPh1nXL6x2ybzvcdqC4705FgSWD4Mextu2rYBm/6Qs7ZtuYl53I9QKwsSYGYPfu3Xz//fckJiYam5TyFDV9vxBCVEh/fAG93re8/tLhwstObjH8TdoP6VchYaHhrzVsucjNjgJdFrx4FPzNTTrqpjUxV0/AkdWG5zGfmtZsmZN8CLR+psvyB3AnfjE8OtoaFNmDnYOYnFtw/QxUKzx9iiuzqSZmyZIldOrUicOHD7Ny5UpycnI4ePAgv/zyC4GBgfYuoxBClDPmgoFiAoTFjxtuVXDpoENKBBgCGDBcoM1xpSHWJoqriTF/fz2zbl6CzzvCzOalK5LVShCM5A+k7F0T89/7YU4UHNto33wdzKZP5DvvvMPHH3/Mzz//jEajYdasWRw5coQnnniCmjVr2ruMQghRPqRdKH4Ys92U4iJn6QLpqh1788przYU95UzR669avv1MIbnZcPp3w98yZ+cgJi84/muJffN1MJuCmBMnTtC7d2/AcPuA9PR0VCoV48eP58svv7RrAYUQ5dvixYtNXr/yyisEBQXRqVMnzpwp5oLjbmY0hv/rYX6dSwUIluQrY3KBGiG93rn9NJY+BXPvNfTrybPi34bJ7/L7pJX99rn2JVjYG9aMtz0PW9+zEm9n5efLmnl2sm7A0fWQm2W6/PweWDUG0qyf9La0bApiKleuzI0bNwCoXr06Bw4cACAlJYWMjAz7lc7N5X3GVG7x5SSEc3z00UfG5zt27GD27Nm8//77BAcHM358KS4OrurivrIJWBwRUOQv94p/33mu18EXXQwdkUvKLuVU4PDPkPw3nE+4s3j/Etg42bos0i7Cic1FlMfM/2zPV4a/ewvcxyonE66UoEYnz0/PweedCwcHZsugmC9TaVkTxCwZBN/1L/ze/vc+2LcIfhxj/3JZYFPH3i5durBx40aaN2/O448/zgsvvMAvv/zCxo0buf/+++1dRiFEOXb+/Hnj81WrVtGvXz9GjRpF586dC90+pOJylR9C+cqRf4bYy0cMAURZshRs2BoUzbjdofUeOwTO/3c/JB+Ap1dBvfuKSZyvvHu+Nvz9ZwM0eaSYzRxV62VFvqduz3q/52voaea+TZf/sW+RimBTTcxnn33Gk08aZn584403iIuLIzk5mX79+jFv3jy7FlAIUb5VqlTJ+Px///sfDzzwAGCYQDPvxq3CFqW4yN24AL/PhIxrpstdqVb5Ur5b0Fz8y375nthceFlJA4ZkQ+sE+5faWAhr9lcwjZ2CGnvVjJWREtfE5Obmsnr1aqKjowFQq9W89po1dz8VxZNx/6Liue+++1i2bBmxsbH8888/9OrVC4CDBw9Su3Zt5xauLNkjQMjOMMyF0jgGqrexPZ+8O0Cf2QaDlt1ZbqmMpbrw2bCtosCif915vXzkneelfR/1JRjJVCxby2Jhu9KMTrL2fXGze0+VuCbG09OT0aNHk5mZ6YjylCuKBCVCFOvDDw13UL569SrLly+natWqACQkJDBgwABnFs2BrLig2BIY7JgNB1fAD8NKvq05xzcVWOCgcpfE+gkw/yHTZfk785a26c3ccGxH1kCZe7+Wj7BmQ7sXxW7KsIO3TX1i2rdvz759+6hVq5a9yyOEqGCCgoIA+O677wgICDAuf/PNN51UojJwYY+ZhXa4UKZfzvfCwR17nXXvop1zil5vNuAowXtrribG1ouyrcGPNXekVpSS5a/Xw60U8AkqJt8CNTF/LTFs12G09fty5eYkgDFjxhAXF8fZs2dp06aNSZs2QIsWLexSOCFE+bdpk+mv/dmzZ/Pf//6XJk2aMHv2bCpXruykkpWxghek0v6aXfJU6bY3y4rmjJJeXF2NpYnxHHZMJfk/l6IM+741PJ7bA1XrFVGcAkHMytuj0Br2hMoFKy6c/3+2KYjJ69T7/PPPG5epVCoURUGlUqHT2bNNUQhRnk2aNMn4/O+//+bFF18kLi6OzZs3ExcXx4IFC5xYOmfKd3Gz5QJql9FCBfbrkD4xTqLXgdrDzPLcwstsVoqLfE4meHlbXq8ooLLhfT+wHLq+UnS+5mSllXxfZcCmIObUqVP2Lke5dGeeGCs3qN7WYWURwlXln9Bu+fLlPPzww7zzzjvs2bPH2Mm3YrBDTYy9awsK5mfVbQdul3vdq9alz3+c6VegUrDVxTPPzHtQsHZh7SuGZpKxuyAg3HSd3kLHVpv+H1aksZTv131gxIaiNix5eaxih3xdvU+M9IWxs+f3Gu5wW+deZ5dEiDLn5eVlfL5p0yYGDx4MQJUqVUhLc81ffy4p5azlex7ZjaWrcoGLVvoV2DW35Nmvfw36/V/Jt8vPXCBXMIj54wvD352zocc00xtCmmtO0uca7l1Vls7uLHq9ojgmWMj/XuXPPycTLuyF8FbWZGLvUllkUxDz9ddfF7k+70tIWKlKXcNDiAqoY8eOrFu3jvfff58//viDpUsNc2v8888/1KhRw8mlK0OFLr4lvBDMbGa3olhksWNv/sWKdR1TzUk9Z9t2xd4A0kLtyvFf4M958Mind5aZa07S23q/K3v3GbFDZ+riAh9LQczix+HWdXgsX5DpAn2fbApiXnjhBZPXOTk5ZGRkoNFo8PX1lSBGCGG1Dz74gHXr1vHjjz/y+eefU716dQDWrVvHQw89VMzW5Zgr9jMpSXNSWTIJUszVxFjop5l308P8Q5rt2ifGGsW8Xye3GJq+HppeYDMHvc+KhUDp1nXD3/1LLKS1lIdj2RTEXL9+vdCyY8eO8eyzz/Lyyy+XulBCiIojMjISgG3btpkMsf7444+dVSTn2PWFs0tgRsGAwMLopIIXrTK7qaG1+ZZgAjebJruzYnI6W33dx/DXywc6PZ9vhZ3e84Ly3qukA4b7URVUKcSaTOxTFivYdNsBcxo0aMC7775bqJamIsv7N6pcYBiaEK7uxx9/5D//+Q//+c9/WLlyZYlGOU6fPp127drh7+9PtWrVePTRRzl69KhJmszMTMaOHUvVqlXx8/OjX79+JCcn2/swbJd/Gn3AJSYzK9SxN38QU0QH2MQdJdhJGRynpc665tgyY63FGio7Tg6YkojJe2XPPjHpV+88v3UdZneAuZ1h67tmEps5ptws+LOUfZlsZLcgBgyz+V64cMGeWQohyrkTJ04AMHr0aFasWMGKFSt46qmnaNq0qXFdcbZu3crYsWPZuXMnGzduJCcnhwcffJD09HRjmvHjx/Pzzz+zbNkytm7dyoULF3jsscccckx24YrNSVgKYgqU1dKMs6vK4O7GZjv2lqB2xZaaGEtBjD37jBT6PFjx+bh+pvg0AB/k65OZtB8uHy6qIHee5h3fhtdhzYv5krh4c9JPP/1k8lpRFC5evMhnn31G586d7VIwIUTF8OqrrwKm90q6evUqTz31FM8//zxr1qwpNo/169ebvF64cCHVqlUjISGBLl26kJqayrx581i8eDHdu3cHYMGCBTRu3JidO3fSoUMH+x2QT+U7/QdcTdbN0m1v1b17iriA7VsEXV81M2mamfxNslQg7TwEWtPR24rRSUWxa02MVTs03A362EYrkhZswismWLh8pBTlsqIMAGe2m6mFcfEg5tFHHzV5rVKpCAkJoXv37nz00Uf2KJcQooLYtm0bYBhSnadq1aq8++67Nv8oSk1NNckzISGBnJwcevToYUzTqFEjatasyY4dO8wGMVlZWWRlZRlfWz3cu2p9OPenTeU2lf9CYKdf9CtGFp+mSBZqYkryy1tXYKRPUX1r8qx9yXChjPnE+v2Y7KMkgYkt88GUojkJ4KfnrNiHLaPXzO2/tAFGge1tGUpvRzYFMfqStC9WYCWe7E6ICkij0ZCRkVFo+c2bN9FoNCXOT6/XM27cODp37kyzZoZhx0lJSWg0GuN9mvKEhoaSlJRkNp/p06fbdv8mu3WwdMCv2aNrS7iBDX1iFvQs4T6skPdLP35a8WnNfeGWpInIpkntLAQxV48Xv+0Wc/1OLMhftg2vQ+8ZxZTLARcfa96fMmxOsmufGCGEKKm8YdS7d+9GURQURWHnzp2MHj2aRx55pMT5jR07lgMHDrBkyZLiExdhwoQJpKamGh9nz54tVX5uqciLoIUL1fkEhxQFMH+bAGv8/X0JEtsxiDn9GyTuKnrb4m5omadgYHDox8LDoXU5hkkP7xTMurxLIjt/k6TKwj5cPIjp168f7733XqHl77//Po8/XsazGgoh3Fred0mPHj3w9vbG29ubTp06Ub9+fWbOnFmivGJjY1m9ejWbN282mSgvLCyM7OxsUlJSTNInJycTFhZmNi+tVktAQIDJo2y5YsfefPJfQM0NxbW8oe37VNkYxOwpeoJWE7bUIqiLuJQeXFHy/CwqomyKAgsfNkx6ePp3w8SBtk46WBST2jznf0Ztak769ddfmTp1aqHlPXv2lD4xQogSyWviSUhI4Nw5w4ytjRs3pn79+lbnoSgKzz33HCtXrmTLli3UqVPHZH2bNm3w8vIiPj6efv36AXD06FESExPp2LGjfQ7E3vJfTK1plihr2TfhRhL4h8HvxTRrWK2Yi2JZtM2XZCRTHnURl9LcTPjqEcudma2lUhUOsDZMMH2dd6uCtS+bGbJvRnYGXNxXunI5mU1BjKW2ai8vL7nXiRnSJUYIU3Fxccbn2dmGX4vz5s0zfq9s3rzZuH7GjOIvkGPHjmXx4sX8+OOP+Pv7G/u5BAYG4uPjQ2BgICNGjCAuLo4qVaoQEBDAc889R8eOHe07Msmu8l2wLA1Zdqbsm/BRQ3jZumHwRrYMFc5jzSig07+VqDiF2FITk3UD/v4BGvU2TEqXX+Iuw5Dl0t432Vy5/l6WP8Gdp9YEMACLnyj9+2WOqw+xbt68OUuXLmXy5Mkmy5csWUKTJk3sUrDyQHGBqjYhXNHevXuNz/Mmtdu/fz8eHqbNBSorf3l//vnnAHTr1s1k+YIFCxg6dChgmAFYrVbTr18/srKyiI6OZs4cK/sjlEh5Ou+teP+T9pfd/lx1lIQu2xBoth0OnQtM+Jp7y447svMdpksdwFh5Q1AHsimImTRpEo899hgnTpwwzrkQHx/Pd999x7Jly4rZWghR0eWvaUlLSyMwMJDVq1fb3O9EseKXn7e3N7Nnz2b27Nk27aPMucJkd9YEDV6VHF8Oo7IIYkrxvu//HmrfY7os1479Uor6TLjC58UJbOrYGxMTw6pVqzh+/DhjxozhxRdf5Ny5c2zatKnQHDLFmT17NrVr18bb25uoqCj++OMPi2lzcnKYNm0a9erVw9vbm5YtWxaa5MqaPF1++nEhhHCFGp2cjMLzuhRUsPnEkVy1JiaPPtfQzyQ/e018WOyxu8DnJU8ZFsXmIda9e/dm27ZtpKenc+XKFX755Re6du1aojyWLl1KXFwcU6ZMYc+ePbRs2ZLo6GguXbpkNv3EiRP54osv+PTTTzl06BCjR4+mb9++JlXT1uTpdtOPCyGEs2x51zAZ228WBm14akuYYVFXuHzrcjIL12KUambcMqDPhZwCzUf2ak6yZobesmYxsHLxIdZ//vknu3YVHvu+a9cudu/ebXU+M2bMYOTIkQwbNowmTZowd+5cfH19mT9/vtn033zzDa+//jq9evWibt26PPvss/Tq1ctkRFRxeeZNPz5jxgy6d+9OmzZtWLBgAdu3b2fnzp0lfCeKIZPdCVHxuPJkd7b47UPDEGVLE82VtJzW3PE6NwvejYSPm5oud4cgJvuG4/Iv6r2+VtqewzZwgc+oTZ+IsWPHmp346fz584wdO9aqPLKzs0lISDCZBlytVtOjRw927DB/B9SsrCy8vb1Nlvn4+PD7779bnWdx048LIUSZSj0H+74zs8L5FwjrOKCcF/YaOsumm6+Vd2kpic7Z75Vjztmv2RtuunjH3kOHDnH33XcXWt66dWsOHbJuaNeVK1fQ6XSEhoaaLA8NDeXIEfM3rYqOjmbGjBl06dKFevXqER8fz4oVK4yjG6zJ05bpx6EU91ERQoiifNYectKLT1eRzI++8zz/BdHVa2IAEhY6MPMiggOrq/zLIsBw8eYkrVZrtiPsxYsX8fS0KS6yyqxZs2jQoAGNGjVCo9EQGxvLsGHDUBc1W6KdTJ8+ncDAQOMjMjLS4fsUQlQA5gIYRXGJqnqrOLqcSwbeee4OQYwj2eu9Tr9in3xcoK+ETZ+IBx980HhfkTwpKSm8/vrrPPDAA1blERwcjIeHR6FgqKhpwENCQli1ahXp6emcOXOGI0eO4OfnR926da3O05bpx6F091Gxdq4LIYQA3CeAAUr+q7uYye4K3qzRZJp7+S4ttV1z4YN68PvHjtuHq98A8sMPP+Ts2bPUqlWL++67j/vuu486deqQlJRk9W0HNBoNbdq0IT4+3rhMr9cTHx9f7DTg3t7eVK9endzcXJYvX06fPn2szjP/9ON5rJl+3Jb7qLjT15AQwl7sceaX45qY4tJv/9Tyugr/g9AOn4nM25UPm6aWPi9LyrB51Ka2n+rVq7N//34WLVrEX3/9hY+PD8OGDWPAgAF4eXlZnU9cXBxDhgyhbdu2tG/fnpkzZ5Kens6wYcMAGDx4MNWrV2f69OmAYfTT+fPnadWqFefPn2fq1Kno9XpeeeUVq/N0z+nHhRAViqsGMGbLVdqamAL57zY/OtWgggcxKRXwTurFsLkDS6VKlbjnnnuoWbOm8d4n69atA+CRRx6xKo/+/ftz+fJlJk+eTFJSEq1atWL9+vXGjrmJiYkm/V0yMzOZOHEiJ0+exM/Pj169evHNN9+YdNItLk8oy+nHhRDCBjkZ1t2BWFHgzHao1tjxZQJY8Uzp81D0d54f31RwpfXbVkTLi3j/L5sfEONQWWlwcGXZ7zcfm4KYkydP0rdvX/7++29UKhWKopj0+8gbLWSN2NhYYmNjza7bsmWLyeuuXbtaNfqpqDyh7Kcfr+C/HYQQJfXhXdYFMQdXwg/DoFKI48tkia3NSXodfNuvwDo9RdfUVPAgpqhmmj//r+zK4UJs6hPzwgsvUKdOHS5duoSvry8HDhxg69attG3btlDgUZFZcz8XIUQ5Y4/zPvcWKFb8GPzB0ExO+uXS79NWiSWcXysvECnYgRduj8oqcuOS7cvd5Z8/KDfTeeVwYTbVxOzYsYNffvmF4OBg1Go1Hh4e3HPPPUyfPp3nn3/e5DYAQgghyrF1rxSfxoRS4K+waNXoO8/1uc4rhwuzqSZGp9Ph7+8PGIY1X7hwAYBatWpx9OhR+5VOCCFE+ZJXE2OuxqrY5qQKHPicLXyrH2FjENOsWTP++usvAKKionj//ffZtm0b06ZNM87ZIvKRTjFCCGFwciv8MMJ8E9jFfcX0e6nAQYwwy6bmpIkTJ5KebuhgNG3aNB5++GHuvfdeqlatytKlS+1aQHdWkX80CCGEWfFvGv5a6uORdt7ythW9Y68oxKYgJjr6zn0t6tevz5EjR7h27RqVK1eW2WmFEBWc/Hqxii13XZZfhqIAu93oqEqVKvbKSgghRHlnzeirwhvZvRjCvVXwu2kJIYRwCnNDrIsjNTGiAAliyoBKevYKIYQpW2piUs7YvxzCrUkQ40Dym0GICkhqC6xjS02MEAVIECOEEKLsSRAj7ECCGCGEEGXPpo69QpiSIKYMyKhzIYQoQGpihB1IEONA0jQuhBAWyL2AhB1IECOEEPai10HSfmeXwj1Ic5KwAwlihBDCXqSJxHp6uYWAKD0JYsqAdIkRooJQyVeq1bJvOLsEohyQM04IIexFghghypSccQ6kyHR3QlQsMhRRiDIlQYwQQtiLuSAmqGbZl0OICkKCGCGEcCRpYhLCYeTsKgNSwyxERSZfAEI4igQxDiST3QkhhBCOI0GMEEI4klTFCuEwEsQIIYQQwi1JEFMGVNImLoQQQtidBDFCCOFQ8iNGCEeRIEYIIRxJ+sQI4TASxAghhBDCLUkQUwbkh5gQQghhfxLECCGEQ8mvGCEcRYIYB1JktjshhBDCYSSIEUIIR5L2ZCEcxulBzOzZs6lduzbe3t5ERUXxxx9/FJl+5syZNGzYEB8fHyIjIxk/fjyZmZnG9bVr10alUhV6jB071pimW7duhdaPHj3aYccohBBCCPvzdObOly5dSlxcHHPnziUqKoqZM2cSHR3N0aNHqVatWqH0ixcv5rXXXmP+/Pl06tSJf/75h6FDh6JSqZgxYwYAf/75JzqdzrjNgQMHeOCBB3j88cdN8ho5ciTTpk0zvvb19XXQUUqLuBBCCOEITg1iZsyYwciRIxk2bBgAc+fOZc2aNcyfP5/XXnutUPrt27fTuXNnBg4cCBhqXQYMGMCuXbuMaUJCQky2effdd6lXrx5du3Y1We7r60tYWJi9D8mE9IgRQsjPGCEcx2nNSdnZ2SQkJNCjR487hVGr6dGjBzt27DC7TadOnUhISDA2OZ08eZK1a9fSq1cvi/v49ttvGT58OKoC7dKLFi0iODiYZs2aMWHCBDIyMoosb1ZWFmlpaSYPIYQQQjiP02pirly5gk6nIzQ01GR5aGgoR44cMbvNwIEDuXLlCvfccw+KopCbm8vo0aN5/fXXzaZftWoVKSkpDB06tFA+tWrVIiIigv379/Pqq69y9OhRVqxYYbG806dP58033yzZQQohhHTsFcJhnNqcVFJbtmzhnXfeYc6cOURFRXH8+HFeeOEF3nrrLSZNmlQo/bx58+jZsycREREmy0eNGmV83rx5c8LDw7n//vs5ceIE9erVM7vvCRMmEBcXZ3ydlpZGZGSkdQWXLzEhKjA5/0UFU6dr8WnsxGlBTHBwMB4eHiQnJ5ssT05OtthXZdKkSTz99NM888wzgCEASU9PZ9SoUbzxxhuo1Xdax86cOcOmTZuKrF3JExUVBcDx48ctBjFarRatVmvVsQkhxB3SO044SJNH4dAqZ5eiMFXZ9VRxWp8YjUZDmzZtiI+PNy7T6/XEx8fTsWNHs9tkZGSYBCoAHh4eQOGJ5RYsWEC1atXo3bt3sWXZt28fAOHh4SU5hGLJXHdCCKmJEQ5Tpa6zS+B0Tm1OiouLY8iQIbRt25b27dszc+ZM0tPTjaOVBg8eTPXq1Zk+fToAMTExzJgxg9atWxubkyZNmkRMTIwxmAFDMLRgwQKGDBmCp6fpIZ44cYLFixfTq1cvqlatyv79+xk/fjxdunShRYsWZXfwQoiKQZqTRZ7IKDi7q/h01nLZz1bZ/YJ3ahDTv39/Ll++zOTJk0lKSqJVq1asX7/e2Nk3MTHRpOZl4sSJqFQqJk6cyPnz5wkJCSEmJoa3337bJN9NmzaRmJjI8OHDC+1To9GwadMmY8AUGRlJv379mDhxosOO01U/ZkIIBxixCc79ARvMDzgQFVhke/sGMa56dSnDZgind+yNjY0lNjbW7LotW7aYvPb09GTKlClMmTKlyDwffPBBi/ctioyMZOvWrTaVVQghihXZzvAwBjEueqER7q8samLCW8LFvxy/Hxs5/bYD5ZkiHfqEEEIY2TvoKIMgRq8rPk0hZXftkyBGCCGEcEdlUROjyyn5NmXYnCRBjBBCOJLLdr4UZc7un4WyqInJLfk2Ny/ZvxwWSBBTBuQ7TAghXFzXV+Gp5c4uRcmUxcVFsaE56cpRG5uhSk6CGAeSeWKEqMA63h6wcP9k55ZDWCewBlSt7+CduGFNTMPi51ozKzfTvuWwQIIYIYRwhOi34Y0kqNHO2SWpmB58u/g0JlS43UiysqiJufdF27ZT9PYthwUSxAghhKN4+Ti7BBVXWLOSpVepHB8UuGOfGE+NYe4jjV/JtiujpggJYsqAyt2ieyHc0K+//kpMTAwRERGoVCpWrVplsl5RFCZPnkx4eDg+Pj706NGDY8eOOb5g0inOSUr6vttYE6MNhEArbwZsb2Xy0VIZ5j168UjJNrOlL40NJIgRQpQL6enptGzZktmzZ5td//777/PJJ58wd+5cdu3aRaVKlYiOjiYzs2za7kUZsyV4tGWbl/6B8Qfg379as4OS51+m+Znbxe19aP1Ltl0Zdex1+oy95Zn06xWi7PTs2ZOePXuaXacoCjNnzmTixIn06dMHgK+//prQ0FBWrVrFk08+6cCSlfJCU6cLnLLmAmlBywFw6EfIyShdOdxNSe+krLKxJibvIh/esuTblpYr1/LJ6CQhhLCPU6dOkZSURI8ePYzLAgMDiYqKYseOHWa3ycrKIi0tzeRhk9JeaFoNAt+qtm//6Ofw8onSlcEtqUreKdWm/1UJtnHHPjG27sOW+WVsIEFMGXDlYFmIiiApKQnAeHPZPKGhocZ1BU2fPp3AwEDjIzLSSf0eUJWuk6RKBZ5a+xXH0bQB9slHpYKgmiXZgFLVxFi9Dzuy58XFUr8eW/chfWKEEMJ5JkyYQGpqqvFx9uxZG3NyhV8xrlAGK71y0k4ZlfCYbR6dZIeaGE0J+5t4+kDfL0u277ImzUnuTya7E8I1hIWFAZCcnGyyPDk52biuIK1WS0BAgMnDJqX9taxSUeoedu5UHawuQVfNMTuLyMejhDt24jwxr54qWfrXz0PL/mX0f7W1OUmCGCGEsIs6deoQFhZGfHy8cVlaWhq7du2iY8eOTizZbR5FNfcUuIiovUqev70udv4R9snHXorqK2RLx96SbpO3nfWJzS/2KOH/tMQBmjUslM3Fm5NkdJIQoly4efMmx48fN74+deoU+/bto0qVKtSsWZNx48bxn//8hwYNGlCnTh0mTZpEREQEjz76qINLZsVFoKiLp6pAn5g3LsJbwaUvli3K4pd/SfZR5Pvm6IDEBXgH2S+v/IfuGwwZV8ysKAGpiSk/3Oy0EMIt7d69m9atW9O6dWsA4uLiaN26NZMnG+5d9Morr/Dcc88xatQo2rVrx82bN1m/fj3e3t6OLZg1F8Zif1nnC2JK+qvdkme327CRq32bFVGeEgcxJayJqdcdmvY1/d/5hxezCzu/fy0HmF/+2H+hQXQJM8tXtqh/21wkozIanSQ1MUKIcqFbt24oRXREU6lUTJs2jWnTppVhqazlhODA08HBW1koKihQe5S8Y2JJgpinV5Zue3vw1BiGkf/2kenyFk9ArU7wcVMbM873vuZ/j7UBkGXlVAMyOqk8kJ69Qgg7NCcVNGi57cXJ41et5NtYW5PQ3g6/5K1RZHlsGJ1U6r4mxe2zDILV+rfnQgqsUbLaGJWFwCV/mYeuNky+ePfg4vOT5iQhhCgHrLnwF3cxLvh7qEEPGL7BfPJa9xS9r94zIDah5NPI55XFGr3eL3p9SOOi1/ebZ2VxStknpteHBbaxEMSENbeuPM6Qv7Yp7ggM/P7Oa1s7HVvaLrwlDPkZIu4uPruAsukELkFMGXC3vmJCiDJW7AXXXK2uhS8W3ypFZxVUC4LrW1OqwirZqUNxcTUezf9lXT5FvW/W1Kq0H5kvryJqYup2gzG7rChPMV/2tl4MQosIou66XduiDYCAcDuNXLIioCmOBDFCCFEelLImxtI6m38dlaKZu9//FV4WUN26bbtPvPPcbr/s8uVTtUGBVWpo1q+E2VkIABQFqjUqWV728uB/iu7MXbOD4eaT4/aXbj8mzUn5QwPX/hUuQYwDyWR3QgjrmpOK+iou5W0H7KlqPfvkU5IJ7YqS/32rWr/wOu8ACKhhbWaO6RMTNbro9dYo7rYR4S3Bp7J15bHIQu2L2c+vi3wekSBGCCGcz1INABQRBFlRQ3NPnM1Fsp6VF0qvSvk2sdNkbSo19F8Ete+F3h8VXgfWByY233agGD3fM91HSSkKPDwTKlWDFv3hxX/sVjQTljrzujgZYl0GVNIpRogKrLQde0uxTY8phZc5q1anzVA4uhbueggO/WifPFUqaPyw4VFQXvASGQUpZ6zJzA7lKW59EQke+y/8/jFcOlRgxe2mrJf+KbsOlsXWxLgOqYkRQghHsuoiUNxQ4ZIEHi560dH4Gobodoq137T5xTXDAfT6wMq8HPC+tRpUYB9mjju0meFviydgzI7C6/OCTkcFuncS53taTGjgKs2bSE2MEEI4ljVDfW26aLhosGINu02Xb8WMvT427qvvF7D2ZcPkbneVdPZboP+3d+ZsyZM/eGs30jDMvd2IAhva4YafpeY+ny2piXEgFwpWhRBO44DJ7qzMttj8hqyGECeMuol+2z75lHaItWlmpi8VxTDiZ9QWwwRvJdU4Brx8CuwiX5kCwg3NfYEFOh6P/h2aPpa/ICXfty0sjk4yx3UubhLECCGEI1kKQp74pvg0hpXY5aJx9xCo3sYw50meOvfC2F0w+Vrhid+sZUszh73mEClyaHoJL28aX9PXit4w4ieidUkKVPRqawKrsGbw+IJ85SirgMF9+sHkJ81JQgjhSJYuCE0esX773jNg1Wjo+qrt+3vkE8vbqD0M843YwqaLrJ0ukkVdbM0OOTbjgWmQdADqdjddrujtWx4o+3srlURJRie5UDODBDFCCOFs+S8KvsHw6Oew+PE7y1oNMPTLMJmN186/lqs1Mcw3cvEv++ZrjrmLfbuREFTTTvl7WH+3784vWFjhgAu1TUGMEwIGqYkRAIoLtRsKIVxY/jv+PrMJqtTJt/L2BaXg7QTsfaFRe8CorfBmUMm2s1c5etvYnGVOUfeFCmsOSX8Xn4eHxoYdl6A5qUxqM2wcneQdaPeSOIoL120JIUQ55FsV/jXfdFlRTRdl+au4zPbloP08OtdwAR7wnenyMbsME/+9dBxaF3MH5m4TDJPnNe1r//LZMsmfI4Kd4m6wGXwXdH2t8ASCLsjpQczs2bOpXbs23t7eREVF8ccffxSZfubMmTRs2BAfHx8iIyMZP348mZmZxvVTp05FpVKZPBo1Mu19n5mZydixY6latSp+fn7069eP5ORkhxwfuFXNnBDC0To9X/iePvp8NTGFvjBKOGOvOwyPddSXYqsB8MppqNXJdHm1RoaRQH4hxe+722uG+WyKm+rfnOLytml+HAcEMQ17FV5WsOz3TYB2z9h/33bm1CBm6dKlxMXFMWXKFPbs2UPLli2Jjo7m0qVLZtMvXryY1157jSlTpnD48GHmzZvH0qVLef31103SNW3alIsXLxofv//+u8n68ePH8/PPP7Ns2TK2bt3KhQsXeOyxxxBCCOew4UJlU3OHnT30XvFpypra6b/NLStRTcztoKJOt1Lsz0JQVdxnx41+eTu1T8yMGTMYOXIkw4YNA2Du3LmsWbOG+fPn89prrxVKv337djp37szAgQMBqF27NgMGDGDXLtNbpHt6ehIWFmZ2n6mpqcybN4/FixfTvbuhN/qCBQto3LgxO3fupEMHG3vom+FCHbiFEK7C3AXC5MvCygtItcZQpS5cO1l8/iVR+144/Vvx6bpNgA6jYcdnNuzEfS6SJVLcl35JamJePg4piVD97tKVKb8RGw0dnj3MXfrd83/itJA1OzubhIQEevS4M6OhWq2mR48e7NhhZuploFOnTiQkJBibnE6ePMnatWvp1cu0auzYsWNERERQt25dBg0aRGJionFdQkICOTk5Jvtt1KgRNWvWtLhfgKysLNLS0kweQghhH0Vc/CxOdqcq3LfmvomlL8rTq8AvtPh0mrwbOjp6Onw3osspen1JRidVCrZvAAMQ2d7yvDf27FhtccSX/TktiLly5Qo6nY7QUNOTJTQ0lKSkJLPbDBw4kGnTpnHPPffg5eVFvXr16Natm0lzUlRUFAsXLmT9+vV8/vnnnDp1invvvZcbN24AkJSUhEajISgoyOr9AkyfPp3AwEDjIzIy0upjVblphCuEKCNF/oK38vvj5ZPQ9eXSl8XDEwKt/34rxM98LbjLcGQApcsuer297hllT40fgUlXDDfKNCrlPDEPTCt1sazlwo2HhW3ZsoV33nmHOXPmsGfPHlasWMGaNWt46623jGl69uzJ448/TosWLYiOjmbt2rWkpKTw/fffl2rfEyZMIDU11fg4e/ZsaQ9HCCEMghvceV7wIhtc3/J2+S8m1s6LUlrtRxmCnNZPF14X9SwMW2tFJs78YeeEIMY32PC3VmfH7dtW6rw5dWx8X2p2Kj6NAzmtT0xwcDAeHh6FRgUlJydb7M8yadIknn76aZ55xtBjunnz5qSnpzNq1CjeeOMN1GY6dAUFBXHXXXdx/PhxAMLCwsjOziYlJcWkNqao/QJotVq0Wht6qwshhIl8F4sRGyHhK0Pfkrn3mCYbsxPSrxj6vViUL4gxNlXY4yJdxC/tXh9Az/fN12j0fNfCNgWaKpzZnOTQmhgLzUnjD0J2OlSq6rh92yrvc2Pr+3LXg5C43X7lKSGn1cRoNBratGlDfHy8cZleryc+Pp6OHTua3SYjI6NQoOLhYaieUyxUb928eZMTJ04QHh4OQJs2bfDy8jLZ79GjR0lMTLS4X1tJv14hRCH5LxaR7eHR2eabYKo1NtzbqCgm/YFddD6ZHm9C+5GOK0tZqt7W8LfRw+bXW6qJ8fJ2zQAGzI+YKsn/V1Fsm//GTpw6OikuLo4hQ4bQtm1b2rdvz8yZM0lPTzeOVho8eDDVq1dn+vTpAMTExDBjxgxat25NVFQUx48fZ9KkScTExBiDmZdeeomYmBhq1arFhQsXmDJlCh4eHgwYMACAwMBARowYQVxcHFWqVCEgIIDnnnuOjh072nVkkhBCWM1kJlcb7tkDGGtgtH6lLo7DlTbgqtYU7p9s685t3+/ApXD4p8Lz/ORp2R/2fgu17jG/3pm6vGJ+uU01MQV+oo/7Gz5uYlOxSsupQUz//v25fPkykydPJikpiVatWrF+/XpjZ9/ExESTmpeJEyeiUqmYOHEi58+fJyQkhJiYGN5++85t3c+dO8eAAQO4evUqISEh3HPPPezcuZOQkBBjmo8//hi1Wk2/fv3IysoiOjqaOXPmOOw4y2tHfCGEneQftZJ/4rti5W9Ouv1Fc98bcHE/3F3MzLRFZuvi9cgdnoWGD5X9fisFQ9vhltf3fB/q3gf1e1hO4yz3vW5+eak7GysQWN1w761Lh0qZV8k5/d5JsbGxxMbGml23ZcsWk9eenp5MmTKFKVOmWMxvyZIlxe7T29ub2bNnM3v27BKVVQghSs/Mrxp71sT4VYNRm23Mw/bduo3AGo7LW1MJmv/LysRlECjm/wVtcai+mV4lGjeozbvN6UFMeebqP2aEEC5Cne+ruCRBjGKuY689lODLy92+5+r3MMynE9bc2SVxDfkD6Idnwq1rBW5Aakb+z52TL3QSxAghhLPl7xhZ2uYke/APB/baLz+7K8WFU6Wyz3w67qDRw3D4Z6gUYjlN/uC37TArM3adyFWCmDLgbrWtQogyZtKcVIIgxpbbFVij90egz4X2/4ZFFjqx5mnWF7bNMtz52BxrgqtH55a8jKJ4zZ8A/zAILaLWqdQ1eFITI4QQFZvNHXvz52HHICYgAgYtsy7tfW9AeCuo09V0uTYQslKL7+Q6dC3UdsFJ4MoDtRrqdis6jXdgmRTFUSSIEUKIsmQu2Mi/zLMkk2o6qCamJDy10OyxwsvjDsLNS1C1XtHby/BN53h4JhxYDp3HlXxbkz4x9iqQbSSIcSDF2f9dIYQLsnDR7j4RbiRDSCPrs1Ic1CfGHrT+hkexXKzcFUXbYSXoA+O6JIgpA6723SKEcEFdbOls6sJBjLXctdylZc2dwt2Cc3+su9UNIIUQQpQzJWo+Kwee+BraPQMtBzq7JPblpKBMamKEEKIs2bPmwZ0no+ryCqSeM3QKrkia9DE83JqZeWIe+RRWjzPMplyGJIhxJDf+fhFCOEh4S2eXwDV0f8PZJRD2FBQJTy0v891Kc5IQQpSVsOZQq5MdM5RfSsIJghvmeyF9Yso9lfS+F0JA0TcPtIU7NycJ91X/ftDcHnnWfpRTiyLNSUII4WgDlsDJLdD6aTtnXI6DGL9QuJlsuAXCjYvOLo3IT6WC188Zgmgnjy6TIMaByvHXixCiJBr2NDyE9V7YD1k34Lv+hYMYL1/nlEmYcoHh8RLECCGEuyrPzUle3oZHfg9Mg8Sd5WB0j7AXCWLKgAsEq0KIcqkcBzHmdH7B8BDiNunYK4QQ7qpmRwiMhLr3ObskjhNWxB2YRYUnNTFCCOGuPLXwwl+md8Eubx6YBtoAaP4vZ5dEuCAJYhxIKc/t1UII16D2cHYJHMs7EB58y9mlEC6qHIfvQgghhCjPJIgRQghh2VMrDLUhT3zt7JIIUYg0JwkhhLCs/v3w6hkZZilcktTEOJD0iBFClAsSwAgXJUGMEEIIIdySBDFlQCW/YoQQQgi7kyBGCCGEEG5JghghhBBCuCUJYhxI5roTQgghHEeCmDIgPWKEEEII+5MgRggh7Cg5LZNvd54hIzvX2UURotyTye6EEMKOHp+7g8RrGRy+mMbbfeUOzEI4ktTEOJB0iRGi4km8lgHA/w4lO7kkQpR/Tg9iZs+eTe3atfH29iYqKoo//vijyPQzZ86kYcOG+Pj4EBkZyfjx48nMzDSunz59Ou3atcPf359q1arx6KOPcvToUZM8unXrhkqlMnmMHj3aIccHMtmlEBVFVq7O+PzyjSwAcnV6Xlr2F9//edZZxRKi3HJqELN06VLi4uKYMmUKe/bsoWXLlkRHR3Pp0iWz6RcvXsxrr73GlClTOHz4MPPmzWPp0qW8/vrrxjRbt25l7Nix7Ny5k40bN5KTk8ODDz5Ienq6SV4jR47k4sWLxsf777/v0GMVQlQ8P/11gf8dSuaHhHO8sny/s4sjRLnj1D4xM2bMYOTIkQwbNgyAuXPnsmbNGubPn89rr71WKP327dvp3LkzAwcOBKB27doMGDCAXbt2GdOsX7/eZJuFCxdSrVo1EhIS6NKli3G5r68vYWFhjjgsIUQFpfEw/V34/Hd7ubtmkPF1SkY2Qb4a5m49wZUbWUx8uEkZl1CI8sVpNTHZ2dkkJCTQo0ePO4VRq+nRowc7duwwu02nTp1ISEgwNjmdPHmStWvX0qtXL4v7SU1NBaBKlSomyxctWkRwcDDNmjVjwoQJZGRkFFnerKws0tLSTB7FUWSiGCFcTkmbsEvC3C1G9iSmGJ8/+eVO9HqFd9cd4f9+P8VT/7eLKzez7LZ/ISoapwUxV65cQafTERoaarI8NDSUpKQks9sMHDiQadOmcc899+Dl5UW9evXo1q2bSXNSfnq9nnHjxtG5c2eaNWtmks+3337L5s2bmTBhAt988w1PPfVUkeWdPn06gYGBxkdkZGQJj1gI4WwlbcK2tyNJN6j7+lrj69+PX2HSqgNlsm8hyiOnd+wtiS1btvDOO+8wZ84c9uzZw4oVK1izZg1vvfWW2fRjx47lwIEDLFmyxGT5qFGjiI6Opnnz5gwaNIivv/6alStXcuLECYv7njBhAqmpqcbH2bPWd9KTfr1CuIb8TdhNmjRh7ty5+Pr6Mn/+fKeVad2BJKm1FRbJZ6NoTusTExwcjIeHB8nJpsMQk5OTLfZVmTRpEk8//TTPPPMMAM2bNyc9PZ1Ro0bxxhtvoFbficliY2NZvXo1v/76KzVq1CiyLFFRUQAcP36cevXqmU2j1WrRarVWH58QwrXkNWFPmDDBuKyoJuysrCyysu409VjThAywZFQHfj92hc82H7e6bHUmrKVJeAA+Gg+0nmoupmZSSeuBn9bwFa0ocPlmFsmpmTQKD8BDpUKnKOTq9OToFDzUKvSKwtlrGYQFeuOn9SQjW0eAjxc6vYJOr5Cj03PpRhZZOTp8NB7UrlqJ01fT8VSr8fRQcSktC08PFTUq++Lv7UlqRo5xZKWiQI5eT9VKGrJz9aBScSs7F28vD9QqFRpPNZk5OjzVKjw91KgwjMrM0Smk3crBV+uJxkNFepYOD7Uh07/Pp1InuJKh7HqFjGwduXo9Wk8PcnR6vL08CAvwxkOtIitXR+qtHDSehvcn78Keq1dIycghIzsXX40nQb5eZObo8PP2QqfX4+vliV5RyNbp0d/extfLk1s5OtRqleHAVIb9azzV5OoVsnP1+Gs9uZGVi6daxd/nDV0SGocHoMIwAq2S1pBvVo4eD7UKf29PcnQKmTk6VCoViqJwK0eHr8aTm1k5KAqEBXjj5aEmR6fnVo6OShpPsnV6cnR6dHqFI0k3qB7kg7+3YbmPlwc3s3K5lJZFaICW6pV9jP8LvWIoZ7ZOj4dKReK1DHw1nvhqPPBQq9B6qo3vT+qtO//HAG8v0rNy8fP2xFOdl0ZPSkYOEYE+eKhV3MrRkXn7M7L3dlNou9qVydUr3MzM5XpGDmGBWny8PNDpFfS3y6NXFDzVhv+NWq3inb7NaRweYPU5YCunBTEajYY2bdoQHx/Po48+Chiaf+Lj44mNjTW7TUZGhkmgAuDh4QHciVYVReG5555j5cqVbNmyhTp16hRbln379gEQHh5u49EIIVxdUU3YR44cKZR++vTpvPnmmyXeT4e6VelQtyqtIoN45uvdAEyNacKKvefZfy7V4naHLloXJCWcuV7k+rTMm8XmkZaZS3Kamb44OXC4iHKcvJxucZ0tTl0pOr+8OXescT0jh/Mpt0pbJIuKel+sce568WWzVP7TVzM4fbXo9+J6Ro4VpbBchqLK9+dp08+cNf24cnR6K8pTek4dnRQXF8eQIUNo27Yt7du3Z+bMmaSnpxtHKw0ePJjq1aszffp0AGJiYpgxYwatW7cmKiqK48ePM2nSJGJiYozBzNixY1m8eDE//vgj/v7+xv41gYGB+Pj4cOLECRYvXkyvXr2oWrUq+/fvZ/z48XTp0oUWLVrY9fie7lCL7o2q0aJGkF3zFUI43oQJE4iLizO+TktLK1FfuB5NQol/sSvVg3zw9vLgqQ610Cuguf0r+WLqLYL9tKzae54cnUIlrYdxW7VKhU6v4OlxpzFap1e4lp5NiL8WtUplrNHwVKvI0RlqG3Jy9fhqPFCpDLUXKpUKjYcatcrwq/xGZg7pWTr8tJ54azzwUqtITsvkWkYOWk81oQHeqACv27UdmTk6rqXnUM1fS1U/DTezclGrVHjervnJq1lRq1X4enmgU5Tbv84VFMUw4aenWkXarRwCfLzQeKjJzNWhQsXuM9eoE1yJKpU0aD09OHwxjYggH7y91NzMzCVXr1ClksZYi5SRrSPEX4tOr+DloSYlI5tKWs/btQPZVPbVEOjrRc7t2o0Aby+ycvUY3iYVqtsVL7l6w3uUka1DUQzly8jWkZmro7KvBl+NB2mZuWTm6EjPyiUlI4esXD1NIgII8PYkM0ePSgW5OsVYA5Gda6iR8fRQU+l2bcjNrFw81WoSr6VTzd8braeaHL2CohhqzjxUhvSeHirOXb/FzcxcAn288PP2RK9X8NV4UEnrSeK1DK6lZ1M9yAeVytB5XAV4eRj+R7l6heS0TCppPfG7XUPkpzWUM0env12TpUfjqUan15OVo8ff24tcvR4vDzVZuYYaoxydHkWBzBwdGk81nmo151MyUKtUhPhrUalU+Hh5cOt2jZtaZficqlUq1GrD88wcvfGzUTu4UinOPus5NYjp378/ly9fZvLkySQlJdGqVSvWr19v/KWUmJhoUvMyceJEVCoVEydO5Pz584SEhBATE8Pbb79tTPP5558Dhgnt8luwYAFDhw5Fo9GwadMmY8AUGRlJv379mDhxot2PL6puVbvnKYSwTUmbsO3RhFwvxM/43LPA8OvwQEPzwONtK+Yggd4tTGu+H2gSaiFlxdbZ2QVwcSpFeg3ZJC0tjcDAQFJTUwkIcHy7nxDlVVmeS1FRUbRv355PP/0UMDRh16xZk9jYWLNzUzmrnEKUd/Y6n+QGkEKICqO4JmwhhHuRIEYIUWEU14QthHAvEsQIISqU2NhYiyMghRDuxa0muxNCCCGEyCNBjBBCCCHckgQxQgghhHBLEsQIIYQQwi1JECOEEEIItyRBjBBCCCHckgQxQgghhHBLEsQIIYQQwi3JZHc2yrvlVFpa6W7PLkRFl3cOufpt3OScF8J+7HXeSxBjoxs3bgAQGVkx70ArhL3duHGDwMBAZxfDIjnnhbC/0p73chdrG+n1ei5cuIC/vz8qlcpsmrS0NCIjIzl79qxb3vXW3csP7n8MFaH8iqJw48YNIiIiUKtdt4XbmnMeKsb/zJVJ+Z3L2vLb67yXmhgbqdVqatSoYVXagIAAt/ww5nH38oP7H0N5L78r18DkKck5D+X/f+bqpPzOZU357XHeu+7PHiGEEEKIIkgQI4QQQgi3JEGMA2m1WqZMmYJWq3V2UWzi7uUH9z8GKb/7cfdjlvI7l5S/ZKRjrxBCCCHcktTECCGEEMItSRAjhBBCCLckQYwQQggh3JIEMUIIIYRwSxLEONDs2bOpXbs23t7eREVF8ccffzi7SEyfPp127drh7+9PtWrVePTRRzl69KhJmm7duqFSqUweo0ePNkmTmJhI79698fX1pVq1arz88svk5uY6vPxTp04tVLZGjRoZ12dmZjJ27FiqVq2Kn58f/fr1Izk52SXKnqd27dqFjkGlUjF27FjA9d7/X3/9lZiYGCIiIlCpVKxatcpkvaIoTJ48mfDwcHx8fOjRowfHjh0zSXPt2jUGDRpEQEAAQUFBjBgxgps3b5qk2b9/P/feey/e3t5ERkby/vvvO+R4HE3Oe/tz9/NeznkHnvOKcIglS5YoGo1GmT9/vnLw4EFl5MiRSlBQkJKcnOzUckVHRysLFixQDhw4oOzbt0/p1auXUrNmTeXmzZvGNF27dlVGjhypXLx40fhITU01rs/NzVWaNWum9OjRQ9m7d6+ydu1aJTg4WJkwYYLDyz9lyhSladOmJmW7fPmycf3o0aOVyMhIJT4+Xtm9e7fSoUMHpVOnTi5R9jyXLl0yKf/GjRsVQNm8ebOiKK73/q9du1Z54403lBUrViiAsnLlSpP17777rhIYGKisWrVK+euvv5RHHnlEqVOnjnLr1i1jmoceekhp2bKlsnPnTuW3335T6tevrwwYMMC4PjU1VQkNDVUGDRqkHDhwQPnuu+8UHx8f5YsvvnDIMTmKnPeO4e7nvZzzjjvnJYhxkPbt2ytjx441vtbpdEpERIQyffp0J5aqsEuXLimAsnXrVuOyrl27Ki+88ILFbdauXauo1WolKSnJuOzzzz9XAgIClKysLEcWV5kyZYrSsmVLs+tSUlIULy8vZdmyZcZlhw8fVgBlx44dTi+7JS+88IJSr149Ra/XK4ri2u9/wS80vV6vhIWFKR988IFxWUpKiqLVapXvvvtOURRFOXTokAIof/75pzHNunXrFJVKpZw/f15RFEWZM2eOUrlyZZPyv/rqq0rDhg0dejz2Jue9Y5S3817Oefud89Kc5ADZ2dkkJCTQo0cP4zK1Wk2PHj3YsWOHE0tWWGpqKgBVqlQxWb5o0SKCg4Np1qwZEyZMICMjw7hux44dNG/enNDQUOOy6Oho0tLSOHjwoMPLfOzYMSIiIqhbty6DBg0iMTERgISEBHJyckze90aNGlGzZk3j++7ssheUnZ3Nt99+y/Dhw01uKujK739+p06dIikpyeQ9DwwMJCoqyuQ9DwoKom3btsY0PXr0QK1Ws2vXLmOaLl26oNFojGmio6M5evQo169fL6OjKR057x2rvJz3cs7b95yXG0A6wJUrV9DpdCYfOIDQ0FCOHDnipFIVptfrGTduHJ07d6ZZs2bG5QMHDqRWrVpERESwf/9+Xn31VY4ePcqKFSsASEpKMntseescKSoqioULF9KwYUMuXrzIm2++yb333suBAwdISkpCo9EQFBRUqGx55XJm2c1ZtWoVKSkpDB061LjMld//gvL2Z648+d/zatWqmaz39PSkSpUqJmnq1KlTKI+8dZUrV3ZI+e1JznvHKU/nvZzz9j3nJYipwMaOHcuBAwf4/fffTZaPGjXK+Lx58+aEh4dz//33c+LECerVq1fWxTTRs2dP4/MWLVoQFRVFrVq1+P777/Hx8XFiyWwzb948evbsSUREhHGZK7//wv3Jee9ccs7blzQnOUBwcDAeHh6FescnJycTFhbmpFKZio2NZfXq1WzevJkaNWoUmTYqKgqA48ePAxAWFmb22PLWlaWgoCDuuusujh8/TlhYGNnZ2aSkpBQqW165XKnsZ86cYdOmTTzzzDNFpnPl9z9vf0V91sPCwrh06ZLJ+tzcXK5du+aS/xdbyXlfdtz1vJdz3v7nvAQxDqDRaGjTpg3x8fHGZXq9nvj4eDp27OjEkhmGxsXGxrJy5Up++eWXQtV55uzbtw+A8PBwADp27Mjff/9t8iHduHEjAQEBNGnSxCHltuTmzZucOHGC8PBw2rRpg5eXl8n7fvToURITE43vuyuVfcGCBVSrVo3evXsXmc6V3/86deoQFhZm8p6npaWxa9cuk/c8JSWFhIQEY5pffvkFvV5v/LLu2LEjv/76Kzk5OcY0GzdupGHDhm7RlARy3pcldz3v5Zx3wDlf8r7KwhpLlixRtFqtsnDhQuXQoUPKqFGjlKCgIJPe5c7w7LPPKoGBgcqWLVtMhvNlZGQoiqIox48fV6ZNm6bs3r1bOXXqlPLjjz8qdevWVbp06WLMI2+434MPPqjs27dPWb9+vRISElImwxVffPFFZcuWLcqpU6eUbdu2KT169FCCg4OVS5cuKYpiGGpZs2ZN5ZdfflF2796tdOzYUenYsaNLlD0/nU6n1KxZU3n11VdNlrvi+3/jxg1l7969yt69exVAmTFjhrJ3717lzJkziqIYhlsGBQUpP/74o7J//36lT58+Zodbtm7dWtm1a5fy+++/Kw0aNDAZbpmSkqKEhoYqTz/9tHLgwAFlyZIliq+vr1sOsZbz3v7Kw3kv57xjznkJYhzo008/VWrWrKloNBqlffv2ys6dO51dJAUw+1iwYIGiKIqSmJiodOnSRalSpYqi1WqV+vXrKy+//LLJnAWKoiinT59Wevbsqfj4+CjBwcHKiy++qOTk5Di8/P3791fCw8MVjUajVK9eXenfv79y/Phx4/pbt24pY8aMUSpXrqz4+voqffv2VS5evOgSZc9vw4YNCqAcPXrUZLkrvv+bN282+5kZMmSIoiiGIZeTJk1SQkNDFa1Wq9x///2Fjuvq1avKgAEDFD8/PyUgIEAZNmyYcuPGDZM0f/31l3LPPfcoWq1WqV69uvLuu+865HgcTc57+ysP572c844551WKoijW19sIIYQQQrgG6RMjhBBCCLckQYwQQggh3JIEMUIIIYRwSxLECCGEEMItSRAjhBBCCLckQYwQQggh3JIEMUIIIYRwSxLECFHAli1bUKlUhe7FIoRwjm7dujFu3DhnF0O4IAlihBBCCOGWJIgRQgghhFuSIEa4HL1ez/Tp06lTpw4+Pj60bNmSH374AbjT1LNmzRpatGiBt7c3HTp04MCBAyZ5LF++nKZNm6LVaqlduzYfffSRyfqsrCxeffVVIiMj0Wq11K9fn3nz5pmkSUhIoG3btvj6+tKpUyeOHj3q2AMXQhTr+vXrDB48mMqVK+Pr60vPnj05duyYcf2ZM2eIiYmhcuXKVKpUiaZNm7J27VrjtoMGDSIkJAQfHx8aNGjAggULnHUowg48nV0AIQqaPn063377LXPnzqVBgwb8+uuvPPXUU4SEhBjTvPzyy8yaNYuwsDBef/11YmJi+Oeff/Dy8iIhIYEnnniCqVOn0r9/f7Zv386YMWOoWrUqQ4cOBWDw4MHs2LGDTz75hJYtW3Lq1CmuXLliUo433niDjz76iJCQEEaPHs3w4cPZtm1bWb4VQogChg4dyrFjx/jpp58ICAjg1VdfpVevXhw6dAgvLy/Gjh1LdnY2v/76K5UqVeLQoUP4+fkBMGnSJA4dOsS6desIDg7m+PHj3Lp1y8lHJErFxptcCuEQmZmZiq+vr7J9+3aT5SNGjFAGDBhgvLvqkiVLjOuuXr2q+Pj4KEuXLlUURVEGDhyoPPDAAybbv/zyy0qTJk0URVGUo0ePKoCyceNGs2XI28emTZuMy9asWaMAJreaF0KUja5duyovvPCC8s8//yiAsm3bNuO6K1euKD4+Psr333+vKIqiNG/eXJk6darZfGJiYpRhw4aVSZlF2ZDmJOFSjh8/TkZGBg888AB+fn7Gx9dff82JEyeM6Tp27Gh8XqVKFRo2bMjhw4cBOHz4MJ07dzbJt3Pnzhw7dgydTse+ffvw8PCga9euRZalRYsWxufh4eEAXLp0qdTHKISwzeHDh/H09CQqKsq4rGrVqibn//PPP89//vMfOnfuzJQpU9i/f78x7bPPPsuSJUto1aoVr7zyCtu3by/zYxD2JUGMcCk3b94EYM2aNezbt8/4OHTokLFfTGn5+PhYlc7Ly8v4XKVSAYb+OkII1/XMM89w8uRJnn76af7++2/atm3Lp59+CkDPnj05c+YM48eP58KFC9x///289NJLTi6xKA0JYoRLadKkCVqtlsTEROrXr2/yiIyMNKbbuXOn8fn169f5559/aNy4MQCNGzcu1Hdl27Zt3HXXXXh4eNC8eXP0ej1bt24tm4MSQthF48aNyc3NZdeuXcZlV69e5ejRozRp0sS4LDIyktGjR7NixQpefPFF/vvf/xrXhYSEMGTIEL799ltmzpzJl19+WabHIOxLOvYKl+Lv789LL73E+PHj0ev13HPPPaSmprJt2zYCAgKoVasWANOmTaNq1aqEhobyxhtvEBwczKOPPgrAiy++SLt27Xjrrbfo378/O3bs4LPPPmPOnDkA1K5dmyFDhjB8+HBjx94zZ85w6dIlnnjiCWcduhCiGA0aNKBPnz6MHDmSL774An9/f1577TWqV69Onz59ABg3bhw9e/bkrrvu4vr162zevNn4A2fy5Mm0adOGpk2bkpWVxerVq43rhJtydqccIQrS6/XKzJkzlYYNGypeXl5KSEiIEh0drWzdutXY6fbnn39WmjZtqmg0GqV9+/bKX3/9ZZLHDz/8oDRp0kTx8vJSatasqXzwwQcm62/duqWMHz9eCQ8PVzQajVK/fn1l/vz5iqLc6dh7/fp1Y/q9e/cqgHLq1ClHH74QooC8jr2KoijXrl1Tnn76aSUwMFDx8fFRoqOjlX/++ef/27VjUwmBKAyjbiRmIliBkWVYgRXYgV3YmJVYgWAJ/2YvfsGCXDgnnmAm+7h3/s7u+55pmtK2bcZxzLZtue87SXIcR+Z5Ttd1GYYh67rmuq43nsSPfJLk5Y6CfzvPs1mWpXmep+n7/u3rAPAif2IAgJJEDABQknUSAFCSSQwAUJKIAQBKEjEAQEkiBgAoScQAACWJGACgJBEDAJQkYgCAkkQMAFDSF/zrw9J6vIRqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = tf.keras.saving.load_model(\"model.keras\")\n",
    "y_true, y_pred = get_true_and_predicted_labels(model, test_dataset)\n",
    "\n",
    "model_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Saving confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true, y_pred,\n",
    "    display_labels=classes\n",
    ")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "plot_model_history(model_history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1592399,
     "sourceId": 2619910,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36427.46127,
   "end_time": "2024-06-02T10:50:39.400822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-02T00:43:31.939552",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
