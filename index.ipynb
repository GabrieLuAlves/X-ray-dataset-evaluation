{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75fdeeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:05.574771Z",
     "iopub.status.busy": "2024-06-02T17:16:05.574369Z",
     "iopub.status.idle": "2024-06-02T17:16:35.356123Z",
     "shell.execute_reply": "2024-06-02T17:16:35.355019Z"
    },
    "papermill": {
     "duration": 29.790646,
     "end_time": "2024-06-02T17:16:35.358561",
     "exception": false,
     "start_time": "2024-06-02T17:16:05.567915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\r\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\r\n",
      "\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: split-folders\r\n",
      "Successfully installed split-folders-0.5.1\r\n",
      "Requirement already satisfied: tensorflow==2.15.0 in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.59.3)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.0) (3.1.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed keras-2.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /kaggle/working/*\n",
    "\n",
    "!pip install split-folders\n",
    "!pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8ec8c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:35.373398Z",
     "iopub.status.busy": "2024-06-02T17:16:35.373074Z",
     "iopub.status.idle": "2024-06-02T17:16:48.213368Z",
     "shell.execute_reply": "2024-06-02T17:16:48.212457Z"
    },
    "id": "MMpVa0OcPGGj",
    "papermill": {
     "duration": 12.850209,
     "end_time": "2024-06-02T17:16:48.215443",
     "exception": false,
     "start_time": "2024-06-02T17:16:35.365234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:16:37.038384: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-02 17:16:37.038485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-02 17:16:37.159334: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "\n",
    "from typing import List\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d2a6e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:48.230484Z",
     "iopub.status.busy": "2024-06-02T17:16:48.229927Z",
     "iopub.status.idle": "2024-06-02T17:16:48.246194Z",
     "shell.execute_reply": "2024-06-02T17:16:48.245550Z"
    },
    "id": "n2c0Ur2eNIbH",
    "papermill": {
     "duration": 0.025724,
     "end_time": "2024-06-02T17:16:48.248139",
     "exception": false,
     "start_time": "2024-06-02T17:16:48.222415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8bf3f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:48.262158Z",
     "iopub.status.busy": "2024-06-02T17:16:48.261898Z",
     "iopub.status.idle": "2024-06-02T17:16:48.272355Z",
     "shell.execute_reply": "2024-06-02T17:16:48.271574Z"
    },
    "papermill": {
     "duration": 0.019571,
     "end_time": "2024-06-02T17:16:48.274198",
     "exception": false,
     "start_time": "2024-06-02T17:16:48.254627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_rmdir(folder):\n",
    "    for item in os.listdir(folder):\n",
    "        item_path = os.path.join(folder, item)\n",
    "        \n",
    "        if os.path.isdir(item_path):\n",
    "            recursive_rmdir(item_path)\n",
    "            os.rmdir(item_path)\n",
    "        else:\n",
    "            os.remove(item_path)\n",
    "            \n",
    "\n",
    "def organize_dataset(source_folder, destination_folder):    \n",
    "    if os.path.exists(destination_folder):\n",
    "        recursive_rmdir(destination_folder)\n",
    "    \n",
    "    # Discover all classes\n",
    "    classes = set()\n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        current_folder = os.path.join(source_folder, subfolder)\n",
    "        discovered_classes = os.listdir(current_folder)\n",
    "        classes = classes.union(discovered_classes)\n",
    "    classes = list(classes)\n",
    "    classes.sort()\n",
    "\n",
    "    # Create a folder for each class\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.mkdir(destination_folder)\n",
    "    \n",
    "    for _class in classes:\n",
    "        class_directory = os.path.join(destination_folder, _class)\n",
    "        os.mkdir(class_directory)\n",
    "    \n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        current_path = os.path.join(source_folder, subfolder)\n",
    "        for class_folder in os.listdir(current_path):\n",
    "            current_path = os.path.join(source_folder, subfolder, class_folder)\n",
    "            for file in os.listdir(current_path):\n",
    "                \n",
    "                file_source_path = os.path.join(\n",
    "                    source_folder,\n",
    "                    subfolder,\n",
    "                    class_folder,\n",
    "                    file\n",
    "                )\n",
    "                \n",
    "                file_destination_path = os.path.join(\n",
    "                    destination_folder,\n",
    "                    class_folder,\n",
    "                    file\n",
    "                )\n",
    "                \n",
    "                shutil.copy2(\n",
    "                    file_source_path,\n",
    "                    file_destination_path,\n",
    "                )\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5e0ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:48.288721Z",
     "iopub.status.busy": "2024-06-02T17:16:48.288046Z",
     "iopub.status.idle": "2024-06-02T17:16:48.293681Z",
     "shell.execute_reply": "2024-06-02T17:16:48.292879Z"
    },
    "id": "G3-UpbprWm2B",
    "papermill": {
     "duration": 0.014699,
     "end_time": "2024-06-02T17:16:48.295488",
     "exception": false,
     "start_time": "2024-06-02T17:16:48.280789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_validation_split(\n",
    "    source: str,\n",
    "    destination: str,\n",
    "    seed: int | None = None\n",
    "):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(999999)\n",
    "    print(f\"Dataset's split seed is {seed}\")\n",
    "\n",
    "    if not os.path.isdir(destination):\n",
    "        splitfolders.ratio(source, output=destination,\n",
    "            seed=seed, ratio=(.6, .2, .2), move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a42137f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:48.309926Z",
     "iopub.status.busy": "2024-06-02T17:16:48.309607Z",
     "iopub.status.idle": "2024-06-02T17:16:48.316687Z",
     "shell.execute_reply": "2024-06-02T17:16:48.315817Z"
    },
    "id": "aNagWAB7IPwC",
    "papermill": {
     "duration": 0.016485,
     "end_time": "2024-06-02T17:16:48.318613",
     "exception": false,
     "start_time": "2024-06-02T17:16:48.302128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_history(history):\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(6, 4.4))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('loss')\n",
    "    ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12b2f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:48.333370Z",
     "iopub.status.busy": "2024-06-02T17:16:48.332694Z",
     "iopub.status.idle": "2024-06-02T17:16:48.338343Z",
     "shell.execute_reply": "2024-06-02T17:16:48.337547Z"
    },
    "id": "7Qo2uteJsmP4",
    "papermill": {
     "duration": 0.014998,
     "end_time": "2024-06-02T17:16:48.340164",
     "exception": false,
     "start_time": "2024-06-02T17:16:48.325166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_true_and_predicted_labels(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for X_batch, y_batch in dataset:\n",
    "        y_batch_pred = np.argmax(model.predict(X_batch, verbose=0), axis=1)\n",
    "        \n",
    "        y_true.append(y_batch)\n",
    "        y_pred.append(y_batch_pred)\n",
    "    \n",
    "    y_true = [y_batch.numpy() for y_batch in y_true]\n",
    "    \n",
    "    return np.concatenate(y_true), np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdafe1d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:16:48.354385Z",
     "iopub.status.busy": "2024-06-02T17:16:48.354117Z",
     "iopub.status.idle": "2024-06-02T17:17:47.755549Z",
     "shell.execute_reply": "2024-06-02T17:17:47.754560Z"
    },
    "id": "ZrBCEYY3kVeL",
    "outputId": "af100c6b-d715-41ad-c463-435d0aa1a173",
    "papermill": {
     "duration": 59.414571,
     "end_time": "2024-06-02T17:17:47.761318",
     "exception": false,
     "start_time": "2024-06-02T17:16:48.346747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's split seed is 892471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7132 files [00:02, 2825.51 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['COVID19', 'NORMAL', 'PNEUMONIA', 'TURBERCULOSIS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = organize_dataset(\n",
    "    os.path.join(\"/\", \"kaggle\", \"input\", \"chest-xray-pneumoniacovid19tuberculosis\"),\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"temp\"),\n",
    ")\n",
    "train_test_validation_split(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"temp\"),\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\"),\n",
    "    seed=892471\n",
    ")\n",
    "\n",
    "print(\"Found classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2f5839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:17:47.812885Z",
     "iopub.status.busy": "2024-06-02T17:17:47.812394Z",
     "iopub.status.idle": "2024-06-02T17:17:50.544865Z",
     "shell.execute_reply": "2024-06-02T17:17:50.544035Z"
    },
    "papermill": {
     "duration": 2.764339,
     "end_time": "2024-06-02T17:17:50.547371",
     "exception": false,
     "start_time": "2024-06-02T17:17:47.783032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ TRAIN DATASET ]\n",
      "Found 4277 files belonging to 4 classes.\n",
      "\n",
      "[ VALIDATION DATASET ]\n",
      "Found 1425 files belonging to 4 classes.\n",
      "\n",
      "[ TEST DATASET ]\n",
      "Found 1430 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[ TRAIN DATASET ]\")\n",
    "train_dataset = train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"train\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(\"\\n[ VALIDATION DATASET ]\")\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"val\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(\"\\n[ TEST DATASET ]\")\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"test\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13077fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:17:52.593421Z",
     "iopub.status.busy": "2024-06-02T17:17:52.592533Z",
     "iopub.status.idle": "2024-06-02T17:17:55.503532Z",
     "shell.execute_reply": "2024-06-02T17:17:55.502564Z"
    },
    "papermill": {
     "duration": 2.937,
     "end_time": "2024-06-02T17:17:55.506228",
     "exception": false,
     "start_time": "2024-06-02T17:17:52.569228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg_16 = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"max\",\n",
    ")\n",
    "\n",
    "for layer in vgg_16.layers:\n",
    "    layer.freeze = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000005, name=\"optimizer\")\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(name=\"loss\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    vgg_16,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\"),\n",
    "], name=\"model\")\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.build((None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780becb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:17:55.535719Z",
     "iopub.status.busy": "2024-06-02T17:17:55.535293Z",
     "iopub.status.idle": "2024-06-02T17:17:55.541051Z",
     "shell.execute_reply": "2024-06-02T17:17:55.540071Z"
    },
    "papermill": {
     "duration": 0.023162,
     "end_time": "2024-06-02T17:17:55.543106",
     "exception": false,
     "start_time": "2024-06-02T17:17:55.519944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learning_rate_schedule(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return 0.000005\n",
    "    else:\n",
    "        return 0.000005 * 0.9 ** ((epoch - 50) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caafdba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T17:17:55.568335Z",
     "iopub.status.busy": "2024-06-02T17:17:55.568056Z",
     "iopub.status.idle": "2024-06-02T20:32:39.626236Z",
     "shell.execute_reply": "2024-06-02T20:32:39.625449Z"
    },
    "id": "0nd5jsSFmE5J",
    "outputId": "b8a02719-59f6-4e2c-90cd-cbde47d69a46",
    "papermill": {
     "duration": 11684.073082,
     "end_time": "2024-06-02T20:32:39.628258",
     "exception": false,
     "start_time": "2024-06-02T17:17:55.555176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717348684.884002      84 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8373\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93825, saving model to model.keras\n",
      "134/134 [==============================] - 63s 336ms/step - loss: 0.5160 - accuracy: 0.8373 - val_loss: 0.5215 - val_accuracy: 0.9382 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0535 - accuracy: 0.9553\n",
      "Epoch 2: val_accuracy improved from 0.93825 to 0.95439, saving model to model.keras\n",
      "134/134 [==============================] - 37s 272ms/step - loss: 1.0535 - accuracy: 0.9553 - val_loss: 1.8154 - val_accuracy: 0.9544 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9668\n",
      "Epoch 3: val_accuracy improved from 0.95439 to 0.96211, saving model to model.keras\n",
      "134/134 [==============================] - 38s 273ms/step - loss: 0.2324 - accuracy: 0.9668 - val_loss: 0.5095 - val_accuracy: 0.9621 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.9750\n",
      "Epoch 4: val_accuracy improved from 0.96211 to 0.96491, saving model to model.keras\n",
      "134/134 [==============================] - 38s 272ms/step - loss: 0.5463 - accuracy: 0.9750 - val_loss: 1.4549 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.9857\n",
      "Epoch 5: val_accuracy improved from 0.96491 to 0.96561, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.6453 - accuracy: 0.9857 - val_loss: 1.3962 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.9909\n",
      "Epoch 6: val_accuracy improved from 0.96561 to 0.96912, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.4727 - accuracy: 0.9909 - val_loss: 1.3496 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.9906\n",
      "Epoch 7: val_accuracy did not improve from 0.96912\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.3893 - accuracy: 0.9906 - val_loss: 1.1040 - val_accuracy: 0.9607 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.9944\n",
      "Epoch 8: val_accuracy improved from 0.96912 to 0.97193, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.6777 - accuracy: 0.9944 - val_loss: 1.4786 - val_accuracy: 0.9719 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9949\n",
      "Epoch 9: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0456 - accuracy: 0.9949 - val_loss: 0.3003 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.9965\n",
      "Epoch 10: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.5608 - accuracy: 0.9965 - val_loss: 2.2925 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.9951\n",
      "Epoch 11: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2549 - accuracy: 0.9951 - val_loss: 0.8745 - val_accuracy: 0.9677 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.9986\n",
      "Epoch 12: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2823 - accuracy: 0.9986 - val_loss: 1.9917 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.9974\n",
      "Epoch 13: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.4362 - accuracy: 0.9974 - val_loss: 1.0770 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9967\n",
      "Epoch 14: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1651 - accuracy: 0.9967 - val_loss: 0.3081 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.9867\n",
      "Epoch 15: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.6771 - accuracy: 0.9867 - val_loss: 1.0393 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9970\n",
      "Epoch 16: val_accuracy did not improve from 0.97193\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1630 - accuracy: 0.9970 - val_loss: 1.1760 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9981\n",
      "Epoch 17: val_accuracy improved from 0.97193 to 0.97544, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.1129 - accuracy: 0.9981 - val_loss: 0.4604 - val_accuracy: 0.9754 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 18: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.1876 - val_accuracy: 0.9719 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9986\n",
      "Epoch 19: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0649 - accuracy: 0.9986 - val_loss: 0.3555 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9972\n",
      "Epoch 20: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.1716 - val_accuracy: 0.9747 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9977\n",
      "Epoch 21: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0571 - accuracy: 0.9977 - val_loss: 0.3550 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9984\n",
      "Epoch 22: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0930 - accuracy: 0.9984 - val_loss: 0.5910 - val_accuracy: 0.9719 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8929 - accuracy: 0.9951\n",
      "Epoch 23: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.8929 - accuracy: 0.9951 - val_loss: 1.6309 - val_accuracy: 0.9607 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9925\n",
      "Epoch 24: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.3142 - accuracy: 0.9925 - val_loss: 1.1690 - val_accuracy: 0.9502 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9972\n",
      "Epoch 25: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0939 - accuracy: 0.9972 - val_loss: 0.4327 - val_accuracy: 0.9684 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9979\n",
      "Epoch 26: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0893 - accuracy: 0.9979 - val_loss: 0.4724 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.9956\n",
      "Epoch 27: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.4702 - accuracy: 0.9956 - val_loss: 0.7499 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9988\n",
      "Epoch 28: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1827 - accuracy: 0.9988 - val_loss: 0.9421 - val_accuracy: 0.9740 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.9953    \n",
      "Epoch 29: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.4306 - accuracy: 0.9953 - val_loss: 1.1138 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.9916\n",
      "Epoch 30: val_accuracy did not improve from 0.97544\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.5327 - accuracy: 0.9916 - val_loss: 1.7264 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9988    \n",
      "Epoch 31: val_accuracy improved from 0.97544 to 0.97614, saving model to model.keras\n",
      "134/134 [==============================] - 38s 272ms/step - loss: 0.0167 - accuracy: 0.9988 - val_loss: 0.3175 - val_accuracy: 0.9761 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9981    \n",
      "Epoch 32: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0794 - accuracy: 0.9981 - val_loss: 0.2429 - val_accuracy: 0.9754 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9960    \n",
      "Epoch 33: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.2146 - accuracy: 0.9960 - val_loss: 0.3854 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.9935\n",
      "Epoch 34: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2778 - accuracy: 0.9935 - val_loss: 1.0684 - val_accuracy: 0.9551 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.9958\n",
      "Epoch 35: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.3634 - accuracy: 0.9958 - val_loss: 0.9166 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9984\n",
      "Epoch 36: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.1776 - accuracy: 0.9984 - val_loss: 0.8161 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9988\n",
      "Epoch 37: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0555 - accuracy: 0.9988 - val_loss: 0.6954 - val_accuracy: 0.9733 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9977\n",
      "Epoch 38: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0901 - accuracy: 0.9977 - val_loss: 0.3197 - val_accuracy: 0.9600 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9991    \n",
      "Epoch 39: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1189 - accuracy: 0.9991 - val_loss: 0.4611 - val_accuracy: 0.9740 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9988    \n",
      "Epoch 40: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0243 - accuracy: 0.9988 - val_loss: 0.2252 - val_accuracy: 0.9747 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.9963    \n",
      "Epoch 41: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.3276 - accuracy: 0.9963 - val_loss: 0.5516 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.9984    \n",
      "Epoch 42: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.2930 - accuracy: 0.9984 - val_loss: 0.9991 - val_accuracy: 0.9726 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9984    \n",
      "Epoch 43: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1111 - accuracy: 0.9984 - val_loss: 0.3453 - val_accuracy: 0.9754 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9991    \n",
      "Epoch 44: val_accuracy improved from 0.97614 to 0.97684, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.0265 - accuracy: 0.9991 - val_loss: 0.1236 - val_accuracy: 0.9768 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9970    \n",
      "Epoch 45: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1524 - accuracy: 0.9970 - val_loss: 0.3739 - val_accuracy: 0.9740 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.9932\n",
      "Epoch 46: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.3667 - accuracy: 0.9932 - val_loss: 1.0289 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9953\n",
      "Epoch 47: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.2770 - accuracy: 0.9953 - val_loss: 0.7552 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9921\n",
      "Epoch 48: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2520 - accuracy: 0.9921 - val_loss: 0.8481 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9963    \n",
      "Epoch 49: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2142 - accuracy: 0.9963 - val_loss: 0.5512 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.9972    \n",
      "Epoch 50: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.5102 - accuracy: 0.9972 - val_loss: 1.2844 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9981    \n",
      "Epoch 51: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0962 - accuracy: 0.9981 - val_loss: 0.8298 - val_accuracy: 0.9726 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 4.947596291031073e-06.\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9979\n",
      "Epoch 52: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1431 - accuracy: 0.9979 - val_loss: 0.5009 - val_accuracy: 0.9628 - lr: 4.9476e-06\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 4.895741811804884e-06.\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9963    \n",
      "Epoch 53: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.2212 - accuracy: 0.9963 - val_loss: 0.2218 - val_accuracy: 0.9740 - lr: 4.8957e-06\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 4.844430805986317e-06.\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9979    \n",
      "Epoch 54: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2342 - accuracy: 0.9979 - val_loss: 0.8224 - val_accuracy: 0.9565 - lr: 4.8444e-06\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 4.793657577570914e-06.\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9972\n",
      "Epoch 55: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1794 - accuracy: 0.9972 - val_loss: 0.4793 - val_accuracy: 0.9691 - lr: 4.7937e-06\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 4.74341649025257e-06.\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9979    \n",
      "Epoch 56: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0444 - accuracy: 0.9979 - val_loss: 0.1798 - val_accuracy: 0.9705 - lr: 4.7434e-06\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 4.693701966797848e-06.\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.9972    \n",
      "Epoch 57: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.2702 - accuracy: 0.9972 - val_loss: 1.0027 - val_accuracy: 0.9698 - lr: 4.6937e-06\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 4.644508488426855e-06.\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9972    \n",
      "Epoch 58: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0719 - accuracy: 0.9972 - val_loss: 0.3496 - val_accuracy: 0.9712 - lr: 4.6445e-06\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 4.595830594200608e-06.\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9981\n",
      "Epoch 59: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0837 - accuracy: 0.9981 - val_loss: 0.7080 - val_accuracy: 0.9649 - lr: 4.5958e-06\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 4.547662880414811e-06.\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9984\n",
      "Epoch 60: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0447 - accuracy: 0.9984 - val_loss: 0.6059 - val_accuracy: 0.9544 - lr: 4.5477e-06\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 4.5e-06.\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9909\n",
      "Epoch 61: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.1704 - accuracy: 0.9909 - val_loss: 0.3422 - val_accuracy: 0.9684 - lr: 4.5000e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 4.452836661927965e-06.\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.9981    \n",
      "Epoch 62: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.3085 - accuracy: 0.9981 - val_loss: 0.7556 - val_accuracy: 0.9705 - lr: 4.4528e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 4.406167630624396e-06.\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9988    \n",
      "Epoch 63: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0318 - accuracy: 0.9988 - val_loss: 0.4010 - val_accuracy: 0.9733 - lr: 4.4062e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 4.359987725387685e-06.\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9979    \n",
      "Epoch 64: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1330 - accuracy: 0.9979 - val_loss: 0.3598 - val_accuracy: 0.9740 - lr: 4.3600e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 4.314291819813823e-06.\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9979    \n",
      "Epoch 65: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0698 - accuracy: 0.9979 - val_loss: 0.1673 - val_accuracy: 0.9719 - lr: 4.3143e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 4.269074841227312e-06.\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9998    \n",
      "Epoch 66: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0341 - accuracy: 0.9998 - val_loss: 0.6038 - val_accuracy: 0.9754 - lr: 4.2691e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 4.224331770118063e-06.\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9991    \n",
      "Epoch 67: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0592 - accuracy: 0.9991 - val_loss: 0.4440 - val_accuracy: 0.9761 - lr: 4.2243e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 4.18005763958417e-06.\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9993    \n",
      "Epoch 68: val_accuracy improved from 0.97684 to 0.97754, saving model to model.keras\n",
      "134/134 [==============================] - 38s 273ms/step - loss: 0.0167 - accuracy: 0.9993 - val_loss: 0.1562 - val_accuracy: 0.9775 - lr: 4.1801e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 4.136247534780548e-06.\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9972    \n",
      "Epoch 69: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0911 - accuracy: 0.9972 - val_loss: 0.2748 - val_accuracy: 0.9733 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 4.09289659237333e-06.\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.9984    \n",
      "Epoch 70: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1937 - accuracy: 0.9984 - val_loss: 0.6159 - val_accuracy: 0.9747 - lr: 4.0929e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.05e-06.\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9988    \n",
      "Epoch 71: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0527 - accuracy: 0.9988 - val_loss: 0.3675 - val_accuracy: 0.9733 - lr: 4.0500e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.007552995735169e-06.\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9984    \n",
      "Epoch 72: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0869 - accuracy: 0.9984 - val_loss: 0.4206 - val_accuracy: 0.9733 - lr: 4.0076e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.965550867561957e-06.\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9981    \n",
      "Epoch 73: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1143 - accuracy: 0.9981 - val_loss: 0.5450 - val_accuracy: 0.9740 - lr: 3.9656e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.923988952848917e-06.\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9981    \n",
      "Epoch 74: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0848 - accuracy: 0.9981 - val_loss: 0.2578 - val_accuracy: 0.9719 - lr: 3.9240e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.882862637832441e-06.\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9977\n",
      "Epoch 75: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0621 - accuracy: 0.9977 - val_loss: 0.3593 - val_accuracy: 0.9719 - lr: 3.8829e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 3.842167357104582e-06.\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9972\n",
      "Epoch 76: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0774 - accuracy: 0.9972 - val_loss: 0.5439 - val_accuracy: 0.9691 - lr: 3.8422e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 3.8018985931062567e-06.\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9981    \n",
      "Epoch 77: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1178 - accuracy: 0.9981 - val_loss: 0.5958 - val_accuracy: 0.9775 - lr: 3.8019e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 3.7620518756257528e-06.\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9970    \n",
      "Epoch 78: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1269 - accuracy: 0.9970 - val_loss: 0.4012 - val_accuracy: 0.9740 - lr: 3.7621e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 3.722622781302493e-06.\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9991    \n",
      "Epoch 79: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0547 - accuracy: 0.9991 - val_loss: 0.4998 - val_accuracy: 0.9733 - lr: 3.7226e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 3.6836069331359973e-06.\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9988    \n",
      "Epoch 80: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0443 - accuracy: 0.9988 - val_loss: 0.2673 - val_accuracy: 0.9747 - lr: 3.6836e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 3.6450000000000007e-06.\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9988    \n",
      "Epoch 81: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0681 - accuracy: 0.9988 - val_loss: 0.4963 - val_accuracy: 0.9740 - lr: 3.6450e-06\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 3.606797696161652e-06.\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9984    \n",
      "Epoch 82: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0530 - accuracy: 0.9984 - val_loss: 0.1843 - val_accuracy: 0.9761 - lr: 3.6068e-06\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 3.568995780805761e-06.\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9981    \n",
      "Epoch 83: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.1143 - accuracy: 0.9981 - val_loss: 0.5720 - val_accuracy: 0.9740 - lr: 3.5690e-06\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 3.5315900575640257e-06.\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9972    \n",
      "Epoch 84: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.1139 - accuracy: 0.9972 - val_loss: 0.3029 - val_accuracy: 0.9740 - lr: 3.5316e-06\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 3.4945763740491965e-06.\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9986    \n",
      "Epoch 85: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.1616 - accuracy: 0.9986 - val_loss: 0.9759 - val_accuracy: 0.9726 - lr: 3.4946e-06\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 3.4579506213941233e-06.\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9993    \n",
      "Epoch 86: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0192 - accuracy: 0.9993 - val_loss: 0.3117 - val_accuracy: 0.9740 - lr: 3.4580e-06\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 3.421708733795631e-06.\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9998    \n",
      "Epoch 87: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0075 - accuracy: 0.9998 - val_loss: 0.3890 - val_accuracy: 0.9719 - lr: 3.4217e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 3.385846688063178e-06.\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9998    \n",
      "Epoch 88: val_accuracy did not improve from 0.97754\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 0.2348 - val_accuracy: 0.9754 - lr: 3.3858e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 3.3503605031722434e-06.\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9981    \n",
      "Epoch 89: val_accuracy improved from 0.97754 to 0.97825, saving model to model.keras\n",
      "134/134 [==============================] - 38s 271ms/step - loss: 0.0471 - accuracy: 0.9981 - val_loss: 0.1285 - val_accuracy: 0.9782 - lr: 3.3504e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 3.3152462398223976e-06.\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9986    \n",
      "Epoch 90: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1092 - accuracy: 0.9986 - val_loss: 0.7146 - val_accuracy: 0.9740 - lr: 3.3152e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 3.2805e-06.\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9988    \n",
      "Epoch 91: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0186 - accuracy: 0.9988 - val_loss: 0.1726 - val_accuracy: 0.9768 - lr: 3.2805e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 3.2461179265454873e-06.\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9988    \n",
      "Epoch 92: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0203 - accuracy: 0.9988 - val_loss: 0.1818 - val_accuracy: 0.9775 - lr: 3.2461e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 3.2120962027251853e-06.\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9986    \n",
      "Epoch 93: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0831 - accuracy: 0.9986 - val_loss: 0.3385 - val_accuracy: 0.9754 - lr: 3.2121e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 3.1784310518076235e-06.\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9984    \n",
      "Epoch 94: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0486 - accuracy: 0.9984 - val_loss: 0.2145 - val_accuracy: 0.9775 - lr: 3.1784e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 3.145118736644277e-06.\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9984    \n",
      "Epoch 95: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0528 - accuracy: 0.9984 - val_loss: 0.3713 - val_accuracy: 0.9747 - lr: 3.1451e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.1121555592547107e-06.\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9984    \n",
      "Epoch 96: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0487 - accuracy: 0.9984 - val_loss: 0.3540 - val_accuracy: 0.9747 - lr: 3.1122e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.079537860416068e-06.\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9991    \n",
      "Epoch 97: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0301 - accuracy: 0.9991 - val_loss: 0.7057 - val_accuracy: 0.9691 - lr: 3.0795e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.04726201925686e-06.\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9906\n",
      "Epoch 98: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0525 - accuracy: 0.9906 - val_loss: 0.7442 - val_accuracy: 0.9691 - lr: 3.0473e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 3.0153244528550195e-06.\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9991    \n",
      "Epoch 99: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0189 - accuracy: 0.9991 - val_loss: 0.2668 - val_accuracy: 0.9747 - lr: 3.0153e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.9837216158401577e-06.\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9991    \n",
      "Epoch 100: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0398 - accuracy: 0.9991 - val_loss: 0.3480 - val_accuracy: 0.9691 - lr: 2.9837e-06\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 2.9524500000000004e-06.\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9988    \n",
      "Epoch 101: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0545 - accuracy: 0.9988 - val_loss: 0.5051 - val_accuracy: 0.9719 - lr: 2.9524e-06\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 2.9215061338909385e-06.\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9981    \n",
      "Epoch 102: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0674 - accuracy: 0.9981 - val_loss: 0.2453 - val_accuracy: 0.9754 - lr: 2.9215e-06\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 2.8908865824526666e-06.\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9988    \n",
      "Epoch 103: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0820 - accuracy: 0.9988 - val_loss: 0.7398 - val_accuracy: 0.9740 - lr: 2.8909e-06\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 2.860587946626861e-06.\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9993    \n",
      "Epoch 104: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.2131 - val_accuracy: 0.9761 - lr: 2.8606e-06\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 2.8306068629798496e-06.\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9986    \n",
      "Epoch 105: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0375 - accuracy: 0.9986 - val_loss: 0.1436 - val_accuracy: 0.9782 - lr: 2.8306e-06\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 2.80094000332924e-06.\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9988    \n",
      "Epoch 106: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0595 - accuracy: 0.9988 - val_loss: 0.5052 - val_accuracy: 0.9726 - lr: 2.8009e-06\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 2.7715840743744617e-06.\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9998    \n",
      "Epoch 107: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.2159 - val_accuracy: 0.9782 - lr: 2.7716e-06\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 2.7425358173311744e-06.\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9995    \n",
      "Epoch 108: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0179 - accuracy: 0.9995 - val_loss: 0.1783 - val_accuracy: 0.9761 - lr: 2.7425e-06\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 2.7137920075695175e-06.\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9991    \n",
      "Epoch 109: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.1642 - val_accuracy: 0.9768 - lr: 2.7138e-06\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 2.685349454256142e-06.\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9995    \n",
      "Epoch 110: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.2079 - val_accuracy: 0.9782 - lr: 2.6853e-06\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 2.6572050000000005e-06.\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9995    \n",
      "Epoch 111: val_accuracy did not improve from 0.97825\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.1490 - val_accuracy: 0.9768 - lr: 2.6572e-06\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 2.6293555205018443e-06.\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9986    \n",
      "Epoch 112: val_accuracy improved from 0.97825 to 0.97895, saving model to model.keras\n",
      "134/134 [==============================] - 38s 273ms/step - loss: 0.0200 - accuracy: 0.9986 - val_loss: 0.1912 - val_accuracy: 0.9789 - lr: 2.6294e-06\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 2.6017979242073997e-06.\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9988    \n",
      "Epoch 113: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.1105 - accuracy: 0.9988 - val_loss: 0.7077 - val_accuracy: 0.9761 - lr: 2.6018e-06\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 2.5745291519641747e-06.\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9991    \n",
      "Epoch 114: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0140 - accuracy: 0.9991 - val_loss: 0.1442 - val_accuracy: 0.9789 - lr: 2.5745e-06\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 2.5475461766818645e-06.\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9988    \n",
      "Epoch 115: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0257 - accuracy: 0.9988 - val_loss: 0.4004 - val_accuracy: 0.9768 - lr: 2.5475e-06\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 2.520846002996316e-06.\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9988    \n",
      "Epoch 116: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0341 - accuracy: 0.9988 - val_loss: 0.3589 - val_accuracy: 0.9740 - lr: 2.5208e-06\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 2.4944256669370153e-06.\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9991    \n",
      "Epoch 117: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0266 - accuracy: 0.9991 - val_loss: 0.2608 - val_accuracy: 0.9768 - lr: 2.4944e-06\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 2.4682822355980567e-06.\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9993    \n",
      "Epoch 118: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0194 - accuracy: 0.9993 - val_loss: 0.1803 - val_accuracy: 0.9782 - lr: 2.4683e-06\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 2.4424128068125657e-06.\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9991    \n",
      "Epoch 119: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0229 - accuracy: 0.9991 - val_loss: 0.3063 - val_accuracy: 0.9775 - lr: 2.4424e-06\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 2.416814508830528e-06.\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9988    \n",
      "Epoch 120: val_accuracy did not improve from 0.97895\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0398 - accuracy: 0.9988 - val_loss: 0.5309 - val_accuracy: 0.9740 - lr: 2.4168e-06\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 2.3914845000000004e-06.\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9993    \n",
      "Epoch 121: val_accuracy improved from 0.97895 to 0.97965, saving model to model.keras\n",
      "134/134 [==============================] - 38s 272ms/step - loss: 0.0191 - accuracy: 0.9993 - val_loss: 0.2713 - val_accuracy: 0.9796 - lr: 2.3915e-06\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 2.3664199684516603e-06.\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9991    \n",
      "Epoch 122: val_accuracy improved from 0.97965 to 0.98035, saving model to model.keras\n",
      "134/134 [==============================] - 37s 271ms/step - loss: 0.0279 - accuracy: 0.9991 - val_loss: 0.1814 - val_accuracy: 0.9804 - lr: 2.3664e-06\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 2.34161813178666e-06.\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9998    \n",
      "Epoch 123: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0080 - accuracy: 0.9998 - val_loss: 0.3431 - val_accuracy: 0.9789 - lr: 2.3416e-06\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 2.3170762367677574e-06.\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9993    \n",
      "Epoch 124: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0220 - accuracy: 0.9993 - val_loss: 0.3591 - val_accuracy: 0.9768 - lr: 2.3171e-06\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 2.2927915590136778e-06.\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9991    \n",
      "Epoch 125: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0234 - accuracy: 0.9991 - val_loss: 0.1409 - val_accuracy: 0.9782 - lr: 2.2928e-06\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 2.2687614026966843e-06.\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9991    \n",
      "Epoch 126: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0210 - accuracy: 0.9991 - val_loss: 0.2717 - val_accuracy: 0.9768 - lr: 2.2688e-06\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 2.244983100243314e-06.\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9984    \n",
      "Epoch 127: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0242 - accuracy: 0.9984 - val_loss: 0.1818 - val_accuracy: 0.9768 - lr: 2.2450e-06\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 2.2214540120382515e-06.\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9988\n",
      "Epoch 128: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0136 - accuracy: 0.9988 - val_loss: 0.4116 - val_accuracy: 0.9621 - lr: 2.2215e-06\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 2.1981715261313094e-06.\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9981\n",
      "Epoch 129: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0750 - accuracy: 0.9981 - val_loss: 0.2749 - val_accuracy: 0.9705 - lr: 2.1982e-06\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 2.175133057947475e-06.\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9991    \n",
      "Epoch 130: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0217 - accuracy: 0.9991 - val_loss: 0.3253 - val_accuracy: 0.9719 - lr: 2.1751e-06\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 2.1523360500000007e-06.\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9988    \n",
      "Epoch 131: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0166 - accuracy: 0.9988 - val_loss: 0.1892 - val_accuracy: 0.9733 - lr: 2.1523e-06\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 2.1297779716064944e-06.\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9981    \n",
      "Epoch 132: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0394 - accuracy: 0.9981 - val_loss: 0.1906 - val_accuracy: 0.9733 - lr: 2.1298e-06\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 2.107456318607994e-06.\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9986    \n",
      "Epoch 133: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0976 - accuracy: 0.9986 - val_loss: 0.2049 - val_accuracy: 0.9761 - lr: 2.1075e-06\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 2.0853686130909814e-06.\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9988    \n",
      "Epoch 134: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0277 - accuracy: 0.9988 - val_loss: 0.2614 - val_accuracy: 0.9705 - lr: 2.0854e-06\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 2.0635124031123102e-06.\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9993    \n",
      "Epoch 135: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0171 - accuracy: 0.9993 - val_loss: 0.2932 - val_accuracy: 0.9733 - lr: 2.0635e-06\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 2.041885262427016e-06.\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9993    \n",
      "Epoch 136: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0176 - accuracy: 0.9993 - val_loss: 0.3790 - val_accuracy: 0.9712 - lr: 2.0419e-06\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 2.0204847902189826e-06.\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9993    \n",
      "Epoch 137: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.1880 - val_accuracy: 0.9775 - lr: 2.0205e-06\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 1.9993086108344263e-06.\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9998    \n",
      "Epoch 138: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.1496 - val_accuracy: 0.9782 - lr: 1.9993e-06\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 1.9783543735181783e-06.\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 139: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.3564 - val_accuracy: 0.9754 - lr: 1.9784e-06\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 1.957619752152728e-06.\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9993    \n",
      "Epoch 140: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0241 - accuracy: 0.9993 - val_loss: 0.2245 - val_accuracy: 0.9761 - lr: 1.9576e-06\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 1.9371024450000008e-06.\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9993    \n",
      "Epoch 141: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 262ms/step - loss: 0.0118 - accuracy: 0.9993 - val_loss: 0.2094 - val_accuracy: 0.9754 - lr: 1.9371e-06\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 1.9168001744458447e-06.\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.7495e-04 - accuracy: 1.0000\n",
      "Epoch 142: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.7495e-04 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9726 - lr: 1.9168e-06\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 1.8967106867471949e-06.\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9993    \n",
      "Epoch 143: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.2228 - val_accuracy: 0.9747 - lr: 1.8967e-06\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 1.8768317517818835e-06.\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9993    \n",
      "Epoch 144: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.2235 - val_accuracy: 0.9740 - lr: 1.8768e-06\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 1.8571611628010794e-06.\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.3551e-04 - accuracy: 0.9998\n",
      "Epoch 145: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.3551e-04 - accuracy: 0.9998 - val_loss: 0.1540 - val_accuracy: 0.9782 - lr: 1.8572e-06\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 1.8376967361843146e-06.\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9986    \n",
      "Epoch 146: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0461 - accuracy: 0.9986 - val_loss: 0.2790 - val_accuracy: 0.9768 - lr: 1.8377e-06\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 1.8184363111970844e-06.\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9981    \n",
      "Epoch 147: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0472 - accuracy: 0.9981 - val_loss: 0.2464 - val_accuracy: 0.9733 - lr: 1.8184e-06\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 1.7993777497509838e-06.\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9986    \n",
      "Epoch 148: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0409 - accuracy: 0.9986 - val_loss: 0.2208 - val_accuracy: 0.9775 - lr: 1.7994e-06\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 1.7805189361663605e-06.\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9991    \n",
      "Epoch 149: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0203 - accuracy: 0.9991 - val_loss: 0.1819 - val_accuracy: 0.9754 - lr: 1.7805e-06\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 1.7618577769374552e-06.\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.9466e-04 - accuracy: 0.9998\n",
      "Epoch 150: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 5.9466e-04 - accuracy: 0.9998 - val_loss: 0.2911 - val_accuracy: 0.9726 - lr: 1.7619e-06\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 1.7433922005000006e-06.\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9988    \n",
      "Epoch 151: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0311 - accuracy: 0.9988 - val_loss: 0.2600 - val_accuracy: 0.9754 - lr: 1.7434e-06\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 1.7251201570012604e-06.\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9995    \n",
      "Epoch 152: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.1692 - val_accuracy: 0.9754 - lr: 1.7251e-06\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 1.7070396180724754e-06.\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9991    \n",
      "Epoch 153: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0160 - accuracy: 0.9991 - val_loss: 0.2488 - val_accuracy: 0.9754 - lr: 1.7070e-06\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 1.6891485766036953e-06.\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9993    \n",
      "Epoch 154: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0120 - accuracy: 0.9993 - val_loss: 0.1608 - val_accuracy: 0.9768 - lr: 1.6891e-06\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 1.6714450465209714e-06.\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4293e-04 - accuracy: 0.9998\n",
      "Epoch 155: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 2.4293e-04 - accuracy: 0.9998 - val_loss: 0.1644 - val_accuracy: 0.9768 - lr: 1.6714e-06\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 1.6539270625658833e-06.\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998    \n",
      "Epoch 156: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 261ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2527 - val_accuracy: 0.9754 - lr: 1.6539e-06\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 1.636592680077376e-06.\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 157: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2271 - val_accuracy: 0.9768 - lr: 1.6366e-06\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 1.6194399747758854e-06.\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.0409e-06 - accuracy: 1.0000\n",
      "Epoch 158: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.0409e-06 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9747 - lr: 1.6194e-06\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 1.6024670425497244e-06.\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.4149e-06 - accuracy: 1.0000\n",
      "Epoch 159: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 6.4149e-06 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9726 - lr: 1.6025e-06\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 1.5856719992437097e-06.\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.7755e-05 - accuracy: 1.0000\n",
      "Epoch 160: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.7755e-05 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9754 - lr: 1.5857e-06\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 1.5690529804500005e-06.\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.3132e-04 - accuracy: 0.9998\n",
      "Epoch 161: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 6.3132e-04 - accuracy: 0.9998 - val_loss: 0.2007 - val_accuracy: 0.9740 - lr: 1.5691e-06\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 1.5526081413011344e-06.\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.7178e-04 - accuracy: 0.9998\n",
      "Epoch 162: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.7178e-04 - accuracy: 0.9998 - val_loss: 0.2612 - val_accuracy: 0.9747 - lr: 1.5526e-06\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 1.536335656265228e-06.\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9993    \n",
      "Epoch 163: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.2367 - val_accuracy: 0.9761 - lr: 1.5363e-06\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 1.5202337189433255e-06.\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9988    \n",
      "Epoch 164: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0383 - accuracy: 0.9988 - val_loss: 0.3359 - val_accuracy: 0.9747 - lr: 1.5202e-06\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 1.5043005418688744e-06.\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9993    \n",
      "Epoch 165: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 0.2076 - val_accuracy: 0.9754 - lr: 1.5043e-06\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 1.4885343563092948e-06.\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 166: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2099 - val_accuracy: 0.9768 - lr: 1.4885e-06\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 1.4729334120696384e-06.\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.9128e-04 - accuracy: 0.9998\n",
      "Epoch 167: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.9128e-04 - accuracy: 0.9998 - val_loss: 0.2406 - val_accuracy: 0.9761 - lr: 1.4729e-06\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 1.457495977298297e-06.\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993    \n",
      "Epoch 168: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.2908 - val_accuracy: 0.9754 - lr: 1.4575e-06\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 1.442220338294752e-06.\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.7088e-06 - accuracy: 1.0000\n",
      "Epoch 169: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 4.7088e-06 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9775 - lr: 1.4422e-06\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 1.4271047993193388e-06.\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9988    \n",
      "Epoch 170: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0377 - accuracy: 0.9988 - val_loss: 0.2680 - val_accuracy: 0.9754 - lr: 1.4271e-06\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 1.4121476824050007e-06.\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9991    \n",
      "Epoch 171: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0194 - accuracy: 0.9991 - val_loss: 0.6185 - val_accuracy: 0.9726 - lr: 1.4121e-06\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 1.397347327171021e-06.\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9995    \n",
      "Epoch 172: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0131 - accuracy: 0.9995 - val_loss: 0.2702 - val_accuracy: 0.9768 - lr: 1.3973e-06\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 1.382702090638705e-06.\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9993    \n",
      "Epoch 173: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.3061 - val_accuracy: 0.9761 - lr: 1.3827e-06\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 1.3682103470489933e-06.\n",
      "Epoch 174/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995    \n",
      "Epoch 174: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.2548 - val_accuracy: 0.9761 - lr: 1.3682e-06\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 1.353870487681987e-06.\n",
      "Epoch 175/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9991    \n",
      "Epoch 175: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1960 - val_accuracy: 0.9768 - lr: 1.3539e-06\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 1.3396809206783653e-06.\n",
      "Epoch 176/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9993    \n",
      "Epoch 176: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0182 - accuracy: 0.9993 - val_loss: 0.2057 - val_accuracy: 0.9782 - lr: 1.3397e-06\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 1.3256400708626746e-06.\n",
      "Epoch 177/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9993    \n",
      "Epoch 177: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0174 - accuracy: 0.9993 - val_loss: 0.1617 - val_accuracy: 0.9775 - lr: 1.3256e-06\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 1.3117463795684674e-06.\n",
      "Epoch 178/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9988    \n",
      "Epoch 178: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0434 - accuracy: 0.9988 - val_loss: 0.5153 - val_accuracy: 0.9747 - lr: 1.3117e-06\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 1.297998304465277e-06.\n",
      "Epoch 179/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9998    \n",
      "Epoch 179: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 0.2175 - val_accuracy: 0.9754 - lr: 1.2980e-06\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 1.2843943193874047e-06.\n",
      "Epoch 180/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9995    \n",
      "Epoch 180: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 0.3253 - val_accuracy: 0.9754 - lr: 1.2844e-06\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 1.2709329141645005e-06.\n",
      "Epoch 181/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9991    \n",
      "Epoch 181: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0228 - accuracy: 0.9991 - val_loss: 0.2029 - val_accuracy: 0.9761 - lr: 1.2709e-06\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 1.2576125944539188e-06.\n",
      "Epoch 182/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9988    \n",
      "Epoch 182: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0352 - accuracy: 0.9988 - val_loss: 0.2146 - val_accuracy: 0.9761 - lr: 1.2576e-06\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 1.2444318815748347e-06.\n",
      "Epoch 183/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 183: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.2498 - val_accuracy: 0.9719 - lr: 1.2444e-06\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 1.2313893123440938e-06.\n",
      "Epoch 184/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9995    \n",
      "Epoch 184: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.2152 - val_accuracy: 0.9768 - lr: 1.2314e-06\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 1.2184834389137882e-06.\n",
      "Epoch 185/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9991    \n",
      "Epoch 185: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0170 - accuracy: 0.9991 - val_loss: 0.2904 - val_accuracy: 0.9761 - lr: 1.2185e-06\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 1.205712828610529e-06.\n",
      "Epoch 186/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9988    \n",
      "Epoch 186: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0204 - accuracy: 0.9988 - val_loss: 0.1749 - val_accuracy: 0.9761 - lr: 1.2057e-06\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 1.193076063776407e-06.\n",
      "Epoch 187/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.9251e-06 - accuracy: 1.0000\n",
      "Epoch 187: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 2.9251e-06 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9719 - lr: 1.1931e-06\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 1.1805717416116205e-06.\n",
      "Epoch 188/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9995    \n",
      "Epoch 188: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.1864 - val_accuracy: 0.9761 - lr: 1.1806e-06\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 1.1681984740187491e-06.\n",
      "Epoch 189/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9998    \n",
      "Epoch 189: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.2715 - val_accuracy: 0.9726 - lr: 1.1682e-06\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 1.1559548874486644e-06.\n",
      "Epoch 190/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9993    \n",
      "Epoch 190: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0146 - accuracy: 0.9993 - val_loss: 0.1730 - val_accuracy: 0.9754 - lr: 1.1560e-06\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 1.1438396227480505e-06.\n",
      "Epoch 191/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9998    \n",
      "Epoch 191: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.2432 - val_accuracy: 0.9761 - lr: 1.1438e-06\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 1.1318513350085272e-06.\n",
      "Epoch 192/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 192: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.2285 - val_accuracy: 0.9768 - lr: 1.1319e-06\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 1.1199886934173512e-06.\n",
      "Epoch 193/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9993    \n",
      "Epoch 193: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.2562 - val_accuracy: 0.9775 - lr: 1.1200e-06\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 1.1082503811096846e-06.\n",
      "Epoch 194/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9993    \n",
      "Epoch 194: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 260ms/step - loss: 0.0106 - accuracy: 0.9993 - val_loss: 0.3461 - val_accuracy: 0.9754 - lr: 1.1083e-06\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 1.0966350950224095e-06.\n",
      "Epoch 195/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9998    \n",
      "Epoch 195: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.3062 - val_accuracy: 0.9761 - lr: 1.0966e-06\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 1.085141545749476e-06.\n",
      "Epoch 196/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9995    \n",
      "Epoch 196: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.2372 - val_accuracy: 0.9782 - lr: 1.0851e-06\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 1.0737684573987664e-06.\n",
      "Epoch 197/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9995    \n",
      "Epoch 197: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.2250 - val_accuracy: 0.9754 - lr: 1.0738e-06\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 1.0625145674504587e-06.\n",
      "Epoch 198/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.4714e-06 - accuracy: 1.0000\n",
      "Epoch 198: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.4714e-06 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9782 - lr: 1.0625e-06\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 1.0513786266168744e-06.\n",
      "Epoch 199/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.3006e-06 - accuracy: 1.0000\n",
      "Epoch 199: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.3006e-06 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9775 - lr: 1.0514e-06\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 1.040359398703798e-06.\n",
      "Epoch 200/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998    \n",
      "Epoch 200: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.2050 - val_accuracy: 0.9782 - lr: 1.0404e-06\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 1.0294556604732455e-06.\n",
      "Epoch 201/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9993    \n",
      "Epoch 201: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0150 - accuracy: 0.9993 - val_loss: 0.2462 - val_accuracy: 0.9761 - lr: 1.0295e-06\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 1.0186662015076745e-06.\n",
      "Epoch 202/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9995    \n",
      "Epoch 202: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.2725 - val_accuracy: 0.9754 - lr: 1.0187e-06\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 1.0079898240756162e-06.\n",
      "Epoch 203/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9995    \n",
      "Epoch 203: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0117 - accuracy: 0.9995 - val_loss: 0.3774 - val_accuracy: 0.9733 - lr: 1.0080e-06\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 9.97425342998716e-07.\n",
      "Epoch 204/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9988    \n",
      "Epoch 204: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0162 - accuracy: 0.9988 - val_loss: 0.1780 - val_accuracy: 0.9775 - lr: 9.9743e-07\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 9.869715855201684e-07.\n",
      "Epoch 205/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9991    \n",
      "Epoch 205: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0203 - accuracy: 0.9991 - val_loss: 0.3265 - val_accuracy: 0.9740 - lr: 9.8697e-07\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 9.766273911745284e-07.\n",
      "Epoch 206/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9993    \n",
      "Epoch 206: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0112 - accuracy: 0.9993 - val_loss: 0.1837 - val_accuracy: 0.9775 - lr: 9.7663e-07\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 9.663916116588897e-07.\n",
      "Epoch 207/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.4120e-06 - accuracy: 1.0000\n",
      "Epoch 207: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 4.4120e-06 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9754 - lr: 9.6639e-07\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 9.562631107054127e-07.\n",
      "Epoch 208/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995    \n",
      "Epoch 208: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.1970 - val_accuracy: 0.9761 - lr: 9.5626e-07\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 9.46240763955187e-07.\n",
      "Epoch 209/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.8765e-04 - accuracy: 0.9998\n",
      "Epoch 209: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 4.8765e-04 - accuracy: 0.9998 - val_loss: 0.1751 - val_accuracy: 0.9775 - lr: 9.4624e-07\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 9.363234588334182e-07.\n",
      "Epoch 210/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 210: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.2393 - val_accuracy: 0.9761 - lr: 9.3632e-07\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 9.265100944259209e-07.\n",
      "Epoch 211/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 211: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1798 - val_accuracy: 0.9768 - lr: 9.2651e-07\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 9.167995813569068e-07.\n",
      "Epoch 212/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998    \n",
      "Epoch 212: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1941 - val_accuracy: 0.9754 - lr: 9.1680e-07\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 9.071908416680546e-07.\n",
      "Epoch 213/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9995    \n",
      "Epoch 213: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.2234 - val_accuracy: 0.9768 - lr: 9.0719e-07\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 8.976828086988444e-07.\n",
      "Epoch 214/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993    \n",
      "Epoch 214: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.2814 - val_accuracy: 0.9754 - lr: 8.9768e-07\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 8.882744269681519e-07.\n",
      "Epoch 215/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998    \n",
      "Epoch 215: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4391 - val_accuracy: 0.9740 - lr: 8.8827e-07\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 8.789646520570756e-07.\n",
      "Epoch 216/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 216: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.1911 - val_accuracy: 0.9768 - lr: 8.7896e-07\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 8.697524504930006e-07.\n",
      "Epoch 217/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998    \n",
      "Epoch 217: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.2987 - val_accuracy: 0.9733 - lr: 8.6975e-07\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 8.606367996348715e-07.\n",
      "Epoch 218/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9704e-06 - accuracy: 1.0000\n",
      "Epoch 218: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.9704e-06 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9747 - lr: 8.6064e-07\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 8.516166875596682e-07.\n",
      "Epoch 219/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6410e-04 - accuracy: 0.9998\n",
      "Epoch 219: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.6410e-04 - accuracy: 0.9998 - val_loss: 0.2216 - val_accuracy: 0.9747 - lr: 8.5162e-07\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 8.426911129500766e-07.\n",
      "Epoch 220/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9995    \n",
      "Epoch 220: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0123 - accuracy: 0.9995 - val_loss: 0.1928 - val_accuracy: 0.9775 - lr: 8.4269e-07\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 8.338590849833289e-07.\n",
      "Epoch 221/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998    \n",
      "Epoch 221: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.2707 - val_accuracy: 0.9747 - lr: 8.3386e-07\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 8.251196232212161e-07.\n",
      "Epoch 222/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 222: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3435 - val_accuracy: 0.9740 - lr: 8.2512e-07\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 8.164717575012492e-07.\n",
      "Epoch 223/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9998    \n",
      "Epoch 223: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.2657 - val_accuracy: 0.9761 - lr: 8.1647e-07\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 8.0791452782896e-07.\n",
      "Epoch 224/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.8743e-04 - accuracy: 0.9998\n",
      "Epoch 224: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 7.8743e-04 - accuracy: 0.9998 - val_loss: 0.2943 - val_accuracy: 0.9726 - lr: 8.0791e-07\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 7.994469842713366e-07.\n",
      "Epoch 225/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4486e-06 - accuracy: 1.0000\n",
      "Epoch 225: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.4486e-06 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9733 - lr: 7.9945e-07\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 7.910681868513681e-07.\n",
      "Epoch 226/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9995    \n",
      "Epoch 226: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.2276 - val_accuracy: 0.9754 - lr: 7.9107e-07\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 7.827772054437007e-07.\n",
      "Epoch 227/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9995    \n",
      "Epoch 227: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.2424 - val_accuracy: 0.9719 - lr: 7.8278e-07\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 7.745731196713843e-07.\n",
      "Epoch 228/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9998    \n",
      "Epoch 228: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.2541 - val_accuracy: 0.9754 - lr: 7.7457e-07\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 7.664550188037015e-07.\n",
      "Epoch 229/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998    \n",
      "Epoch 229: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.2264 - val_accuracy: 0.9733 - lr: 7.6646e-07\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 7.584220016550689e-07.\n",
      "Epoch 230/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9998    \n",
      "Epoch 230: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.2429 - val_accuracy: 0.9726 - lr: 7.5842e-07\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 7.50473176484996e-07.\n",
      "Epoch 231/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.2628e-05 - accuracy: 1.0000\n",
      "Epoch 231: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 3.2628e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9740 - lr: 7.5047e-07\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 7.426076608990945e-07.\n",
      "Epoch 232/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9993    \n",
      "Epoch 232: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.3101 - val_accuracy: 0.9726 - lr: 7.4261e-07\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 7.348245817511242e-07.\n",
      "Epoch 233/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9995    \n",
      "Epoch 233: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.2203 - val_accuracy: 0.9754 - lr: 7.3482e-07\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 7.27123075046064e-07.\n",
      "Epoch 234/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.7056e-06 - accuracy: 1.0000\n",
      "Epoch 234: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.7056e-06 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9733 - lr: 7.2712e-07\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 7.19502285844203e-07.\n",
      "Epoch 235/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998    \n",
      "Epoch 235: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.4530 - val_accuracy: 0.9719 - lr: 7.1950e-07\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 7.119613681662313e-07.\n",
      "Epoch 236/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1323e-06 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.1323e-06 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9747 - lr: 7.1196e-07\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 7.044994848993306e-07.\n",
      "Epoch 237/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998    \n",
      "Epoch 237: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.2750 - val_accuracy: 0.9712 - lr: 7.0450e-07\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 6.971158077042459e-07.\n",
      "Epoch 238/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1601e-06 - accuracy: 1.0000\n",
      "Epoch 238: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1601e-06 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9712 - lr: 6.9712e-07\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 6.898095169233313e-07.\n",
      "Epoch 239/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1806e-06 - accuracy: 1.0000\n",
      "Epoch 239: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1806e-06 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9740 - lr: 6.8981e-07\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 6.825798014895621e-07.\n",
      "Epoch 240/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9995    \n",
      "Epoch 240: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 0.2675 - val_accuracy: 0.9726 - lr: 6.8258e-07\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 6.754258588364965e-07.\n",
      "Epoch 241/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9993    \n",
      "Epoch 241: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0143 - accuracy: 0.9993 - val_loss: 0.2395 - val_accuracy: 0.9740 - lr: 6.7543e-07\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 6.683468948091851e-07.\n",
      "Epoch 242/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.6917e-07 - accuracy: 1.0000\n",
      "Epoch 242: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 7.6917e-07 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9740 - lr: 6.6835e-07\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 6.613421235760118e-07.\n",
      "Epoch 243/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995    \n",
      "Epoch 243: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.2168 - val_accuracy: 0.9754 - lr: 6.6134e-07\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 6.544107675414577e-07.\n",
      "Epoch 244/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4434e-06 - accuracy: 1.0000\n",
      "Epoch 244: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.4434e-06 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9775 - lr: 6.5441e-07\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 6.475520572597828e-07.\n",
      "Epoch 245/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998    \n",
      "Epoch 245: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.2377 - val_accuracy: 0.9754 - lr: 6.4755e-07\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 6.407652313496082e-07.\n",
      "Epoch 246/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.1964e-07 - accuracy: 1.0000\n",
      "Epoch 246: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 4.1964e-07 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9754 - lr: 6.4077e-07\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 6.340495364093975e-07.\n",
      "Epoch 247/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.6328e-07 - accuracy: 1.0000\n",
      "Epoch 247: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.6328e-07 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9754 - lr: 6.3405e-07\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 6.274042269338214e-07.\n",
      "Epoch 248/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.4572e-07 - accuracy: 1.0000\n",
      "Epoch 248: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.4572e-07 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9740 - lr: 6.2740e-07\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 6.208285652309982e-07.\n",
      "Epoch 249/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.8622e-06 - accuracy: 1.0000\n",
      "Epoch 249: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.8622e-06 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9761 - lr: 6.2083e-07\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 6.143218213406059e-07.\n",
      "Epoch 250/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.6419e-04 - accuracy: 0.9995\n",
      "Epoch 250: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 9.6419e-04 - accuracy: 0.9995 - val_loss: 0.2678 - val_accuracy: 0.9747 - lr: 6.1432e-07\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 6.078832729528468e-07.\n",
      "Epoch 251/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.7531e-05 - accuracy: 1.0000\n",
      "Epoch 251: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.7531e-05 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9740 - lr: 6.0788e-07\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 6.015122053282667e-07.\n",
      "Epoch 252/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998    \n",
      "Epoch 252: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.2149 - val_accuracy: 0.9740 - lr: 6.0151e-07\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 5.952079112184107e-07.\n",
      "Epoch 253/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9995    \n",
      "Epoch 253: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.2447 - val_accuracy: 0.9747 - lr: 5.9521e-07\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 5.889696907873119e-07.\n",
      "Epoch 254/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9998    \n",
      "Epoch 254: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.2901 - val_accuracy: 0.9733 - lr: 5.8897e-07\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 5.827968515338045e-07.\n",
      "Epoch 255/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.9363e-07 - accuracy: 1.0000\n",
      "Epoch 255: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.9363e-07 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9754 - lr: 5.8280e-07\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 5.766887082146474e-07.\n",
      "Epoch 256/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9998    \n",
      "Epoch 256: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.2011 - val_accuracy: 0.9747 - lr: 5.7669e-07\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 5.706445827684578e-07.\n",
      "Epoch 257/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998    \n",
      "Epoch 257: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2059 - val_accuracy: 0.9768 - lr: 5.7064e-07\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 5.646638042404392e-07.\n",
      "Epoch 258/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9998    \n",
      "Epoch 258: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.2731 - val_accuracy: 0.9740 - lr: 5.6466e-07\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 5.587457087078984e-07.\n",
      "Epoch 259/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9993    \n",
      "Epoch 259: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0105 - accuracy: 0.9993 - val_loss: 0.3012 - val_accuracy: 0.9726 - lr: 5.5875e-07\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 5.528896392065452e-07.\n",
      "Epoch 260/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998    \n",
      "Epoch 260: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.2724 - val_accuracy: 0.9754 - lr: 5.5289e-07\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 5.470949456575622e-07.\n",
      "Epoch 261/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9998    \n",
      "Epoch 261: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.3486 - val_accuracy: 0.9747 - lr: 5.4709e-07\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 5.4136098479544e-07.\n",
      "Epoch 262/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998    \n",
      "Epoch 262: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.2661 - val_accuracy: 0.9747 - lr: 5.4136e-07\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 5.356871200965696e-07.\n",
      "Epoch 263/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.6259e-07 - accuracy: 1.0000\n",
      "Epoch 263: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 3.6259e-07 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9740 - lr: 5.3569e-07\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 5.300727217085808e-07.\n",
      "Epoch 264/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5160e-05 - accuracy: 1.0000\n",
      "Epoch 264: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 2.5160e-05 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9747 - lr: 5.3007e-07\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 5.24517166380424e-07.\n",
      "Epoch 265/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.9052e-06 - accuracy: 1.0000\n",
      "Epoch 265: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 5.9052e-06 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9747 - lr: 5.2452e-07\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 5.190198373931827e-07.\n",
      "Epoch 266/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.8934e-07 - accuracy: 1.0000\n",
      "Epoch 266: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 2.8934e-07 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9726 - lr: 5.1902e-07\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 5.13580124491612e-07.\n",
      "Epoch 267/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4154e-05 - accuracy: 1.0000\n",
      "Epoch 267: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 1.4154e-05 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9733 - lr: 5.1358e-07\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 5.081974238163953e-07.\n",
      "Epoch 268/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.3512e-07 - accuracy: 1.0000\n",
      "Epoch 268: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 7.3512e-07 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9740 - lr: 5.0820e-07\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 5.028711378371086e-07.\n",
      "Epoch 269/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6073e-04 - accuracy: 1.0000\n",
      "Epoch 269: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.6073e-04 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9733 - lr: 5.0287e-07\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 4.976006752858908e-07.\n",
      "Epoch 270/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4173e-07 - accuracy: 1.0000\n",
      "Epoch 270: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 2.4173e-07 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9719 - lr: 4.9760e-07\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 4.92385451091806e-07.\n",
      "Epoch 271/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998    \n",
      "Epoch 271: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.3177 - val_accuracy: 0.9726 - lr: 4.9239e-07\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 4.87224886315896e-07.\n",
      "Epoch 272/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.8076e-04 - accuracy: 0.9998\n",
      "Epoch 272: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.8076e-04 - accuracy: 0.9998 - val_loss: 0.2282 - val_accuracy: 0.9754 - lr: 4.8722e-07\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 4.821184080869126e-07.\n",
      "Epoch 273/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1711e-06 - accuracy: 1.0000\n",
      "Epoch 273: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.1711e-06 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9747 - lr: 4.8212e-07\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 4.770654495377228e-07.\n",
      "Epoch 274/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.3742e-06 - accuracy: 1.0000\n",
      "Epoch 274: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 261ms/step - loss: 3.3742e-06 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9754 - lr: 4.7707e-07\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 4.7206544974238163e-07.\n",
      "Epoch 275/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9998    \n",
      "Epoch 275: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.2178 - val_accuracy: 0.9761 - lr: 4.7207e-07\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 4.671178536538644e-07.\n",
      "Epoch 276/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.2391e-04 - accuracy: 0.9995\n",
      "Epoch 276: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 4.2391e-04 - accuracy: 0.9995 - val_loss: 0.2800 - val_accuracy: 0.9733 - lr: 4.6712e-07\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 4.622221120424509e-07.\n",
      "Epoch 277/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998    \n",
      "Epoch 277: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.2574 - val_accuracy: 0.9754 - lr: 4.6222e-07\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 4.573776814347558e-07.\n",
      "Epoch 278/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.8208e-04 - accuracy: 0.9998\n",
      "Epoch 278: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.8208e-04 - accuracy: 0.9998 - val_loss: 0.2637 - val_accuracy: 0.9754 - lr: 4.5738e-07\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 4.5258402405339773e-07.\n",
      "Epoch 279/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993    \n",
      "Epoch 279: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.2572 - val_accuracy: 0.9754 - lr: 4.5258e-07\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 4.478406077573017e-07.\n",
      "Epoch 280/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998    \n",
      "Epoch 280: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.2169 - val_accuracy: 0.9761 - lr: 4.4784e-07\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 4.431469059826254e-07.\n",
      "Epoch 281/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1907e-07 - accuracy: 1.0000\n",
      "Epoch 281: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.1907e-07 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9754 - lr: 4.4315e-07\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 4.385023976843064e-07.\n",
      "Epoch 282/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9995    \n",
      "Epoch 282: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.2727 - val_accuracy: 0.9733 - lr: 4.3850e-07\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 4.339065672782214e-07.\n",
      "Epoch 283/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.2532e-05 - accuracy: 1.0000\n",
      "Epoch 283: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.2532e-05 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9733 - lr: 4.3391e-07\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 4.2935890458395047e-07.\n",
      "Epoch 284/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995    \n",
      "Epoch 284: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.3753 - val_accuracy: 0.9747 - lr: 4.2936e-07\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 4.248589047681435e-07.\n",
      "Epoch 285/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4800e-07 - accuracy: 1.0000\n",
      "Epoch 285: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.4800e-07 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9747 - lr: 4.2486e-07\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 4.20406068288478e-07.\n",
      "Epoch 286/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3153e-07 - accuracy: 1.0000\n",
      "Epoch 286: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.3153e-07 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9740 - lr: 4.2041e-07\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 4.159999008382058e-07.\n",
      "Epoch 287/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995    \n",
      "Epoch 287: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2200 - val_accuracy: 0.9754 - lr: 4.1600e-07\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 4.1163991329128023e-07.\n",
      "Epoch 288/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.4149e-06 - accuracy: 1.0000\n",
      "Epoch 288: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 3.4149e-06 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9726 - lr: 4.1164e-07\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 4.0732562164805795e-07.\n",
      "Epoch 289/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4245e-07 - accuracy: 1.0000\n",
      "Epoch 289: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.4245e-07 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9733 - lr: 4.0733e-07\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 4.0305654698157156e-07.\n",
      "Epoch 290/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.1833e-05 - accuracy: 1.0000\n",
      "Epoch 290: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 6.1833e-05 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9747 - lr: 4.0306e-07\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 3.988322153843628e-07.\n",
      "Epoch 291/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5968e-07 - accuracy: 1.0000\n",
      "Epoch 291: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.5968e-07 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9733 - lr: 3.9883e-07\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 3.9465215791587575e-07.\n",
      "Epoch 292/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9351e-07 - accuracy: 1.0000\n",
      "Epoch 292: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.9351e-07 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9768 - lr: 3.9465e-07\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 3.905159105503992e-07.\n",
      "Epoch 293/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3381e-07 - accuracy: 1.0000\n",
      "Epoch 293: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.3381e-07 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9733 - lr: 3.9052e-07\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 3.864230141255554e-07.\n",
      "Epoch 294/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2710e-07 - accuracy: 1.0000\n",
      "Epoch 294: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.2710e-07 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9740 - lr: 3.8642e-07\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 3.823730142913291e-07.\n",
      "Epoch 295/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.1568e-04 - accuracy: 0.9998\n",
      "Epoch 295: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 2.1568e-04 - accuracy: 0.9998 - val_loss: 0.2417 - val_accuracy: 0.9754 - lr: 3.8237e-07\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 3.783654614596302e-07.\n",
      "Epoch 296/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5139e-04 - accuracy: 1.0000\n",
      "Epoch 296: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.5139e-04 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9754 - lr: 3.7837e-07\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 3.743999107543852e-07.\n",
      "Epoch 297/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995    \n",
      "Epoch 297: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2929 - val_accuracy: 0.9761 - lr: 3.7440e-07\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 3.704759219621522e-07.\n",
      "Epoch 298/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.5269e-04 - accuracy: 0.9998\n",
      "Epoch 298: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.5269e-04 - accuracy: 0.9998 - val_loss: 0.2834 - val_accuracy: 0.9754 - lr: 3.7048e-07\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 3.665930594832522e-07.\n",
      "Epoch 299/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.6836e-06 - accuracy: 1.0000\n",
      "Epoch 299: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 7.6836e-06 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9740 - lr: 3.6659e-07\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 3.627508922834144e-07.\n",
      "Epoch 300/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995    \n",
      "Epoch 300: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2607 - val_accuracy: 0.9740 - lr: 3.6275e-07\n",
      "\n",
      "Epoch 301: LearningRateScheduler setting learning rate to 3.5894899384592653e-07.\n",
      "Epoch 301/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.7317e-05 - accuracy: 1.0000\n",
      "Epoch 301: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 3.7317e-05 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9768 - lr: 3.5895e-07\n",
      "\n",
      "Epoch 302: LearningRateScheduler setting learning rate to 3.551869421242882e-07.\n",
      "Epoch 302/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1004e-07 - accuracy: 1.0000\n",
      "Epoch 302: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 258ms/step - loss: 1.1004e-07 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9754 - lr: 3.5519e-07\n",
      "\n",
      "Epoch 303: LearningRateScheduler setting learning rate to 3.514643194953593e-07.\n",
      "Epoch 303/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.4819e-05 - accuracy: 1.0000\n",
      "Epoch 303: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 4.4819e-05 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9761 - lr: 3.5146e-07\n",
      "\n",
      "Epoch 304: LearningRateScheduler setting learning rate to 3.477807127129999e-07.\n",
      "Epoch 304/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1831e-06 - accuracy: 1.0000\n",
      "Epoch 304: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.1831e-06 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9754 - lr: 3.4778e-07\n",
      "\n",
      "Epoch 305: LearningRateScheduler setting learning rate to 3.4413571286219623e-07.\n",
      "Epoch 305/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 305: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.2737 - val_accuracy: 0.9768 - lr: 3.4414e-07\n",
      "\n",
      "Epoch 306: LearningRateScheduler setting learning rate to 3.405289153136672e-07.\n",
      "Epoch 306/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6698e-07 - accuracy: 1.0000\n",
      "Epoch 306: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.6698e-07 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9761 - lr: 3.4053e-07\n",
      "\n",
      "Epoch 307: LearningRateScheduler setting learning rate to 3.369599196789467e-07.\n",
      "Epoch 307/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.4592e-06 - accuracy: 1.0000\n",
      "Epoch 307: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 8.4592e-06 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9761 - lr: 3.3696e-07\n",
      "\n",
      "Epoch 308: LearningRateScheduler setting learning rate to 3.33428329765937e-07.\n",
      "Epoch 308/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1584e-05 - accuracy: 1.0000\n",
      "Epoch 308: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.1584e-05 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9761 - lr: 3.3343e-07\n",
      "\n",
      "Epoch 309: LearningRateScheduler setting learning rate to 3.2993375353492693e-07.\n",
      "Epoch 309/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.7108e-04 - accuracy: 0.9998\n",
      "Epoch 309: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 3.7108e-04 - accuracy: 0.9998 - val_loss: 0.2962 - val_accuracy: 0.9754 - lr: 3.2993e-07\n",
      "\n",
      "Epoch 310: LearningRateScheduler setting learning rate to 3.26475803055073e-07.\n",
      "Epoch 310/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9998    \n",
      "Epoch 310: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.2270 - val_accuracy: 0.9761 - lr: 3.2648e-07\n",
      "\n",
      "Epoch 311: LearningRateScheduler setting learning rate to 3.230540944613339e-07.\n",
      "Epoch 311/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0544e-07 - accuracy: 1.0000\n",
      "Epoch 311: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.0544e-07 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9740 - lr: 3.2305e-07\n",
      "\n",
      "Epoch 312: LearningRateScheduler setting learning rate to 3.196682479118594e-07.\n",
      "Epoch 312/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995    \n",
      "Epoch 312: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3751 - val_accuracy: 0.9740 - lr: 3.1967e-07\n",
      "\n",
      "Epoch 313: LearningRateScheduler setting learning rate to 3.1631788754582345e-07.\n",
      "Epoch 313/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.0729e-06 - accuracy: 1.0000\n",
      "Epoch 313: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 6.0729e-06 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9761 - lr: 3.1632e-07\n",
      "\n",
      "Epoch 314: LearningRateScheduler setting learning rate to 3.1300264144169984e-07.\n",
      "Epoch 314/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4623e-07 - accuracy: 1.0000\n",
      "Epoch 314: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 2.4623e-07 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9754 - lr: 3.1300e-07\n",
      "\n",
      "Epoch 315: LearningRateScheduler setting learning rate to 3.0972214157597667e-07.\n",
      "Epoch 315/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998    \n",
      "Epoch 315: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.2131 - val_accuracy: 0.9761 - lr: 3.0972e-07\n",
      "\n",
      "Epoch 316: LearningRateScheduler setting learning rate to 3.0647602378230047e-07.\n",
      "Epoch 316/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9998    \n",
      "Epoch 316: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.2908 - val_accuracy: 0.9740 - lr: 3.0648e-07\n",
      "\n",
      "Epoch 317: LearningRateScheduler setting learning rate to 3.0326392771105206e-07.\n",
      "Epoch 317/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4541e-07 - accuracy: 1.0000\n",
      "Epoch 317: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.4541e-07 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9747 - lr: 3.0326e-07\n",
      "\n",
      "Epoch 318: LearningRateScheduler setting learning rate to 3.000854967893433e-07.\n",
      "Epoch 318/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2947e-07 - accuracy: 1.0000\n",
      "Epoch 318: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 1.2947e-07 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9740 - lr: 3.0009e-07\n",
      "\n",
      "Epoch 319: LearningRateScheduler setting learning rate to 2.9694037818143425e-07.\n",
      "Epoch 319/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9993    \n",
      "Epoch 319: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.2573 - val_accuracy: 0.9733 - lr: 2.9694e-07\n",
      "\n",
      "Epoch 320: LearningRateScheduler setting learning rate to 2.9382822274956565e-07.\n",
      "Epoch 320/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4839e-07 - accuracy: 1.0000\n",
      "Epoch 320: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 1.4839e-07 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9747 - lr: 2.9383e-07\n",
      "\n",
      "Epoch 321: LearningRateScheduler setting learning rate to 2.907486850152005e-07.\n",
      "Epoch 321/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995    \n",
      "Epoch 321: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.2368 - val_accuracy: 0.9747 - lr: 2.9075e-07\n",
      "\n",
      "Epoch 322: LearningRateScheduler setting learning rate to 2.8770142312067344e-07.\n",
      "Epoch 322/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3759e-05 - accuracy: 1.0000\n",
      "Epoch 322: val_accuracy did not improve from 0.98035\n",
      "134/134 [==============================] - 36s 259ms/step - loss: 1.3759e-05 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9754 - lr: 2.8770e-07\n",
      "Epoch 322: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            model.name + '.keras',\n",
    "            monitor='val_accuracy',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='auto',\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            min_delta=0,\n",
    "            patience=200,\n",
    "            verbose=1,\n",
    "            mode='auto',\n",
    "        ),\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            learning_rate_schedule,\n",
    "            verbose=1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Save history\n",
    "dataframe = pd.DataFrame(model_history.history)\n",
    "dataframe.to_csv(\"history.csv\", index_label=\"model_name\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17c357",
   "metadata": {
    "papermill": {
     "duration": 3.682542,
     "end_time": "2024-06-02T20:32:47.061260",
     "exception": false,
     "start_time": "2024-06-02T20:32:43.378718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testando o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "076d3e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T20:32:54.516664Z",
     "iopub.status.busy": "2024-06-02T20:32:54.515919Z",
     "iopub.status.idle": "2024-06-02T20:33:23.310757Z",
     "shell.execute_reply": "2024-06-02T20:33:23.309889Z"
    },
    "papermill": {
     "duration": 32.484317,
     "end_time": "2024-06-02T20:33:23.312960",
     "exception": false,
     "start_time": "2024-06-02T20:32:50.828643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      COVID19       0.98      0.97      0.98       116\n",
      "       NORMAL       0.96      0.93      0.95       318\n",
      "    PNEUMONIA       0.98      0.98      0.98       856\n",
      "TURBERCULOSIS       0.98      0.99      0.98       140\n",
      "\n",
      "     accuracy                           0.97      1430\n",
      "    macro avg       0.97      0.97      0.97      1430\n",
      " weighted avg       0.97      0.97      0.97      1430\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = tf.keras.saving.load_model(\"model.keras\")\n",
    "y_true, y_pred = get_true_and_predicted_labels(model, test_dataset)\n",
    "\n",
    "model_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Saving confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true, y_pred,\n",
    "    display_labels=classes\n",
    ")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "plot_model_history(model_history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1592399,
     "sourceId": 2619910,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11846.679114,
   "end_time": "2024-06-02T20:33:29.599288",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-02T17:16:02.920174",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
