{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2c4581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:47:29.840803Z",
     "iopub.status.busy": "2024-06-08T15:47:29.840394Z",
     "iopub.status.idle": "2024-06-08T15:48:00.632370Z",
     "shell.execute_reply": "2024-06-08T15:48:00.631230Z"
    },
    "papermill": {
     "duration": 30.800662,
     "end_time": "2024-06-08T15:48:00.634816",
     "exception": false,
     "start_time": "2024-06-08T15:47:29.834154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\r\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\r\n",
      "Installing collected packages: split-folders\r\n",
      "Successfully installed split-folders-0.5.1\r\n",
      "Requirement already satisfied: tf_keras in /opt/conda/lib/python3.10/site-packages (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tf_keras) (2.15.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (1.59.3)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf_keras) (2.15.0)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15->tf_keras)\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf_keras) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (2.32.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (3.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.16,>=2.15->tf_keras) (3.1.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf_keras) (3.2.2)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed keras-2.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /kaggle/working/*\n",
    "\n",
    "!pip install split-folders\n",
    "!pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b5689f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:00.649538Z",
     "iopub.status.busy": "2024-06-08T15:48:00.649140Z",
     "iopub.status.idle": "2024-06-08T15:48:14.473708Z",
     "shell.execute_reply": "2024-06-08T15:48:14.472753Z"
    },
    "id": "MMpVa0OcPGGj",
    "papermill": {
     "duration": 13.834506,
     "end_time": "2024-06-08T15:48:14.475972",
     "exception": false,
     "start_time": "2024-06-08T15:48:00.641466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 15:48:02.374035: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-08 15:48:02.374143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-08 15:48:02.499561: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "\n",
    "from typing import List\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802f8361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:14.490914Z",
     "iopub.status.busy": "2024-06-08T15:48:14.489856Z",
     "iopub.status.idle": "2024-06-08T15:48:14.505887Z",
     "shell.execute_reply": "2024-06-08T15:48:14.505180Z"
    },
    "id": "n2c0Ur2eNIbH",
    "papermill": {
     "duration": 0.025718,
     "end_time": "2024-06-08T15:48:14.508123",
     "exception": false,
     "start_time": "2024-06-08T15:48:14.482405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3d3c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:14.522484Z",
     "iopub.status.busy": "2024-06-08T15:48:14.521922Z",
     "iopub.status.idle": "2024-06-08T15:48:14.533475Z",
     "shell.execute_reply": "2024-06-08T15:48:14.532632Z"
    },
    "papermill": {
     "duration": 0.020555,
     "end_time": "2024-06-08T15:48:14.535405",
     "exception": false,
     "start_time": "2024-06-08T15:48:14.514850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_rmdir(folder):\n",
    "    for item in os.listdir(folder):\n",
    "        item_path = os.path.join(folder, item)\n",
    "        \n",
    "        if os.path.isdir(item_path):\n",
    "            recursive_rmdir(item_path)\n",
    "            os.rmdir(item_path)\n",
    "        else:\n",
    "            os.remove(item_path)\n",
    "            \n",
    "\n",
    "def organize_dataset(source_folder, destination_folder):    \n",
    "    if os.path.exists(destination_folder):\n",
    "        recursive_rmdir(destination_folder)\n",
    "    \n",
    "    # Discover all classes\n",
    "    classes = set()\n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        current_folder = os.path.join(source_folder, subfolder)\n",
    "        discovered_classes = os.listdir(current_folder)\n",
    "        classes = classes.union(discovered_classes)\n",
    "    classes = list(classes)\n",
    "    classes.sort()\n",
    "\n",
    "    # Create a folder for each class\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.mkdir(destination_folder)\n",
    "    \n",
    "    for _class in classes:\n",
    "        class_directory = os.path.join(destination_folder, _class)\n",
    "        os.mkdir(class_directory)\n",
    "    \n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        current_path = os.path.join(source_folder, subfolder)\n",
    "        for class_folder in os.listdir(current_path):\n",
    "            current_path = os.path.join(source_folder, subfolder, class_folder)\n",
    "            for file in os.listdir(current_path):\n",
    "                \n",
    "                file_source_path = os.path.join(\n",
    "                    source_folder,\n",
    "                    subfolder,\n",
    "                    class_folder,\n",
    "                    file\n",
    "                )\n",
    "                \n",
    "                file_destination_path = os.path.join(\n",
    "                    destination_folder,\n",
    "                    class_folder,\n",
    "                    file\n",
    "                )\n",
    "                \n",
    "                shutil.copy2(\n",
    "                    file_source_path,\n",
    "                    file_destination_path,\n",
    "                )\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9cee36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:14.549391Z",
     "iopub.status.busy": "2024-06-08T15:48:14.549088Z",
     "iopub.status.idle": "2024-06-08T15:48:14.554944Z",
     "shell.execute_reply": "2024-06-08T15:48:14.554012Z"
    },
    "id": "G3-UpbprWm2B",
    "papermill": {
     "duration": 0.015332,
     "end_time": "2024-06-08T15:48:14.557050",
     "exception": false,
     "start_time": "2024-06-08T15:48:14.541718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_validation_split(\n",
    "    source: str,\n",
    "    destination: str,\n",
    "    seed: int | None = None\n",
    "):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(999999)\n",
    "    print(f\"Dataset's split seed is {seed}\")\n",
    "\n",
    "    if not os.path.isdir(destination):\n",
    "        splitfolders.ratio(source, output=destination,\n",
    "            seed=seed, ratio=(.6, .2, .2), move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a8e493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:14.570997Z",
     "iopub.status.busy": "2024-06-08T15:48:14.570721Z",
     "iopub.status.idle": "2024-06-08T15:48:14.578325Z",
     "shell.execute_reply": "2024-06-08T15:48:14.577421Z"
    },
    "id": "aNagWAB7IPwC",
    "papermill": {
     "duration": 0.016979,
     "end_time": "2024-06-08T15:48:14.580381",
     "exception": false,
     "start_time": "2024-06-08T15:48:14.563402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_history(history):\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(6, 4.4))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('loss')\n",
    "    ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af708fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:14.594752Z",
     "iopub.status.busy": "2024-06-08T15:48:14.594208Z",
     "iopub.status.idle": "2024-06-08T15:48:14.600180Z",
     "shell.execute_reply": "2024-06-08T15:48:14.599263Z"
    },
    "id": "7Qo2uteJsmP4",
    "papermill": {
     "duration": 0.015395,
     "end_time": "2024-06-08T15:48:14.602229",
     "exception": false,
     "start_time": "2024-06-08T15:48:14.586834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_true_and_predicted_labels(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for X_batch, y_batch in dataset:\n",
    "        y_batch_pred = np.argmax(model.predict(X_batch, verbose=0), axis=1)\n",
    "        \n",
    "        y_true.append(y_batch)\n",
    "        y_pred.append(y_batch_pred)\n",
    "    \n",
    "    y_true = [y_batch.numpy() for y_batch in y_true]\n",
    "    \n",
    "    return np.concatenate(y_true), np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48749654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:48:14.616908Z",
     "iopub.status.busy": "2024-06-08T15:48:14.616595Z",
     "iopub.status.idle": "2024-06-08T15:49:31.802377Z",
     "shell.execute_reply": "2024-06-08T15:49:31.801228Z"
    },
    "id": "ZrBCEYY3kVeL",
    "outputId": "af100c6b-d715-41ad-c463-435d0aa1a173",
    "papermill": {
     "duration": 77.198225,
     "end_time": "2024-06-08T15:49:31.807331",
     "exception": false,
     "start_time": "2024-06-08T15:48:14.609106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's split seed is 892471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7132 files [00:02, 2757.94 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['COVID19', 'NORMAL', 'PNEUMONIA', 'TURBERCULOSIS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = organize_dataset(\n",
    "    os.path.join(\"/\", \"kaggle\", \"input\", \"chest-xray-pneumoniacovid19tuberculosis\"),\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"temp\"),\n",
    ")\n",
    "train_test_validation_split(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"temp\"),\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\"),\n",
    "    seed=892471\n",
    ")\n",
    "\n",
    "print(\"Found classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5be0513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:49:31.846040Z",
     "iopub.status.busy": "2024-06-08T15:49:31.845256Z",
     "iopub.status.idle": "2024-06-08T15:49:34.737128Z",
     "shell.execute_reply": "2024-06-08T15:49:34.736327Z"
    },
    "papermill": {
     "duration": 2.913695,
     "end_time": "2024-06-08T15:49:34.739410",
     "exception": false,
     "start_time": "2024-06-08T15:49:31.825715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ TRAIN DATASET ]\n",
      "Found 4277 files belonging to 4 classes.\n",
      "\n",
      "[ VALIDATION DATASET ]\n",
      "Found 1425 files belonging to 4 classes.\n",
      "\n",
      "[ TEST DATASET ]\n",
      "Found 1430 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[ TRAIN DATASET ]\")\n",
    "train_dataset = train_set = keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"train\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(\"\\n[ VALIDATION DATASET ]\")\n",
    "validation_dataset = keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"val\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(\"\\n[ TEST DATASET ]\")\n",
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(\"/\", \"kaggle\", \"working\", \"dataset\", \"test\"),\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    interpolation='bilinear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5cb4a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:49:34.759325Z",
     "iopub.status.busy": "2024-06-08T15:49:34.758554Z",
     "iopub.status.idle": "2024-06-08T15:49:36.081882Z",
     "shell.execute_reply": "2024-06-08T15:49:36.080997Z"
    },
    "papermill": {
     "duration": 1.335981,
     "end_time": "2024-06-08T15:49:36.084562",
     "exception": false,
     "start_time": "2024-06-08T15:49:34.748581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg_16 = keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"max\",\n",
    ")\n",
    "\n",
    "for layer in vgg_16.layers:\n",
    "    layer.freeze = True\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.000005, name=\"optimizer\")\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(name=\"loss\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Rescaling(1./255),\n",
    "    vgg_16,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dense(4, activation=\"softmax\"),\n",
    "], name=\"model\")\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.build((None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8628668d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:49:36.107016Z",
     "iopub.status.busy": "2024-06-08T15:49:36.106184Z",
     "iopub.status.idle": "2024-06-08T15:49:36.112417Z",
     "shell.execute_reply": "2024-06-08T15:49:36.111433Z"
    },
    "papermill": {
     "duration": 0.019987,
     "end_time": "2024-06-08T15:49:36.114324",
     "exception": false,
     "start_time": "2024-06-08T15:49:36.094337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learning_rate_schedule(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return 0.000005\n",
    "    else:\n",
    "        return 0.000005 * 0.95 ** ((epoch - 50) / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba77102d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T15:49:36.135965Z",
     "iopub.status.busy": "2024-06-08T15:49:36.135131Z",
     "iopub.status.idle": "2024-06-08T21:01:16.102926Z",
     "shell.execute_reply": "2024-06-08T21:01:16.101863Z"
    },
    "id": "0nd5jsSFmE5J",
    "outputId": "b8a02719-59f6-4e2c-90cd-cbde47d69a46",
    "papermill": {
     "duration": 18705.891999,
     "end_time": "2024-06-08T21:01:22.016020",
     "exception": false,
     "start_time": "2024-06-08T15:49:36.124021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717861785.592026      87 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 0.7121 - accuracy: 0.8279\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93544, saving model to model.keras\n",
      "134/134 [==============================] - 64s 341ms/step - loss: 0.7121 - accuracy: 0.8279 - val_loss: 7.7879 - val_accuracy: 0.9354 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.9537\n",
      "Epoch 2: val_accuracy improved from 0.93544 to 0.95368, saving model to model.keras\n",
      "134/134 [==============================] - 38s 275ms/step - loss: 0.3029 - accuracy: 0.9537 - val_loss: 18.6388 - val_accuracy: 0.9537 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.9656\n",
      "Epoch 3: val_accuracy improved from 0.95368 to 0.95649, saving model to model.keras\n",
      "134/134 [==============================] - 38s 278ms/step - loss: 0.8756 - accuracy: 0.9656 - val_loss: 21.4250 - val_accuracy: 0.9565 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.9799\n",
      "Epoch 4: val_accuracy improved from 0.95649 to 0.96211, saving model to model.keras\n",
      "134/134 [==============================] - 38s 276ms/step - loss: 0.4941 - accuracy: 0.9799 - val_loss: 25.7432 - val_accuracy: 0.9621 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.9783\n",
      "Epoch 5: val_accuracy improved from 0.96211 to 0.96351, saving model to model.keras\n",
      "134/134 [==============================] - 38s 277ms/step - loss: 0.5961 - accuracy: 0.9783 - val_loss: 21.4118 - val_accuracy: 0.9635 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9895\n",
      "Epoch 6: val_accuracy did not improve from 0.96351\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.2175 - accuracy: 0.9895 - val_loss: 27.5923 - val_accuracy: 0.9607 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8798 - accuracy: 0.9878\n",
      "Epoch 7: val_accuracy did not improve from 0.96351\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.8798 - accuracy: 0.9878 - val_loss: 21.0025 - val_accuracy: 0.9635 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.9953\n",
      "Epoch 8: val_accuracy did not improve from 0.96351\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.3014 - accuracy: 0.9953 - val_loss: 22.1754 - val_accuracy: 0.9579 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9956\n",
      "Epoch 9: val_accuracy did not improve from 0.96351\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.3092 - accuracy: 0.9956 - val_loss: 39.5226 - val_accuracy: 0.9544 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.9960\n",
      "Epoch 10: val_accuracy did not improve from 0.96351\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.3173 - accuracy: 0.9960 - val_loss: 32.9876 - val_accuracy: 0.9628 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9960\n",
      "Epoch 11: val_accuracy did not improve from 0.96351\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0932 - accuracy: 0.9960 - val_loss: 26.8858 - val_accuracy: 0.9495 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9906\n",
      "Epoch 12: val_accuracy improved from 0.96351 to 0.96491, saving model to model.keras\n",
      "134/134 [==============================] - 38s 276ms/step - loss: 0.2611 - accuracy: 0.9906 - val_loss: 19.5436 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.9970\n",
      "Epoch 13: val_accuracy did not improve from 0.96491\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.4367 - accuracy: 0.9970 - val_loss: 37.4201 - val_accuracy: 0.9635 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9951\n",
      "Epoch 14: val_accuracy did not improve from 0.96491\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1146 - accuracy: 0.9951 - val_loss: 20.4743 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.9984\n",
      "Epoch 15: val_accuracy did not improve from 0.96491\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.3281 - accuracy: 0.9984 - val_loss: 32.4302 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9970\n",
      "Epoch 16: val_accuracy improved from 0.96491 to 0.96632, saving model to model.keras\n",
      "134/134 [==============================] - 38s 275ms/step - loss: 0.2451 - accuracy: 0.9970 - val_loss: 22.8941 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.9935\n",
      "Epoch 17: val_accuracy did not improve from 0.96632\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.4805 - accuracy: 0.9935 - val_loss: 34.3442 - val_accuracy: 0.9621 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9946\n",
      "Epoch 18: val_accuracy did not improve from 0.96632\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.2620 - accuracy: 0.9946 - val_loss: 23.8417 - val_accuracy: 0.9614 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.9977\n",
      "Epoch 19: val_accuracy did not improve from 0.96632\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.3568 - accuracy: 0.9977 - val_loss: 36.3634 - val_accuracy: 0.9621 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9956\n",
      "Epoch 20: val_accuracy improved from 0.96632 to 0.96772, saving model to model.keras\n",
      "134/134 [==============================] - 38s 276ms/step - loss: 0.1433 - accuracy: 0.9956 - val_loss: 21.8610 - val_accuracy: 0.9677 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.9977\n",
      "Epoch 21: val_accuracy improved from 0.96772 to 0.97123, saving model to model.keras\n",
      "134/134 [==============================] - 38s 275ms/step - loss: 0.5122 - accuracy: 0.9977 - val_loss: 10.4801 - val_accuracy: 0.9712 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9977\n",
      "Epoch 22: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.1712 - accuracy: 0.9977 - val_loss: 12.5177 - val_accuracy: 0.9698 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.9977\n",
      "Epoch 23: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1322 - accuracy: 0.9977 - val_loss: 39.2475 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.9853\n",
      "Epoch 24: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.3049 - accuracy: 0.9853 - val_loss: 12.0796 - val_accuracy: 0.9375 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9951\n",
      "Epoch 25: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1712 - accuracy: 0.9951 - val_loss: 26.1769 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.9951\n",
      "Epoch 26: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.4035 - accuracy: 0.9951 - val_loss: 16.8420 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.9970    \n",
      "Epoch 27: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.3643 - accuracy: 0.9970 - val_loss: 23.1716 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.9967\n",
      "Epoch 28: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.3262 - accuracy: 0.9967 - val_loss: 20.5006 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9984\n",
      "Epoch 29: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1576 - accuracy: 0.9984 - val_loss: 31.5530 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9965\n",
      "Epoch 30: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1115 - accuracy: 0.9965 - val_loss: 22.2052 - val_accuracy: 0.9677 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.9981\n",
      "Epoch 31: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.3202 - accuracy: 0.9981 - val_loss: 18.7354 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.9970\n",
      "Epoch 32: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.2911 - accuracy: 0.9970 - val_loss: 28.5296 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9869\n",
      "Epoch 33: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0602 - accuracy: 0.9869 - val_loss: 5.0171 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.9984\n",
      "Epoch 34: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.2506 - accuracy: 0.9984 - val_loss: 16.5848 - val_accuracy: 0.9642 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9963\n",
      "Epoch 35: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0836 - accuracy: 0.9963 - val_loss: 18.7659 - val_accuracy: 0.9677 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.9988    \n",
      "Epoch 36: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.3989 - accuracy: 0.9988 - val_loss: 17.6064 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9981\n",
      "Epoch 37: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1839 - accuracy: 0.9981 - val_loss: 22.1070 - val_accuracy: 0.9649 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.9956\n",
      "Epoch 38: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.2968 - accuracy: 0.9956 - val_loss: 22.1259 - val_accuracy: 0.9705 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9981    \n",
      "Epoch 39: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1769 - accuracy: 0.9981 - val_loss: 27.8474 - val_accuracy: 0.9684 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.9956\n",
      "Epoch 40: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.3177 - accuracy: 0.9956 - val_loss: 27.5299 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.9984    \n",
      "Epoch 41: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.4142 - accuracy: 0.9984 - val_loss: 15.7592 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.9974    \n",
      "Epoch 42: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.2714 - accuracy: 0.9974 - val_loss: 20.0919 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.9965    \n",
      "Epoch 43: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.3041 - accuracy: 0.9965 - val_loss: 22.7736 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9981    \n",
      "Epoch 44: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.2235 - accuracy: 0.9981 - val_loss: 17.0712 - val_accuracy: 0.9691 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9841\n",
      "Epoch 45: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1891 - accuracy: 0.9841 - val_loss: 7.3204 - val_accuracy: 0.9446 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.9967\n",
      "Epoch 46: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.3713 - accuracy: 0.9967 - val_loss: 18.0271 - val_accuracy: 0.9663 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9977\n",
      "Epoch 47: val_accuracy did not improve from 0.97123\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1230 - accuracy: 0.9977 - val_loss: 13.2024 - val_accuracy: 0.9684 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9984\n",
      "Epoch 48: val_accuracy improved from 0.97123 to 0.97404, saving model to model.keras\n",
      "134/134 [==============================] - 38s 277ms/step - loss: 0.0223 - accuracy: 0.9984 - val_loss: 11.4669 - val_accuracy: 0.9740 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9988    \n",
      "Epoch 49: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0518 - accuracy: 0.9988 - val_loss: 17.9758 - val_accuracy: 0.9677 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9988\n",
      "Epoch 50: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 18.0757 - val_accuracy: 0.9656 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9974    \n",
      "Epoch 51: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0998 - accuracy: 0.9974 - val_loss: 12.9605 - val_accuracy: 0.9670 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 4.99487330066384e-06.\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.9928\n",
      "Epoch 52: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.3435 - accuracy: 0.9928 - val_loss: 19.9311 - val_accuracy: 0.9572 - lr: 4.9949e-06\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 4.989751857936897e-06.\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9974\n",
      "Epoch 53: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1600 - accuracy: 0.9974 - val_loss: 22.4098 - val_accuracy: 0.9670 - lr: 4.9898e-06\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 4.9846356664293586e-06.\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9974    \n",
      "Epoch 54: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1190 - accuracy: 0.9974 - val_loss: 10.7591 - val_accuracy: 0.9740 - lr: 4.9846e-06\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 4.979524720756941e-06.\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.9984    \n",
      "Epoch 55: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.2996 - accuracy: 0.9984 - val_loss: 18.1307 - val_accuracy: 0.9698 - lr: 4.9795e-06\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 4.974419015540882e-06.\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9986    \n",
      "Epoch 56: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0418 - accuracy: 0.9986 - val_loss: 21.7225 - val_accuracy: 0.9691 - lr: 4.9744e-06\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 4.969318545407931e-06.\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9963    \n",
      "Epoch 57: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1748 - accuracy: 0.9963 - val_loss: 15.5602 - val_accuracy: 0.9712 - lr: 4.9693e-06\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 4.964223304990348e-06.\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9988    \n",
      "Epoch 58: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.2816 - accuracy: 0.9988 - val_loss: 17.4469 - val_accuracy: 0.9733 - lr: 4.9642e-06\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 4.9591332889258995e-06.\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.9974    \n",
      "Epoch 59: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.2780 - accuracy: 0.9974 - val_loss: 27.5123 - val_accuracy: 0.9684 - lr: 4.9591e-06\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 4.9540484918578455e-06.\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9963    \n",
      "Epoch 60: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.1423 - accuracy: 0.9963 - val_loss: 6.6640 - val_accuracy: 0.9740 - lr: 4.9540e-06\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 4.948968908434943e-06.\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9981\n",
      "Epoch 61: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.2591 - accuracy: 0.9981 - val_loss: 21.7833 - val_accuracy: 0.9691 - lr: 4.9490e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 4.943894533311433e-06.\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9984\n",
      "Epoch 62: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0387 - accuracy: 0.9984 - val_loss: 23.5818 - val_accuracy: 0.9677 - lr: 4.9439e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 4.938825361147037e-06.\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9953\n",
      "Epoch 63: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.2282 - accuracy: 0.9953 - val_loss: 20.6686 - val_accuracy: 0.9684 - lr: 4.9388e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 4.933761386606956e-06.\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5989 - accuracy: 0.9864\n",
      "Epoch 64: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.5989 - accuracy: 0.9864 - val_loss: 9.4275 - val_accuracy: 0.9495 - lr: 4.9338e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 4.928702604361859e-06.\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9960\n",
      "Epoch 65: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0714 - accuracy: 0.9960 - val_loss: 12.4851 - val_accuracy: 0.9684 - lr: 4.9287e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 4.923649009087875e-06.\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9984    \n",
      "Epoch 66: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0369 - accuracy: 0.9984 - val_loss: 10.7018 - val_accuracy: 0.9740 - lr: 4.9236e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 4.9186005954666e-06.\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9981    \n",
      "Epoch 67: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0572 - accuracy: 0.9981 - val_loss: 12.3930 - val_accuracy: 0.9733 - lr: 4.9186e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 4.913557358185077e-06.\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.9965    \n",
      "Epoch 68: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.2922 - accuracy: 0.9965 - val_loss: 11.3724 - val_accuracy: 0.9726 - lr: 4.9136e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 4.908519291935799e-06.\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9981    \n",
      "Epoch 69: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.2182 - accuracy: 0.9981 - val_loss: 15.0914 - val_accuracy: 0.9698 - lr: 4.9085e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 4.903486391416699e-06.\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9967    \n",
      "Epoch 70: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0847 - accuracy: 0.9967 - val_loss: 18.0196 - val_accuracy: 0.9684 - lr: 4.9035e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.898458651331149e-06.\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9972\n",
      "Epoch 71: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1690 - accuracy: 0.9972 - val_loss: 12.3458 - val_accuracy: 0.9670 - lr: 4.8985e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.893436066387952e-06.\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9970\n",
      "Epoch 72: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0676 - accuracy: 0.9970 - val_loss: 18.7331 - val_accuracy: 0.9691 - lr: 4.8934e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 4.888418631301333e-06.\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9986    \n",
      "Epoch 73: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 40s 288ms/step - loss: 0.2248 - accuracy: 0.9986 - val_loss: 20.4107 - val_accuracy: 0.9698 - lr: 4.8884e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 4.88340634079094e-06.\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9988    \n",
      "Epoch 74: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0124 - accuracy: 0.9988 - val_loss: 7.9954 - val_accuracy: 0.9684 - lr: 4.8834e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 4.878399189581833e-06.\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9986    \n",
      "Epoch 75: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0757 - accuracy: 0.9986 - val_loss: 10.6366 - val_accuracy: 0.9684 - lr: 4.8784e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 4.873397172404482e-06.\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9974    \n",
      "Epoch 76: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1071 - accuracy: 0.9974 - val_loss: 18.6688 - val_accuracy: 0.9684 - lr: 4.8734e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 4.86840028399476e-06.\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.9974\n",
      "Epoch 77: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1716 - accuracy: 0.9974 - val_loss: 10.3568 - val_accuracy: 0.9600 - lr: 4.8684e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 4.863408519093936e-06.\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 78: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 10.1984 - val_accuracy: 0.9670 - lr: 4.8634e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 4.858421872448673e-06.\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9993    \n",
      "Epoch 79: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 11.6795 - val_accuracy: 0.9698 - lr: 4.8584e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 4.853440338811019e-06.\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9979    \n",
      "Epoch 80: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0388 - accuracy: 0.9979 - val_loss: 11.8880 - val_accuracy: 0.9670 - lr: 4.8534e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 4.848463912938404e-06.\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9986    \n",
      "Epoch 81: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1607 - accuracy: 0.9986 - val_loss: 13.4702 - val_accuracy: 0.9670 - lr: 4.8485e-06\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 4.8434925895936324e-06.\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9988    \n",
      "Epoch 82: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0477 - accuracy: 0.9988 - val_loss: 23.4398 - val_accuracy: 0.9656 - lr: 4.8435e-06\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 4.838526363544879e-06.\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9979    \n",
      "Epoch 83: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0830 - accuracy: 0.9979 - val_loss: 13.6829 - val_accuracy: 0.9684 - lr: 4.8385e-06\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 4.833565229565682e-06.\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.9960    \n",
      "Epoch 84: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.3639 - accuracy: 0.9960 - val_loss: 16.8836 - val_accuracy: 0.9691 - lr: 4.8336e-06\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 4.828609182434942e-06.\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.9946\n",
      "Epoch 85: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.2905 - accuracy: 0.9946 - val_loss: 13.1579 - val_accuracy: 0.9691 - lr: 4.8286e-06\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 4.823658216936909e-06.\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9979\n",
      "Epoch 86: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1845 - accuracy: 0.9979 - val_loss: 9.8353 - val_accuracy: 0.9719 - lr: 4.8237e-06\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 4.818712327861182e-06.\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9979    \n",
      "Epoch 87: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0961 - accuracy: 0.9979 - val_loss: 8.5392 - val_accuracy: 0.9684 - lr: 4.8187e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 4.8137715100027035e-06.\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9986    \n",
      "Epoch 88: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1219 - accuracy: 0.9986 - val_loss: 14.3948 - val_accuracy: 0.9691 - lr: 4.8138e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 4.808835758161752e-06.\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9988    \n",
      "Epoch 89: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0417 - accuracy: 0.9988 - val_loss: 12.9772 - val_accuracy: 0.9705 - lr: 4.8088e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 4.803905067143938e-06.\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9979    \n",
      "Epoch 90: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0814 - accuracy: 0.9979 - val_loss: 13.0016 - val_accuracy: 0.9705 - lr: 4.8039e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 4.7989794317601966e-06.\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9965    \n",
      "Epoch 91: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1877 - accuracy: 0.9965 - val_loss: 17.0640 - val_accuracy: 0.9691 - lr: 4.7990e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 4.794058846826786e-06.\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9916\n",
      "Epoch 92: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1141 - accuracy: 0.9916 - val_loss: 6.8581 - val_accuracy: 0.9698 - lr: 4.7941e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 4.789143307165278e-06.\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.9967\n",
      "Epoch 93: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.3553 - accuracy: 0.9967 - val_loss: 3.2743 - val_accuracy: 0.9691 - lr: 4.7891e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.784232807602554e-06.\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9991    \n",
      "Epoch 94: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.1445 - accuracy: 0.9991 - val_loss: 8.0884 - val_accuracy: 0.9677 - lr: 4.7842e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.779327342970799e-06.\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9991    \n",
      "Epoch 95: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0770 - accuracy: 0.9991 - val_loss: 8.4965 - val_accuracy: 0.9663 - lr: 4.7793e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 4.774426908107499e-06.\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9991    \n",
      "Epoch 96: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 14.7892 - val_accuracy: 0.9670 - lr: 4.7744e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 4.769531497855431e-06.\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9993    \n",
      "Epoch 97: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0212 - accuracy: 0.9993 - val_loss: 3.6649 - val_accuracy: 0.9705 - lr: 4.7695e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 4.764641107062661e-06.\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.9965    \n",
      "Epoch 98: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.2473 - accuracy: 0.9965 - val_loss: 4.0674 - val_accuracy: 0.9733 - lr: 4.7646e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 4.7597557305825375e-06.\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9977\n",
      "Epoch 99: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1977 - accuracy: 0.9977 - val_loss: 9.0946 - val_accuracy: 0.9670 - lr: 4.7598e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 4.7548753632736845e-06.\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9921\n",
      "Epoch 100: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.2120 - accuracy: 0.9921 - val_loss: 5.8273 - val_accuracy: 0.9600 - lr: 4.7549e-06\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 4.75e-06.\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9986\n",
      "Epoch 101: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1320 - accuracy: 0.9986 - val_loss: 7.5721 - val_accuracy: 0.9691 - lr: 4.7500e-06\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 4.745129635630648e-06.\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9981\n",
      "Epoch 102: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0680 - accuracy: 0.9981 - val_loss: 9.7335 - val_accuracy: 0.9726 - lr: 4.7451e-06\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 4.7402642650400516e-06.\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9979    \n",
      "Epoch 103: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0689 - accuracy: 0.9979 - val_loss: 10.9003 - val_accuracy: 0.9719 - lr: 4.7403e-06\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 4.73540388310789e-06.\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9986    \n",
      "Epoch 104: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1884 - accuracy: 0.9986 - val_loss: 11.2380 - val_accuracy: 0.9719 - lr: 4.7354e-06\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 4.7305484847190945e-06.\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9991    \n",
      "Epoch 105: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0322 - accuracy: 0.9991 - val_loss: 13.7085 - val_accuracy: 0.9663 - lr: 4.7305e-06\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 4.7256980647638375e-06.\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9986    \n",
      "Epoch 106: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0349 - accuracy: 0.9986 - val_loss: 9.5708 - val_accuracy: 0.9733 - lr: 4.7257e-06\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 4.7208526181375334e-06.\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9981    \n",
      "Epoch 107: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1928 - accuracy: 0.9981 - val_loss: 3.7571 - val_accuracy: 0.9726 - lr: 4.7209e-06\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 4.716012139740831e-06.\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9972    \n",
      "Epoch 108: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1273 - accuracy: 0.9972 - val_loss: 9.0581 - val_accuracy: 0.9684 - lr: 4.7160e-06\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 4.711176624479603e-06.\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9909\n",
      "Epoch 109: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.2171 - accuracy: 0.9909 - val_loss: 9.0994 - val_accuracy: 0.9439 - lr: 4.7112e-06\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 4.706346067264953e-06.\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9981\n",
      "Epoch 110: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 8.6893 - val_accuracy: 0.9670 - lr: 4.7063e-06\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 4.701520463013196e-06.\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9988    \n",
      "Epoch 111: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0628 - accuracy: 0.9988 - val_loss: 7.0294 - val_accuracy: 0.9691 - lr: 4.7015e-06\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 4.696699806645861e-06.\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9979    \n",
      "Epoch 112: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1035 - accuracy: 0.9979 - val_loss: 5.0417 - val_accuracy: 0.9705 - lr: 4.6967e-06\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 4.691884093089686e-06.\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9984    \n",
      "Epoch 113: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1102 - accuracy: 0.9984 - val_loss: 2.7810 - val_accuracy: 0.9733 - lr: 4.6919e-06\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 4.687073317276609e-06.\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9986    \n",
      "Epoch 114: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0571 - accuracy: 0.9986 - val_loss: 1.7543 - val_accuracy: 0.9733 - lr: 4.6871e-06\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 4.682267474143766e-06.\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9986    \n",
      "Epoch 115: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0933 - accuracy: 0.9986 - val_loss: 7.1708 - val_accuracy: 0.9733 - lr: 4.6823e-06\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 4.677466558633481e-06.\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9981    \n",
      "Epoch 116: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0953 - accuracy: 0.9981 - val_loss: 5.8416 - val_accuracy: 0.9733 - lr: 4.6775e-06\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 4.67267056569327e-06.\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9993    \n",
      "Epoch 117: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0816 - accuracy: 0.9993 - val_loss: 6.0853 - val_accuracy: 0.9705 - lr: 4.6727e-06\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 4.6678794902758225e-06.\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9998    \n",
      "Epoch 118: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0112 - accuracy: 0.9998 - val_loss: 11.6869 - val_accuracy: 0.9698 - lr: 4.6679e-06\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 4.663093327339008e-06.\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9991    \n",
      "Epoch 119: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0114 - accuracy: 0.9991 - val_loss: 8.1153 - val_accuracy: 0.9712 - lr: 4.6631e-06\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 4.658312071845864e-06.\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9981    \n",
      "Epoch 120: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0772 - accuracy: 0.9981 - val_loss: 12.8816 - val_accuracy: 0.9684 - lr: 4.6583e-06\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 4.653535718764592e-06.\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9979    \n",
      "Epoch 121: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.1546 - accuracy: 0.9979 - val_loss: 9.6175 - val_accuracy: 0.9712 - lr: 4.6535e-06\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 4.6487642630685545e-06.\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9986    \n",
      "Epoch 122: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0267 - accuracy: 0.9986 - val_loss: 10.7430 - val_accuracy: 0.9726 - lr: 4.6488e-06\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 4.643997699736267e-06.\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9988    \n",
      "Epoch 123: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0603 - accuracy: 0.9988 - val_loss: 10.9477 - val_accuracy: 0.9628 - lr: 4.6440e-06\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 4.639236023751393e-06.\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9984    \n",
      "Epoch 124: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0744 - accuracy: 0.9984 - val_loss: 10.1444 - val_accuracy: 0.9677 - lr: 4.6392e-06\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 4.634479230102741e-06.\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9988    \n",
      "Epoch 125: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0985 - accuracy: 0.9988 - val_loss: 9.4374 - val_accuracy: 0.9705 - lr: 4.6345e-06\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 4.629727313784258e-06.\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9897\n",
      "Epoch 126: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1211 - accuracy: 0.9897 - val_loss: 5.7653 - val_accuracy: 0.9523 - lr: 4.6297e-06\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 4.624980269795022e-06.\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9984\n",
      "Epoch 127: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0808 - accuracy: 0.9984 - val_loss: 6.5591 - val_accuracy: 0.9684 - lr: 4.6250e-06\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 4.620238093139239e-06.\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9998    \n",
      "Epoch 128: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0159 - accuracy: 0.9998 - val_loss: 4.5227 - val_accuracy: 0.9698 - lr: 4.6202e-06\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 4.615500778826239e-06.\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9991    \n",
      "Epoch 129: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0240 - accuracy: 0.9991 - val_loss: 7.7229 - val_accuracy: 0.9670 - lr: 4.6155e-06\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 4.610768321870468e-06.\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9993    \n",
      "Epoch 130: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0140 - accuracy: 0.9993 - val_loss: 6.0897 - val_accuracy: 0.9677 - lr: 4.6108e-06\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 4.606040717291483e-06.\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9986    \n",
      "Epoch 131: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0249 - accuracy: 0.9986 - val_loss: 5.6595 - val_accuracy: 0.9677 - lr: 4.6060e-06\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 4.60131796011395e-06.\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9967    \n",
      "Epoch 132: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.1841 - accuracy: 0.9967 - val_loss: 8.3321 - val_accuracy: 0.9670 - lr: 4.6013e-06\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 4.5966000453676346e-06.\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9960\n",
      "Epoch 133: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.2665 - accuracy: 0.9960 - val_loss: 5.4976 - val_accuracy: 0.9684 - lr: 4.5966e-06\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 4.591886968087399e-06.\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9958\n",
      "Epoch 134: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0667 - accuracy: 0.9958 - val_loss: 10.6750 - val_accuracy: 0.9642 - lr: 4.5919e-06\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 4.587178723313195e-06.\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9988\n",
      "Epoch 135: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0159 - accuracy: 0.9988 - val_loss: 10.2915 - val_accuracy: 0.9677 - lr: 4.5872e-06\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 4.582475306090063e-06.\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9988    \n",
      "Epoch 136: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0351 - accuracy: 0.9988 - val_loss: 6.3079 - val_accuracy: 0.9677 - lr: 4.5825e-06\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 4.5777767114681224e-06.\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9988    \n",
      "Epoch 137: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0638 - accuracy: 0.9988 - val_loss: 5.6220 - val_accuracy: 0.9670 - lr: 4.5778e-06\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 4.573082934502568e-06.\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9981    \n",
      "Epoch 138: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0845 - accuracy: 0.9981 - val_loss: 9.6910 - val_accuracy: 0.9677 - lr: 4.5731e-06\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 4.568393970253664e-06.\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9977    \n",
      "Epoch 139: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1694 - accuracy: 0.9977 - val_loss: 4.8274 - val_accuracy: 0.9698 - lr: 4.5684e-06\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 4.56370981378674e-06.\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9995    \n",
      "Epoch 140: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0382 - accuracy: 0.9995 - val_loss: 9.7295 - val_accuracy: 0.9684 - lr: 4.5637e-06\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 4.559030460172186e-06.\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9993    \n",
      "Epoch 141: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0105 - accuracy: 0.9993 - val_loss: 19.9645 - val_accuracy: 0.9628 - lr: 4.5590e-06\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 4.5543559044854465e-06.\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9986    \n",
      "Epoch 142: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0365 - accuracy: 0.9986 - val_loss: 11.5698 - val_accuracy: 0.9663 - lr: 4.5544e-06\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 4.5496861418070134e-06.\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.9977    \n",
      "Epoch 143: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.2697 - accuracy: 0.9977 - val_loss: 8.7448 - val_accuracy: 0.9649 - lr: 4.5497e-06\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 4.545021167222426e-06.\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.9918\n",
      "Epoch 144: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.2654 - accuracy: 0.9918 - val_loss: 6.6580 - val_accuracy: 0.9607 - lr: 4.5450e-06\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 4.540360975822259e-06.\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9963\n",
      "Epoch 145: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0978 - accuracy: 0.9963 - val_loss: 5.9450 - val_accuracy: 0.9691 - lr: 4.5404e-06\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 4.535705562702124e-06.\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9984    \n",
      "Epoch 146: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.1032 - accuracy: 0.9984 - val_loss: 4.6766 - val_accuracy: 0.9740 - lr: 4.5357e-06\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 4.531054922962659e-06.\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9984    \n",
      "Epoch 147: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0851 - accuracy: 0.9984 - val_loss: 7.4117 - val_accuracy: 0.9684 - lr: 4.5311e-06\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 4.526409051709528e-06.\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4257e-04 - accuracy: 1.0000\n",
      "Epoch 148: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.4257e-04 - accuracy: 1.0000 - val_loss: 8.6562 - val_accuracy: 0.9663 - lr: 4.5264e-06\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 4.52176794405341e-06.\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9995    \n",
      "Epoch 149: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0157 - accuracy: 0.9995 - val_loss: 8.6930 - val_accuracy: 0.9705 - lr: 4.5218e-06\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 4.51713159511e-06.\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9984    \n",
      "Epoch 150: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0925 - accuracy: 0.9984 - val_loss: 6.4709 - val_accuracy: 0.9740 - lr: 4.5171e-06\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 4.5125e-06.\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9991\n",
      "Epoch 151: val_accuracy did not improve from 0.97404\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0607 - accuracy: 0.9991 - val_loss: 3.2046 - val_accuracy: 0.9712 - lr: 4.5125e-06\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 4.507873153849116e-06.\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9993    \n",
      "Epoch 152: val_accuracy improved from 0.97404 to 0.97474, saving model to model.keras\n",
      "134/134 [==============================] - 38s 275ms/step - loss: 0.0222 - accuracy: 0.9993 - val_loss: 1.6078 - val_accuracy: 0.9747 - lr: 4.5079e-06\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 4.503251051788048e-06.\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9995    \n",
      "Epoch 153: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0206 - accuracy: 0.9995 - val_loss: 5.6406 - val_accuracy: 0.9712 - lr: 4.5033e-06\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 4.498633688952496e-06.\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9988    \n",
      "Epoch 154: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0272 - accuracy: 0.9988 - val_loss: 4.6085 - val_accuracy: 0.9719 - lr: 4.4986e-06\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 4.494021060483139e-06.\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9972    \n",
      "Epoch 155: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1495 - accuracy: 0.9972 - val_loss: 5.2101 - val_accuracy: 0.9733 - lr: 4.4940e-06\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 4.489413161525645e-06.\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9995    \n",
      "Epoch 156: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0447 - accuracy: 0.9995 - val_loss: 8.0443 - val_accuracy: 0.9740 - lr: 4.4894e-06\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 4.484809987230657e-06.\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9998    \n",
      "Epoch 157: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 4.7970 - val_accuracy: 0.9740 - lr: 4.4848e-06\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 4.480211532753789e-06.\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9988    \n",
      "Epoch 158: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 0.0398 - accuracy: 0.9988 - val_loss: 3.7989 - val_accuracy: 0.9733 - lr: 4.4802e-06\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 4.475617793255623e-06.\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9951\n",
      "Epoch 159: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0447 - accuracy: 0.9951 - val_loss: 3.9790 - val_accuracy: 0.9537 - lr: 4.4756e-06\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 4.471028763901705e-06.\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9965\n",
      "Epoch 160: val_accuracy did not improve from 0.97474\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.1105 - accuracy: 0.9965 - val_loss: 3.0623 - val_accuracy: 0.9733 - lr: 4.4710e-06\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 4.466444439862535e-06.\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5316e-04 - accuracy: 1.0000\n",
      "Epoch 161: val_accuracy improved from 0.97474 to 0.97544, saving model to model.keras\n",
      "134/134 [==============================] - 38s 276ms/step - loss: 2.5316e-04 - accuracy: 1.0000 - val_loss: 5.7033 - val_accuracy: 0.9754 - lr: 4.4664e-06\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 4.461864816313567e-06.\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9991    \n",
      "Epoch 162: val_accuracy improved from 0.97544 to 0.97614, saving model to model.keras\n",
      "134/134 [==============================] - 39s 281ms/step - loss: 0.0261 - accuracy: 0.9991 - val_loss: 2.5857 - val_accuracy: 0.9761 - lr: 4.4619e-06\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 4.4572898884352015e-06.\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9993    \n",
      "Epoch 163: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0238 - accuracy: 0.9993 - val_loss: 7.4330 - val_accuracy: 0.9733 - lr: 4.4573e-06\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 4.452719651412778e-06.\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9993    \n",
      "Epoch 164: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0368 - accuracy: 0.9993 - val_loss: 2.6072 - val_accuracy: 0.9740 - lr: 4.4527e-06\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 4.448154100436577e-06.\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9991    \n",
      "Epoch 165: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0309 - accuracy: 0.9991 - val_loss: 4.6469 - val_accuracy: 0.9747 - lr: 4.4482e-06\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 4.443593230701808e-06.\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9984    \n",
      "Epoch 166: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0754 - accuracy: 0.9984 - val_loss: 1.2505 - val_accuracy: 0.9733 - lr: 4.4436e-06\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 4.439037037408607e-06.\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9972    \n",
      "Epoch 167: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1447 - accuracy: 0.9972 - val_loss: 4.0605 - val_accuracy: 0.9726 - lr: 4.4390e-06\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 4.434485515762032e-06.\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9921\n",
      "Epoch 168: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.1339 - accuracy: 0.9921 - val_loss: 14.5918 - val_accuracy: 0.9607 - lr: 4.4345e-06\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 4.429938660972058e-06.\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9965\n",
      "Epoch 169: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0551 - accuracy: 0.9965 - val_loss: 9.4969 - val_accuracy: 0.9726 - lr: 4.4299e-06\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 4.425396468253571e-06.\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9965\n",
      "Epoch 170: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1565 - accuracy: 0.9965 - val_loss: 4.1593 - val_accuracy: 0.9712 - lr: 4.4254e-06\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 4.420858932826362e-06.\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9974\n",
      "Epoch 171: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1488 - accuracy: 0.9974 - val_loss: 1.7559 - val_accuracy: 0.9761 - lr: 4.4209e-06\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 4.416326049915126e-06.\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9991    \n",
      "Epoch 172: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0221 - accuracy: 0.9991 - val_loss: 4.7364 - val_accuracy: 0.9740 - lr: 4.4163e-06\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 4.411797814749453e-06.\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9993    \n",
      "Epoch 173: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0320 - accuracy: 0.9993 - val_loss: 4.7289 - val_accuracy: 0.9712 - lr: 4.4118e-06\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 4.407274222563822e-06.\n",
      "Epoch 174/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9995    \n",
      "Epoch 174: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0185 - accuracy: 0.9995 - val_loss: 1.2463 - val_accuracy: 0.9740 - lr: 4.4073e-06\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 4.402755268597604e-06.\n",
      "Epoch 175/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9993    \n",
      "Epoch 175: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0446 - accuracy: 0.9993 - val_loss: 4.5012 - val_accuracy: 0.9712 - lr: 4.4028e-06\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 4.398240948095045e-06.\n",
      "Epoch 176/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9998    \n",
      "Epoch 176: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 9.5438 - val_accuracy: 0.9677 - lr: 4.3982e-06\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 4.3937312563052705e-06.\n",
      "Epoch 177/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9993    \n",
      "Epoch 177: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0191 - accuracy: 0.9993 - val_loss: 2.5328 - val_accuracy: 0.9698 - lr: 4.3937e-06\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 4.389226188482277e-06.\n",
      "Epoch 178/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9993    \n",
      "Epoch 178: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 4.5865 - val_accuracy: 0.9719 - lr: 4.3892e-06\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 4.384725739884927e-06.\n",
      "Epoch 179/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9991    \n",
      "Epoch 179: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0350 - accuracy: 0.9991 - val_loss: 4.5609 - val_accuracy: 0.9719 - lr: 4.3847e-06\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 4.380229905776944e-06.\n",
      "Epoch 180/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998    \n",
      "Epoch 180: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 6.7529 - val_accuracy: 0.9726 - lr: 4.3802e-06\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 4.375738681426909e-06.\n",
      "Epoch 181/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9993    \n",
      "Epoch 181: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0249 - accuracy: 0.9993 - val_loss: 4.1400 - val_accuracy: 0.9754 - lr: 4.3757e-06\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 4.3712520621082524e-06.\n",
      "Epoch 182/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993    \n",
      "Epoch 182: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 8.6806 - val_accuracy: 0.9705 - lr: 4.3713e-06\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 4.366770043099253e-06.\n",
      "Epoch 183/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9991    \n",
      "Epoch 183: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 0.0203 - accuracy: 0.9991 - val_loss: 5.2965 - val_accuracy: 0.9747 - lr: 4.3668e-06\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 4.362292619683028e-06.\n",
      "Epoch 184/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9986    \n",
      "Epoch 184: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0473 - accuracy: 0.9986 - val_loss: 5.8302 - val_accuracy: 0.9747 - lr: 4.3623e-06\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 4.357819787147535e-06.\n",
      "Epoch 185/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9986    \n",
      "Epoch 185: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0800 - accuracy: 0.9986 - val_loss: 2.5331 - val_accuracy: 0.9747 - lr: 4.3578e-06\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 4.35335154078556e-06.\n",
      "Epoch 186/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9991    \n",
      "Epoch 186: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0527 - accuracy: 0.9991 - val_loss: 8.8686 - val_accuracy: 0.9677 - lr: 4.3534e-06\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 4.348887875894717e-06.\n",
      "Epoch 187/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9993    \n",
      "Epoch 187: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0144 - accuracy: 0.9993 - val_loss: 9.1047 - val_accuracy: 0.9733 - lr: 4.3489e-06\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 4.34442878777744e-06.\n",
      "Epoch 188/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9998    \n",
      "Epoch 188: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0145 - accuracy: 0.9998 - val_loss: 9.3668 - val_accuracy: 0.9677 - lr: 4.3444e-06\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 4.3399742717409805e-06.\n",
      "Epoch 189/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9993    \n",
      "Epoch 189: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0101 - accuracy: 0.9993 - val_loss: 5.8089 - val_accuracy: 0.9726 - lr: 4.3400e-06\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 4.335524323097403e-06.\n",
      "Epoch 190/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9993    \n",
      "Epoch 190: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0254 - accuracy: 0.9993 - val_loss: 9.1322 - val_accuracy: 0.9712 - lr: 4.3355e-06\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 4.331078937163577e-06.\n",
      "Epoch 191/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9988    \n",
      "Epoch 191: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0325 - accuracy: 0.9988 - val_loss: 4.6786 - val_accuracy: 0.9705 - lr: 4.3311e-06\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 4.326638109261174e-06.\n",
      "Epoch 192/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9979    \n",
      "Epoch 192: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0873 - accuracy: 0.9979 - val_loss: 10.2415 - val_accuracy: 0.9712 - lr: 4.3266e-06\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 4.322201834716663e-06.\n",
      "Epoch 193/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9986    \n",
      "Epoch 193: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.1237 - accuracy: 0.9986 - val_loss: 7.9301 - val_accuracy: 0.9698 - lr: 4.3222e-06\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 4.3177701088613046e-06.\n",
      "Epoch 194/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9979\n",
      "Epoch 194: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 11.9411 - val_accuracy: 0.9705 - lr: 4.3178e-06\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 4.3133429270311465e-06.\n",
      "Epoch 195/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.3213e-04 - accuracy: 1.0000\n",
      "Epoch 195: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 5.3213e-04 - accuracy: 1.0000 - val_loss: 8.1880 - val_accuracy: 0.9712 - lr: 4.3133e-06\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 4.308920284567017e-06.\n",
      "Epoch 196/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9995    \n",
      "Epoch 196: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 13.8927 - val_accuracy: 0.9698 - lr: 4.3089e-06\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 4.304502176814526e-06.\n",
      "Epoch 197/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9995    \n",
      "Epoch 197: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 13.2636 - val_accuracy: 0.9670 - lr: 4.3045e-06\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 4.300088599124051e-06.\n",
      "Epoch 198/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9995    \n",
      "Epoch 198: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0127 - accuracy: 0.9995 - val_loss: 8.7998 - val_accuracy: 0.9726 - lr: 4.3001e-06\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 4.295679546850739e-06.\n",
      "Epoch 199/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9988    \n",
      "Epoch 199: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0302 - accuracy: 0.9988 - val_loss: 7.1283 - val_accuracy: 0.9719 - lr: 4.2957e-06\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 4.2912750153545e-06.\n",
      "Epoch 200/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9993    \n",
      "Epoch 200: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0376 - accuracy: 0.9993 - val_loss: 8.8615 - val_accuracy: 0.9747 - lr: 4.2913e-06\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 4.2868749999999995e-06.\n",
      "Epoch 201/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9993    \n",
      "Epoch 201: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0131 - accuracy: 0.9993 - val_loss: 7.3798 - val_accuracy: 0.9705 - lr: 4.2869e-06\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 4.282479496156659e-06.\n",
      "Epoch 202/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9991    \n",
      "Epoch 202: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0375 - accuracy: 0.9991 - val_loss: 8.3188 - val_accuracy: 0.9733 - lr: 4.2825e-06\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 4.278088499198646e-06.\n",
      "Epoch 203/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9995    \n",
      "Epoch 203: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 5.8751 - val_accuracy: 0.9670 - lr: 4.2781e-06\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 4.27370200450487e-06.\n",
      "Epoch 204/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995    \n",
      "Epoch 204: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 12.9586 - val_accuracy: 0.9691 - lr: 4.2737e-06\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 4.269320007458983e-06.\n",
      "Epoch 205/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9899\n",
      "Epoch 205: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0453 - accuracy: 0.9899 - val_loss: 13.4373 - val_accuracy: 0.9677 - lr: 4.2693e-06\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 4.264942503449363e-06.\n",
      "Epoch 206/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9984\n",
      "Epoch 206: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0471 - accuracy: 0.9984 - val_loss: 3.1707 - val_accuracy: 0.9747 - lr: 4.2649e-06\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 4.260569487869124e-06.\n",
      "Epoch 207/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9984    \n",
      "Epoch 207: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0916 - accuracy: 0.9984 - val_loss: 12.5509 - val_accuracy: 0.9705 - lr: 4.2606e-06\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 4.256200956116099e-06.\n",
      "Epoch 208/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9991    \n",
      "Epoch 208: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0882 - accuracy: 0.9991 - val_loss: 12.2321 - val_accuracy: 0.9698 - lr: 4.2562e-06\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 4.251836903592842e-06.\n",
      "Epoch 209/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9974    \n",
      "Epoch 209: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.1228 - accuracy: 0.9974 - val_loss: 13.9898 - val_accuracy: 0.9677 - lr: 4.2518e-06\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 4.24747732570662e-06.\n",
      "Epoch 210/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9984    \n",
      "Epoch 210: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1771 - accuracy: 0.9984 - val_loss: 3.9418 - val_accuracy: 0.9761 - lr: 4.2475e-06\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 4.243122217869409e-06.\n",
      "Epoch 211/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 211: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 7.1729 - val_accuracy: 0.9740 - lr: 4.2431e-06\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 4.238771575497888e-06.\n",
      "Epoch 212/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.3901e-04 - accuracy: 1.0000\n",
      "Epoch 212: val_accuracy did not improve from 0.97614\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 2.3901e-04 - accuracy: 1.0000 - val_loss: 4.8612 - val_accuracy: 0.9733 - lr: 4.2388e-06\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 4.234425394013441e-06.\n",
      "Epoch 213/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9991    \n",
      "Epoch 213: val_accuracy improved from 0.97614 to 0.97684, saving model to model.keras\n",
      "134/134 [==============================] - 38s 278ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 4.8708 - val_accuracy: 0.9768 - lr: 4.2344e-06\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 4.23008366884214e-06.\n",
      "Epoch 214/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9995    \n",
      "Epoch 214: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0140 - accuracy: 0.9995 - val_loss: 7.9510 - val_accuracy: 0.9740 - lr: 4.2301e-06\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 4.225746395414748e-06.\n",
      "Epoch 215/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9984    \n",
      "Epoch 215: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0640 - accuracy: 0.9984 - val_loss: 12.0876 - val_accuracy: 0.9740 - lr: 4.2257e-06\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 4.221413569166717e-06.\n",
      "Epoch 216/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9984    \n",
      "Epoch 216: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0784 - accuracy: 0.9984 - val_loss: 5.6044 - val_accuracy: 0.9740 - lr: 4.2214e-06\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 4.2170851855381765e-06.\n",
      "Epoch 217/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9993    \n",
      "Epoch 217: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0200 - accuracy: 0.9993 - val_loss: 6.8197 - val_accuracy: 0.9733 - lr: 4.2171e-06\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 4.21276123997393e-06.\n",
      "Epoch 218/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9995    \n",
      "Epoch 218: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0176 - accuracy: 0.9995 - val_loss: 10.0565 - val_accuracy: 0.9705 - lr: 4.2128e-06\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 4.2084417279234545e-06.\n",
      "Epoch 219/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9986    \n",
      "Epoch 219: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0511 - accuracy: 0.9986 - val_loss: 8.0185 - val_accuracy: 0.9705 - lr: 4.2084e-06\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 4.204126644840892e-06.\n",
      "Epoch 220/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9979    \n",
      "Epoch 220: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.1024 - accuracy: 0.9979 - val_loss: 10.1376 - val_accuracy: 0.9642 - lr: 4.2041e-06\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 4.199815986185044e-06.\n",
      "Epoch 221/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9993    \n",
      "Epoch 221: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0445 - accuracy: 0.9993 - val_loss: 4.9004 - val_accuracy: 0.9712 - lr: 4.1998e-06\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 4.195509747419369e-06.\n",
      "Epoch 222/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993    \n",
      "Epoch 222: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 11.3804 - val_accuracy: 0.9684 - lr: 4.1955e-06\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 4.191207924011981e-06.\n",
      "Epoch 223/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9991    \n",
      "Epoch 223: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0647 - accuracy: 0.9991 - val_loss: 8.4706 - val_accuracy: 0.9705 - lr: 4.1912e-06\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 4.186910511435632e-06.\n",
      "Epoch 224/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9988    \n",
      "Epoch 224: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0301 - accuracy: 0.9988 - val_loss: 1.9065 - val_accuracy: 0.9761 - lr: 4.1869e-06\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 4.182617505167723e-06.\n",
      "Epoch 225/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9988    \n",
      "Epoch 225: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0555 - accuracy: 0.9988 - val_loss: 8.1208 - val_accuracy: 0.9719 - lr: 4.1826e-06\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 4.1783289006902926e-06.\n",
      "Epoch 226/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9993    \n",
      "Epoch 226: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0155 - accuracy: 0.9993 - val_loss: 5.9897 - val_accuracy: 0.9726 - lr: 4.1783e-06\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 4.174044693490007e-06.\n",
      "Epoch 227/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9986    \n",
      "Epoch 227: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0229 - accuracy: 0.9986 - val_loss: 6.3025 - val_accuracy: 0.9740 - lr: 4.1740e-06\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 4.169764879058163e-06.\n",
      "Epoch 228/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9995    \n",
      "Epoch 228: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0420 - accuracy: 0.9995 - val_loss: 17.7884 - val_accuracy: 0.9670 - lr: 4.1698e-06\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 4.16548945289068e-06.\n",
      "Epoch 229/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9993    \n",
      "Epoch 229: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0148 - accuracy: 0.9993 - val_loss: 8.6429 - val_accuracy: 0.9705 - lr: 4.1655e-06\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 4.161218410488097e-06.\n",
      "Epoch 230/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9986    \n",
      "Epoch 230: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0498 - accuracy: 0.9986 - val_loss: 7.0740 - val_accuracy: 0.9726 - lr: 4.1612e-06\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 4.156951747355564e-06.\n",
      "Epoch 231/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9981    \n",
      "Epoch 231: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0407 - accuracy: 0.9981 - val_loss: 14.3036 - val_accuracy: 0.9677 - lr: 4.1570e-06\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 4.15268945900284e-06.\n",
      "Epoch 232/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9984    \n",
      "Epoch 232: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0884 - accuracy: 0.9984 - val_loss: 6.8505 - val_accuracy: 0.9705 - lr: 4.1527e-06\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 4.14843154094429e-06.\n",
      "Epoch 233/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9998    \n",
      "Epoch 233: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0270 - accuracy: 0.9998 - val_loss: 6.0426 - val_accuracy: 0.9670 - lr: 4.1484e-06\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 4.144177988698877e-06.\n",
      "Epoch 234/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9988    \n",
      "Epoch 234: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0271 - accuracy: 0.9988 - val_loss: 5.6619 - val_accuracy: 0.9705 - lr: 4.1442e-06\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 4.139928797790158e-06.\n",
      "Epoch 235/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 235: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 3.1355 - val_accuracy: 0.9761 - lr: 4.1399e-06\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 4.135683963746282e-06.\n",
      "Epoch 236/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2740e-04 - accuracy: 1.0000\n",
      "Epoch 236: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.2740e-04 - accuracy: 1.0000 - val_loss: 11.0913 - val_accuracy: 0.9698 - lr: 4.1357e-06\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 4.13144348209998e-06.\n",
      "Epoch 237/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9998    \n",
      "Epoch 237: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0088 - accuracy: 0.9998 - val_loss: 7.8830 - val_accuracy: 0.9719 - lr: 4.1314e-06\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 4.127207348388567e-06.\n",
      "Epoch 238/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9988    \n",
      "Epoch 238: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0401 - accuracy: 0.9988 - val_loss: 7.9023 - val_accuracy: 0.9747 - lr: 4.1272e-06\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 4.122975558153932e-06.\n",
      "Epoch 239/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9979\n",
      "Epoch 239: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0805 - accuracy: 0.9979 - val_loss: 4.4080 - val_accuracy: 0.9670 - lr: 4.1230e-06\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 4.118748106942532e-06.\n",
      "Epoch 240/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9949\n",
      "Epoch 240: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0696 - accuracy: 0.9949 - val_loss: 8.0083 - val_accuracy: 0.9705 - lr: 4.1187e-06\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 4.114524990305398e-06.\n",
      "Epoch 241/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998    \n",
      "Epoch 241: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 10.9761 - val_accuracy: 0.9698 - lr: 4.1145e-06\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 4.110306203798115e-06.\n",
      "Epoch 242/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.5044e-05 - accuracy: 1.0000\n",
      "Epoch 242: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 3.5044e-05 - accuracy: 1.0000 - val_loss: 6.5435 - val_accuracy: 0.9712 - lr: 4.1103e-06\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 4.10609174298083e-06.\n",
      "Epoch 243/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9993    \n",
      "Epoch 243: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0198 - accuracy: 0.9993 - val_loss: 10.4945 - val_accuracy: 0.9684 - lr: 4.1061e-06\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 4.101881603418239e-06.\n",
      "Epoch 244/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9988    \n",
      "Epoch 244: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0348 - accuracy: 0.9988 - val_loss: 19.3874 - val_accuracy: 0.9712 - lr: 4.1019e-06\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 4.0976757806795885e-06.\n",
      "Epoch 245/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9998    \n",
      "Epoch 245: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 4.7256 - val_accuracy: 0.9691 - lr: 4.0977e-06\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 4.0934742703386665e-06.\n",
      "Epoch 246/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9991    \n",
      "Epoch 246: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 7.1823 - val_accuracy: 0.9684 - lr: 4.0935e-06\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 4.0892770679738e-06.\n",
      "Epoch 247/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9988    \n",
      "Epoch 247: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0479 - accuracy: 0.9988 - val_loss: 6.7163 - val_accuracy: 0.9656 - lr: 4.0893e-06\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 4.085084169167849e-06.\n",
      "Epoch 248/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9991    \n",
      "Epoch 248: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0147 - accuracy: 0.9991 - val_loss: 6.5586 - val_accuracy: 0.9663 - lr: 4.0851e-06\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 4.080895569508202e-06.\n",
      "Epoch 249/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9974    \n",
      "Epoch 249: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.1259 - accuracy: 0.9974 - val_loss: 2.2490 - val_accuracy: 0.9712 - lr: 4.0809e-06\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 4.076711264586775e-06.\n",
      "Epoch 250/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9979\n",
      "Epoch 250: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0811 - accuracy: 0.9979 - val_loss: 14.3121 - val_accuracy: 0.9691 - lr: 4.0767e-06\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 4.07253125e-06.\n",
      "Epoch 251/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9953\n",
      "Epoch 251: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0280 - accuracy: 0.9953 - val_loss: 5.1343 - val_accuracy: 0.9705 - lr: 4.0725e-06\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 4.068355521348827e-06.\n",
      "Epoch 252/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.9011e-04 - accuracy: 1.0000\n",
      "Epoch 252: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 5.9011e-04 - accuracy: 1.0000 - val_loss: 6.2301 - val_accuracy: 0.9684 - lr: 4.0684e-06\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 4.064184074238714e-06.\n",
      "Epoch 253/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9993    \n",
      "Epoch 253: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0464 - accuracy: 0.9993 - val_loss: 8.2595 - val_accuracy: 0.9670 - lr: 4.0642e-06\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 4.060016904279627e-06.\n",
      "Epoch 254/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9991    \n",
      "Epoch 254: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0265 - accuracy: 0.9991 - val_loss: 7.9126 - val_accuracy: 0.9670 - lr: 4.0600e-06\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 4.055854007086033e-06.\n",
      "Epoch 255/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9993    \n",
      "Epoch 255: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 4.3757 - val_accuracy: 0.9691 - lr: 4.0559e-06\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 4.051695378276895e-06.\n",
      "Epoch 256/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995    \n",
      "Epoch 256: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 3.6407 - val_accuracy: 0.9726 - lr: 4.0517e-06\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 4.047541013475668e-06.\n",
      "Epoch 257/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9993    \n",
      "Epoch 257: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0296 - accuracy: 0.9993 - val_loss: 7.8498 - val_accuracy: 0.9698 - lr: 4.0475e-06\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 4.043390908310294e-06.\n",
      "Epoch 258/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9993    \n",
      "Epoch 258: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0143 - accuracy: 0.9993 - val_loss: 13.3284 - val_accuracy: 0.9684 - lr: 4.0434e-06\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 4.0392450584132e-06.\n",
      "Epoch 259/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9993    \n",
      "Epoch 259: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 6.6392 - val_accuracy: 0.9705 - lr: 4.0392e-06\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 4.0351034594212884e-06.\n",
      "Epoch 260/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9991    \n",
      "Epoch 260: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0601 - accuracy: 0.9991 - val_loss: 8.6589 - val_accuracy: 0.9726 - lr: 4.0351e-06\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 4.030966106975938e-06.\n",
      "Epoch 261/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9993    \n",
      "Epoch 261: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0180 - accuracy: 0.9993 - val_loss: 8.7996 - val_accuracy: 0.9754 - lr: 4.0310e-06\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 4.026832996722994e-06.\n",
      "Epoch 262/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9993    \n",
      "Epoch 262: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0219 - accuracy: 0.9993 - val_loss: 9.8248 - val_accuracy: 0.9698 - lr: 4.0268e-06\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 4.022704124312768e-06.\n",
      "Epoch 263/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9995    \n",
      "Epoch 263: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 5.3269 - val_accuracy: 0.9719 - lr: 4.0227e-06\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 4.0185794854000324e-06.\n",
      "Epoch 264/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9998    \n",
      "Epoch 264: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0105 - accuracy: 0.9998 - val_loss: 11.0115 - val_accuracy: 0.9726 - lr: 4.0186e-06\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 4.01445907564401e-06.\n",
      "Epoch 265/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.5349e-05 - accuracy: 1.0000\n",
      "Epoch 265: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.5349e-05 - accuracy: 1.0000 - val_loss: 10.5408 - val_accuracy: 0.9733 - lr: 4.0145e-06\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 4.010342890708381e-06.\n",
      "Epoch 266/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9995    \n",
      "Epoch 266: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 11.2732 - val_accuracy: 0.9740 - lr: 4.0103e-06\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 4.006230926261267e-06.\n",
      "Epoch 267/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9993    \n",
      "Epoch 267: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 8.3204 - val_accuracy: 0.9712 - lr: 4.0062e-06\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 4.002123177975234e-06.\n",
      "Epoch 268/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9991    \n",
      "Epoch 268: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0617 - accuracy: 0.9991 - val_loss: 11.9196 - val_accuracy: 0.9719 - lr: 4.0021e-06\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 3.9980196415272815e-06.\n",
      "Epoch 269/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9993    \n",
      "Epoch 269: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0226 - accuracy: 0.9993 - val_loss: 6.4780 - val_accuracy: 0.9698 - lr: 3.9980e-06\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 3.993920312598847e-06.\n",
      "Epoch 270/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9991    \n",
      "Epoch 270: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0453 - accuracy: 0.9991 - val_loss: 9.3569 - val_accuracy: 0.9712 - lr: 3.9939e-06\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 3.989825186875791e-06.\n",
      "Epoch 271/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9993    \n",
      "Epoch 271: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0305 - accuracy: 0.9993 - val_loss: 17.3551 - val_accuracy: 0.9719 - lr: 3.9898e-06\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 3.985734260048401e-06.\n",
      "Epoch 272/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.1796e-05 - accuracy: 1.0000\n",
      "Epoch 272: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 2.1796e-05 - accuracy: 1.0000 - val_loss: 13.8122 - val_accuracy: 0.9740 - lr: 3.9857e-06\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 3.981647527811381e-06.\n",
      "Epoch 273/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9993    \n",
      "Epoch 273: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0177 - accuracy: 0.9993 - val_loss: 16.6166 - val_accuracy: 0.9705 - lr: 3.9816e-06\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 3.97756498586385e-06.\n",
      "Epoch 274/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9991    \n",
      "Epoch 274: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0316 - accuracy: 0.9991 - val_loss: 12.7958 - val_accuracy: 0.9698 - lr: 3.9776e-06\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 3.973486629909337e-06.\n",
      "Epoch 275/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9988    \n",
      "Epoch 275: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0410 - accuracy: 0.9988 - val_loss: 8.1274 - val_accuracy: 0.9747 - lr: 3.9735e-06\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 3.969412455655778e-06.\n",
      "Epoch 276/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9998    \n",
      "Epoch 276: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0185 - accuracy: 0.9998 - val_loss: 7.5071 - val_accuracy: 0.9677 - lr: 3.9694e-06\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 3.965342458815507e-06.\n",
      "Epoch 277/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9993    \n",
      "Epoch 277: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0129 - accuracy: 0.9993 - val_loss: 7.9546 - val_accuracy: 0.9705 - lr: 3.9653e-06\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 3.9612766351052546e-06.\n",
      "Epoch 278/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9995    \n",
      "Epoch 278: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 5.2868 - val_accuracy: 0.9712 - lr: 3.9613e-06\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 3.957214980246147e-06.\n",
      "Epoch 279/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9995    \n",
      "Epoch 279: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 10.6142 - val_accuracy: 0.9677 - lr: 3.9572e-06\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 3.953157489963692e-06.\n",
      "Epoch 280/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9995    \n",
      "Epoch 280: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 4.5845 - val_accuracy: 0.9726 - lr: 3.9532e-06\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 3.949104159987786e-06.\n",
      "Epoch 281/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9993    \n",
      "Epoch 281: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0205 - accuracy: 0.9993 - val_loss: 5.8150 - val_accuracy: 0.9705 - lr: 3.9491e-06\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 3.945054986052698e-06.\n",
      "Epoch 282/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9988    \n",
      "Epoch 282: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0407 - accuracy: 0.9988 - val_loss: 7.5239 - val_accuracy: 0.9719 - lr: 3.9451e-06\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 3.9410099638970755e-06.\n",
      "Epoch 283/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9979    \n",
      "Epoch 283: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0936 - accuracy: 0.9979 - val_loss: 8.1883 - val_accuracy: 0.9698 - lr: 3.9410e-06\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 3.936969089263933e-06.\n",
      "Epoch 284/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9956\n",
      "Epoch 284: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0838 - accuracy: 0.9956 - val_loss: 8.9758 - val_accuracy: 0.9607 - lr: 3.9370e-06\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 3.93293235790065e-06.\n",
      "Epoch 285/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9993    \n",
      "Epoch 285: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0244 - accuracy: 0.9993 - val_loss: 7.7129 - val_accuracy: 0.9740 - lr: 3.9329e-06\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 3.928899765558968e-06.\n",
      "Epoch 286/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9998    \n",
      "Epoch 286: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 8.6238 - val_accuracy: 0.9747 - lr: 3.9289e-06\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 3.924871307994981e-06.\n",
      "Epoch 287/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9988    \n",
      "Epoch 287: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0483 - accuracy: 0.9988 - val_loss: 4.5525 - val_accuracy: 0.9740 - lr: 3.9249e-06\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 3.920846980969138e-06.\n",
      "Epoch 288/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9998    \n",
      "Epoch 288: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 6.7945 - val_accuracy: 0.9747 - lr: 3.9208e-06\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 3.916826780246235e-06.\n",
      "Epoch 289/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4914e-05 - accuracy: 1.0000\n",
      "Epoch 289: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 2.4914e-05 - accuracy: 1.0000 - val_loss: 10.4890 - val_accuracy: 0.9733 - lr: 3.9168e-06\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 3.9128107015954055e-06.\n",
      "Epoch 290/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9993    \n",
      "Epoch 290: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0189 - accuracy: 0.9993 - val_loss: 4.1628 - val_accuracy: 0.9754 - lr: 3.9128e-06\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 3.908798740790128e-06.\n",
      "Epoch 291/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9988    \n",
      "Epoch 291: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0168 - accuracy: 0.9988 - val_loss: 10.0370 - val_accuracy: 0.9747 - lr: 3.9088e-06\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 3.904790893608209e-06.\n",
      "Epoch 292/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9993    \n",
      "Epoch 292: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0312 - accuracy: 0.9993 - val_loss: 6.7915 - val_accuracy: 0.9740 - lr: 3.9048e-06\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 3.900787155831788e-06.\n",
      "Epoch 293/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9988    \n",
      "Epoch 293: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0123 - accuracy: 0.9988 - val_loss: 11.8501 - val_accuracy: 0.9733 - lr: 3.9008e-06\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 3.896787523247327e-06.\n",
      "Epoch 294/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9979\n",
      "Epoch 294: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 8.1821 - val_accuracy: 0.9670 - lr: 3.8968e-06\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 3.892791991645609e-06.\n",
      "Epoch 295/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995    \n",
      "Epoch 295: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.8558 - val_accuracy: 0.9705 - lr: 3.8928e-06\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 3.888800556821733e-06.\n",
      "Epoch 296/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9995    \n",
      "Epoch 296: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0274 - accuracy: 0.9995 - val_loss: 13.1190 - val_accuracy: 0.9684 - lr: 3.8888e-06\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 3.8848132145751095e-06.\n",
      "Epoch 297/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9988    \n",
      "Epoch 297: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 6.3384 - val_accuracy: 0.9726 - lr: 3.8848e-06\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 3.880829960709456e-06.\n",
      "Epoch 298/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1608e-05 - accuracy: 1.0000\n",
      "Epoch 298: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 1.1608e-05 - accuracy: 1.0000 - val_loss: 4.7468 - val_accuracy: 0.9726 - lr: 3.8808e-06\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 3.876850791032792e-06.\n",
      "Epoch 299/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9998    \n",
      "Epoch 299: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 4.1677 - val_accuracy: 0.9754 - lr: 3.8769e-06\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 3.872875701357436e-06.\n",
      "Epoch 300/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 300: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 2.3530 - val_accuracy: 0.9740 - lr: 3.8729e-06\n",
      "\n",
      "Epoch 301: LearningRateScheduler setting learning rate to 3.868904687499999e-06.\n",
      "Epoch 301/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6348e-05 - accuracy: 1.0000\n",
      "Epoch 301: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 1.6348e-05 - accuracy: 1.0000 - val_loss: 9.5907 - val_accuracy: 0.9740 - lr: 3.8689e-06\n",
      "\n",
      "Epoch 302: LearningRateScheduler setting learning rate to 3.864937745281384e-06.\n",
      "Epoch 302/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.7044e-06 - accuracy: 1.0000\n",
      "Epoch 302: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 8.7044e-06 - accuracy: 1.0000 - val_loss: 3.5554 - val_accuracy: 0.9747 - lr: 3.8649e-06\n",
      "\n",
      "Epoch 303: LearningRateScheduler setting learning rate to 3.860974870526777e-06.\n",
      "Epoch 303/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9995    \n",
      "Epoch 303: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 8.8755 - val_accuracy: 0.9747 - lr: 3.8610e-06\n",
      "\n",
      "Epoch 304: LearningRateScheduler setting learning rate to 3.8570160590656455e-06.\n",
      "Epoch 304/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9998    \n",
      "Epoch 304: val_accuracy did not improve from 0.97684\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 16.1747 - val_accuracy: 0.9719 - lr: 3.8570e-06\n",
      "\n",
      "Epoch 305: LearningRateScheduler setting learning rate to 3.853061306731731e-06.\n",
      "Epoch 305/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993    \n",
      "Epoch 305: val_accuracy improved from 0.97684 to 0.97965, saving model to model.keras\n",
      "134/134 [==============================] - 39s 277ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 2.4921 - val_accuracy: 0.9796 - lr: 3.8531e-06\n",
      "\n",
      "Epoch 306: LearningRateScheduler setting learning rate to 3.84911060936305e-06.\n",
      "Epoch 306/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9988    \n",
      "Epoch 306: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0278 - accuracy: 0.9988 - val_loss: 9.0211 - val_accuracy: 0.9740 - lr: 3.8491e-06\n",
      "\n",
      "Epoch 307: LearningRateScheduler setting learning rate to 3.845163962801884e-06.\n",
      "Epoch 307/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9986    \n",
      "Epoch 307: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0438 - accuracy: 0.9986 - val_loss: 5.1018 - val_accuracy: 0.9726 - lr: 3.8452e-06\n",
      "\n",
      "Epoch 308: LearningRateScheduler setting learning rate to 3.841221362894779e-06.\n",
      "Epoch 308/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9991    \n",
      "Epoch 308: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0459 - accuracy: 0.9991 - val_loss: 5.6122 - val_accuracy: 0.9726 - lr: 3.8412e-06\n",
      "\n",
      "Epoch 309: LearningRateScheduler setting learning rate to 3.83728280549254e-06.\n",
      "Epoch 309/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 309: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 6.1156 - val_accuracy: 0.9691 - lr: 3.8373e-06\n",
      "\n",
      "Epoch 310: LearningRateScheduler setting learning rate to 3.8333482864502245e-06.\n",
      "Epoch 310/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9993    \n",
      "Epoch 310: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0231 - accuracy: 0.9993 - val_loss: 6.9631 - val_accuracy: 0.9698 - lr: 3.8333e-06\n",
      "\n",
      "Epoch 311: LearningRateScheduler setting learning rate to 3.829417801627141e-06.\n",
      "Epoch 311/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9995    \n",
      "Epoch 311: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0276 - accuracy: 0.9995 - val_loss: 3.2812 - val_accuracy: 0.9698 - lr: 3.8294e-06\n",
      "\n",
      "Epoch 312: LearningRateScheduler setting learning rate to 3.825491346886844e-06.\n",
      "Epoch 312/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9995    \n",
      "Epoch 312: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0140 - accuracy: 0.9995 - val_loss: 4.6262 - val_accuracy: 0.9698 - lr: 3.8255e-06\n",
      "\n",
      "Epoch 313: LearningRateScheduler setting learning rate to 3.82156891809713e-06.\n",
      "Epoch 313/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9984    \n",
      "Epoch 313: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0540 - accuracy: 0.9984 - val_loss: 13.3173 - val_accuracy: 0.9726 - lr: 3.8216e-06\n",
      "\n",
      "Epoch 314: LearningRateScheduler setting learning rate to 3.81765051113003e-06.\n",
      "Epoch 314/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9956\n",
      "Epoch 314: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1263 - accuracy: 0.9956 - val_loss: 5.4613 - val_accuracy: 0.9747 - lr: 3.8177e-06\n",
      "\n",
      "Epoch 315: LearningRateScheduler setting learning rate to 3.8137361218618095e-06.\n",
      "Epoch 315/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 315: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 11.3614 - val_accuracy: 0.9719 - lr: 3.8137e-06\n",
      "\n",
      "Epoch 316: LearningRateScheduler setting learning rate to 3.8098257461729615e-06.\n",
      "Epoch 316/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.3939e-05 - accuracy: 1.0000\n",
      "Epoch 316: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 6.3939e-05 - accuracy: 1.0000 - val_loss: 6.3892 - val_accuracy: 0.9740 - lr: 3.8098e-06\n",
      "\n",
      "Epoch 317: LearningRateScheduler setting learning rate to 3.8059193799482038e-06.\n",
      "Epoch 317/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.5377e-04 - accuracy: 0.9998\n",
      "Epoch 317: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 7.5377e-04 - accuracy: 0.9998 - val_loss: 5.4792 - val_accuracy: 0.9761 - lr: 3.8059e-06\n",
      "\n",
      "Epoch 318: LearningRateScheduler setting learning rate to 3.8020170190764716e-06.\n",
      "Epoch 318/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9988    \n",
      "Epoch 318: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0200 - accuracy: 0.9988 - val_loss: 4.4759 - val_accuracy: 0.9740 - lr: 3.8020e-06\n",
      "\n",
      "Epoch 319: LearningRateScheduler setting learning rate to 3.7981186594509173e-06.\n",
      "Epoch 319/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9988    \n",
      "Epoch 319: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0251 - accuracy: 0.9988 - val_loss: 4.0011 - val_accuracy: 0.9747 - lr: 3.7981e-06\n",
      "\n",
      "Epoch 320: LearningRateScheduler setting learning rate to 3.7942242969689045e-06.\n",
      "Epoch 320/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9991    \n",
      "Epoch 320: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0452 - accuracy: 0.9991 - val_loss: 3.5084 - val_accuracy: 0.9705 - lr: 3.7942e-06\n",
      "\n",
      "Epoch 321: LearningRateScheduler setting learning rate to 3.790333927532002e-06.\n",
      "Epoch 321/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9988    \n",
      "Epoch 321: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0299 - accuracy: 0.9988 - val_loss: 10.0989 - val_accuracy: 0.9761 - lr: 3.7903e-06\n",
      "\n",
      "Epoch 322: LearningRateScheduler setting learning rate to 3.7864475470459813e-06.\n",
      "Epoch 322/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9981    \n",
      "Epoch 322: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0328 - accuracy: 0.9981 - val_loss: 1.9713 - val_accuracy: 0.9768 - lr: 3.7864e-06\n",
      "\n",
      "Epoch 323: LearningRateScheduler setting learning rate to 3.782565151420812e-06.\n",
      "Epoch 323/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9974\n",
      "Epoch 323: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0391 - accuracy: 0.9974 - val_loss: 6.3214 - val_accuracy: 0.9698 - lr: 3.7826e-06\n",
      "\n",
      "Epoch 324: LearningRateScheduler setting learning rate to 3.778686736570657e-06.\n",
      "Epoch 324/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9993    \n",
      "Epoch 324: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 3.8842 - val_accuracy: 0.9719 - lr: 3.7787e-06\n",
      "\n",
      "Epoch 325: LearningRateScheduler setting learning rate to 3.7748122984138702e-06.\n",
      "Epoch 325/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9993    \n",
      "Epoch 325: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 38s 270ms/step - loss: 0.0214 - accuracy: 0.9993 - val_loss: 7.6410 - val_accuracy: 0.9712 - lr: 3.7748e-06\n",
      "\n",
      "Epoch 326: LearningRateScheduler setting learning rate to 3.7709418328729885e-06.\n",
      "Epoch 326/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995    \n",
      "Epoch 326: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 3.3052 - val_accuracy: 0.9733 - lr: 3.7709e-06\n",
      "\n",
      "Epoch 327: LearningRateScheduler setting learning rate to 3.767075335874731e-06.\n",
      "Epoch 327/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0942e-05 - accuracy: 1.0000\n",
      "Epoch 327: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 1.0942e-05 - accuracy: 1.0000 - val_loss: 9.8981 - val_accuracy: 0.9740 - lr: 3.7671e-06\n",
      "\n",
      "Epoch 328: LearningRateScheduler setting learning rate to 3.7632128033499917e-06.\n",
      "Epoch 328/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9644e-04 - accuracy: 0.9998\n",
      "Epoch 328: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.9644e-04 - accuracy: 0.9998 - val_loss: 3.5502 - val_accuracy: 0.9747 - lr: 3.7632e-06\n",
      "\n",
      "Epoch 329: LearningRateScheduler setting learning rate to 3.7593542312338387e-06.\n",
      "Epoch 329/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9995    \n",
      "Epoch 329: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 7.9737 - val_accuracy: 0.9740 - lr: 3.7594e-06\n",
      "\n",
      "Epoch 330: LearningRateScheduler setting learning rate to 3.755499615465507e-06.\n",
      "Epoch 330/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9984\n",
      "Epoch 330: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0370 - accuracy: 0.9984 - val_loss: 2.5399 - val_accuracy: 0.9558 - lr: 3.7555e-06\n",
      "\n",
      "Epoch 331: LearningRateScheduler setting learning rate to 3.751648951988396e-06.\n",
      "Epoch 331/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9935\n",
      "Epoch 331: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0422 - accuracy: 0.9935 - val_loss: 7.7360 - val_accuracy: 0.9656 - lr: 3.7516e-06\n",
      "\n",
      "Epoch 332: LearningRateScheduler setting learning rate to 3.747802236750063e-06.\n",
      "Epoch 332/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9984\n",
      "Epoch 332: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0192 - accuracy: 0.9984 - val_loss: 11.1107 - val_accuracy: 0.9740 - lr: 3.7478e-06\n",
      "\n",
      "Epoch 333: LearningRateScheduler setting learning rate to 3.7439594657022215e-06.\n",
      "Epoch 333/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9993    \n",
      "Epoch 333: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 4.7098 - val_accuracy: 0.9698 - lr: 3.7440e-06\n",
      "\n",
      "Epoch 334: LearningRateScheduler setting learning rate to 3.740120634800736e-06.\n",
      "Epoch 334/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9995    \n",
      "Epoch 334: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0376 - accuracy: 0.9995 - val_loss: 6.2461 - val_accuracy: 0.9677 - lr: 3.7401e-06\n",
      "\n",
      "Epoch 335: LearningRateScheduler setting learning rate to 3.7362857400056176e-06.\n",
      "Epoch 335/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9993    \n",
      "Epoch 335: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0200 - accuracy: 0.9993 - val_loss: 5.2096 - val_accuracy: 0.9719 - lr: 3.7363e-06\n",
      "\n",
      "Epoch 336: LearningRateScheduler setting learning rate to 3.732454777281019e-06.\n",
      "Epoch 336/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1040e-04 - accuracy: 1.0000\n",
      "Epoch 336: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 1.1040e-04 - accuracy: 1.0000 - val_loss: 7.9733 - val_accuracy: 0.9691 - lr: 3.7325e-06\n",
      "\n",
      "Epoch 337: LearningRateScheduler setting learning rate to 3.7286277425952323e-06.\n",
      "Epoch 337/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998    \n",
      "Epoch 337: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 3.5193 - val_accuracy: 0.9705 - lr: 3.7286e-06\n",
      "\n",
      "Epoch 338: LearningRateScheduler setting learning rate to 3.7248046319206815e-06.\n",
      "Epoch 338/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9993    \n",
      "Epoch 338: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 38s 267ms/step - loss: 0.0237 - accuracy: 0.9993 - val_loss: 4.2352 - val_accuracy: 0.9691 - lr: 3.7248e-06\n",
      "\n",
      "Epoch 339: LearningRateScheduler setting learning rate to 3.720985441233923e-06.\n",
      "Epoch 339/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9993    \n",
      "Epoch 339: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 5.5249 - val_accuracy: 0.9719 - lr: 3.7210e-06\n",
      "\n",
      "Epoch 340: LearningRateScheduler setting learning rate to 3.7171701665156357e-06.\n",
      "Epoch 340/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9993    \n",
      "Epoch 340: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0428 - accuracy: 0.9993 - val_loss: 9.2133 - val_accuracy: 0.9726 - lr: 3.7172e-06\n",
      "\n",
      "Epoch 341: LearningRateScheduler setting learning rate to 3.713358803750621e-06.\n",
      "Epoch 341/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9993    \n",
      "Epoch 341: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0114 - accuracy: 0.9993 - val_loss: 6.5475 - val_accuracy: 0.9698 - lr: 3.7134e-06\n",
      "\n",
      "Epoch 342: LearningRateScheduler setting learning rate to 3.7095513489277985e-06.\n",
      "Epoch 342/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.8286e-04 - accuracy: 0.9995\n",
      "Epoch 342: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 8.8286e-04 - accuracy: 0.9995 - val_loss: 8.7515 - val_accuracy: 0.9712 - lr: 3.7096e-06\n",
      "\n",
      "Epoch 343: LearningRateScheduler setting learning rate to 3.7057477980401984e-06.\n",
      "Epoch 343/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.1463e-06 - accuracy: 1.0000\n",
      "Epoch 343: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 9.1463e-06 - accuracy: 1.0000 - val_loss: 4.7202 - val_accuracy: 0.9698 - lr: 3.7057e-06\n",
      "\n",
      "Epoch 344: LearningRateScheduler setting learning rate to 3.7019481470849607e-06.\n",
      "Epoch 344/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9998    \n",
      "Epoch 344: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0166 - accuracy: 0.9998 - val_loss: 16.0063 - val_accuracy: 0.9691 - lr: 3.7019e-06\n",
      "\n",
      "Epoch 345: LearningRateScheduler setting learning rate to 3.6981523920633285e-06.\n",
      "Epoch 345/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9998    \n",
      "Epoch 345: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 10.9689 - val_accuracy: 0.9691 - lr: 3.6982e-06\n",
      "\n",
      "Epoch 346: LearningRateScheduler setting learning rate to 3.694360528980646e-06.\n",
      "Epoch 346/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9998    \n",
      "Epoch 346: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0126 - accuracy: 0.9998 - val_loss: 5.1151 - val_accuracy: 0.9684 - lr: 3.6944e-06\n",
      "\n",
      "Epoch 347: LearningRateScheduler setting learning rate to 3.6905725538463538e-06.\n",
      "Epoch 347/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9995    \n",
      "Epoch 347: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0154 - accuracy: 0.9995 - val_loss: 13.0051 - val_accuracy: 0.9726 - lr: 3.6906e-06\n",
      "\n",
      "Epoch 348: LearningRateScheduler setting learning rate to 3.6867884626739823e-06.\n",
      "Epoch 348/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9995    \n",
      "Epoch 348: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 6.4582 - val_accuracy: 0.9754 - lr: 3.6868e-06\n",
      "\n",
      "Epoch 349: LearningRateScheduler setting learning rate to 3.6830082514811517e-06.\n",
      "Epoch 349/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9998    \n",
      "Epoch 349: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 5.6552 - val_accuracy: 0.9733 - lr: 3.6830e-06\n",
      "\n",
      "Epoch 350: LearningRateScheduler setting learning rate to 3.6792319162895633e-06.\n",
      "Epoch 350/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9991    \n",
      "Epoch 350: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 4.0805 - val_accuracy: 0.9740 - lr: 3.6792e-06\n",
      "\n",
      "Epoch 351: LearningRateScheduler setting learning rate to 3.675459453124999e-06.\n",
      "Epoch 351/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9995    \n",
      "Epoch 351: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0135 - accuracy: 0.9995 - val_loss: 6.8299 - val_accuracy: 0.9712 - lr: 3.6755e-06\n",
      "\n",
      "Epoch 352: LearningRateScheduler setting learning rate to 3.6716908580173155e-06.\n",
      "Epoch 352/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9984    \n",
      "Epoch 352: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0406 - accuracy: 0.9984 - val_loss: 3.8573 - val_accuracy: 0.9740 - lr: 3.6717e-06\n",
      "\n",
      "Epoch 353: LearningRateScheduler setting learning rate to 3.6679261270004384e-06.\n",
      "Epoch 353/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9991    \n",
      "Epoch 353: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0400 - accuracy: 0.9991 - val_loss: 9.5124 - val_accuracy: 0.9726 - lr: 3.6679e-06\n",
      "\n",
      "Epoch 354: LearningRateScheduler setting learning rate to 3.664165256112363e-06.\n",
      "Epoch 354/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9991    \n",
      "Epoch 354: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0293 - accuracy: 0.9991 - val_loss: 5.4437 - val_accuracy: 0.9705 - lr: 3.6642e-06\n",
      "\n",
      "Epoch 355: LearningRateScheduler setting learning rate to 3.660408241395144e-06.\n",
      "Epoch 355/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9998    \n",
      "Epoch 355: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0112 - accuracy: 0.9998 - val_loss: 6.7380 - val_accuracy: 0.9733 - lr: 3.6604e-06\n",
      "\n",
      "Epoch 356: LearningRateScheduler setting learning rate to 3.6566550788948975e-06.\n",
      "Epoch 356/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995    \n",
      "Epoch 356: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 14.2289 - val_accuracy: 0.9691 - lr: 3.6567e-06\n",
      "\n",
      "Epoch 357: LearningRateScheduler setting learning rate to 3.6529057646617893e-06.\n",
      "Epoch 357/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4811e-04 - accuracy: 1.0000\n",
      "Epoch 357: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 1.4811e-04 - accuracy: 1.0000 - val_loss: 2.4502 - val_accuracy: 0.9733 - lr: 3.6529e-06\n",
      "\n",
      "Epoch 358: LearningRateScheduler setting learning rate to 3.64916029475004e-06.\n",
      "Epoch 358/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9998    \n",
      "Epoch 358: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 6.4939 - val_accuracy: 0.9719 - lr: 3.6492e-06\n",
      "\n",
      "Epoch 359: LearningRateScheduler setting learning rate to 3.6454186652179125e-06.\n",
      "Epoch 359/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.1414e-04 - accuracy: 0.9998\n",
      "Epoch 359: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 9.1414e-04 - accuracy: 0.9998 - val_loss: 7.0673 - val_accuracy: 0.9733 - lr: 3.6454e-06\n",
      "\n",
      "Epoch 360: LearningRateScheduler setting learning rate to 3.6416808721277125e-06.\n",
      "Epoch 360/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9995    \n",
      "Epoch 360: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 7.7629 - val_accuracy: 0.9705 - lr: 3.6417e-06\n",
      "\n",
      "Epoch 361: LearningRateScheduler setting learning rate to 3.637946911545784e-06.\n",
      "Epoch 361/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9993    \n",
      "Epoch 361: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0203 - accuracy: 0.9993 - val_loss: 4.7448 - val_accuracy: 0.9768 - lr: 3.6379e-06\n",
      "\n",
      "Epoch 362: LearningRateScheduler setting learning rate to 3.634216779542502e-06.\n",
      "Epoch 362/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9991    \n",
      "Epoch 362: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 38s 270ms/step - loss: 0.0333 - accuracy: 0.9991 - val_loss: 7.5640 - val_accuracy: 0.9719 - lr: 3.6342e-06\n",
      "\n",
      "Epoch 363: LearningRateScheduler setting learning rate to 3.6304904721922735e-06.\n",
      "Epoch 363/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9988    \n",
      "Epoch 363: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0284 - accuracy: 0.9988 - val_loss: 7.3095 - val_accuracy: 0.9733 - lr: 3.6305e-06\n",
      "\n",
      "Epoch 364: LearningRateScheduler setting learning rate to 3.626767985573528e-06.\n",
      "Epoch 364/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9993    \n",
      "Epoch 364: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0140 - accuracy: 0.9993 - val_loss: 8.2526 - val_accuracy: 0.9691 - lr: 3.6268e-06\n",
      "\n",
      "Epoch 365: LearningRateScheduler setting learning rate to 3.623049315768719e-06.\n",
      "Epoch 365/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9991    \n",
      "Epoch 365: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0231 - accuracy: 0.9991 - val_loss: 8.4869 - val_accuracy: 0.9677 - lr: 3.6230e-06\n",
      "\n",
      "Epoch 366: LearningRateScheduler setting learning rate to 3.6193344588643138e-06.\n",
      "Epoch 366/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9991    \n",
      "Epoch 366: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0361 - accuracy: 0.9991 - val_loss: 9.4955 - val_accuracy: 0.9726 - lr: 3.6193e-06\n",
      "\n",
      "Epoch 367: LearningRateScheduler setting learning rate to 3.615623410950793e-06.\n",
      "Epoch 367/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9972\n",
      "Epoch 367: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0211 - accuracy: 0.9972 - val_loss: 10.3635 - val_accuracy: 0.9502 - lr: 3.6156e-06\n",
      "\n",
      "Epoch 368: LearningRateScheduler setting learning rate to 3.6119161681226477e-06.\n",
      "Epoch 368/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9995    \n",
      "Epoch 368: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0113 - accuracy: 0.9995 - val_loss: 4.9784 - val_accuracy: 0.9677 - lr: 3.6119e-06\n",
      "\n",
      "Epoch 369: LearningRateScheduler setting learning rate to 3.608212726478371e-06.\n",
      "Epoch 369/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.9701e-05 - accuracy: 1.0000\n",
      "Epoch 369: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 2.9701e-05 - accuracy: 1.0000 - val_loss: 7.2125 - val_accuracy: 0.9691 - lr: 3.6082e-06\n",
      "\n",
      "Epoch 370: LearningRateScheduler setting learning rate to 3.604513082120459e-06.\n",
      "Epoch 370/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995    \n",
      "Epoch 370: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 6.1471 - val_accuracy: 0.9698 - lr: 3.6045e-06\n",
      "\n",
      "Epoch 371: LearningRateScheduler setting learning rate to 3.600817231155401e-06.\n",
      "Epoch 371/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.8801e-05 - accuracy: 1.0000\n",
      "Epoch 371: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.8801e-05 - accuracy: 1.0000 - val_loss: 10.4807 - val_accuracy: 0.9691 - lr: 3.6008e-06\n",
      "\n",
      "Epoch 372: LearningRateScheduler setting learning rate to 3.5971251696936814e-06.\n",
      "Epoch 372/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9998    \n",
      "Epoch 372: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 6.9336 - val_accuracy: 0.9677 - lr: 3.5971e-06\n",
      "\n",
      "Epoch 373: LearningRateScheduler setting learning rate to 3.5934368938497706e-06.\n",
      "Epoch 373/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9998    \n",
      "Epoch 373: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0066 - accuracy: 0.9998 - val_loss: 2.8141 - val_accuracy: 0.9684 - lr: 3.5934e-06\n",
      "\n",
      "Epoch 374: LearningRateScheduler setting learning rate to 3.5897523997421243e-06.\n",
      "Epoch 374/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9995    \n",
      "Epoch 374: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 6.2912 - val_accuracy: 0.9670 - lr: 3.5898e-06\n",
      "\n",
      "Epoch 375: LearningRateScheduler setting learning rate to 3.586071683493176e-06.\n",
      "Epoch 375/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.7863e-04 - accuracy: 0.9998\n",
      "Epoch 375: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 2.7863e-04 - accuracy: 0.9998 - val_loss: 15.2866 - val_accuracy: 0.9705 - lr: 3.5861e-06\n",
      "\n",
      "Epoch 376: LearningRateScheduler setting learning rate to 3.5823947412293393e-06.\n",
      "Epoch 376/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5357e-06 - accuracy: 1.0000\n",
      "Epoch 376: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 2.5357e-06 - accuracy: 1.0000 - val_loss: 9.1051 - val_accuracy: 0.9733 - lr: 3.5824e-06\n",
      "\n",
      "Epoch 377: LearningRateScheduler setting learning rate to 3.578721569080994e-06.\n",
      "Epoch 377/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.3165e-06 - accuracy: 1.0000\n",
      "Epoch 377: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 2.3165e-06 - accuracy: 1.0000 - val_loss: 12.6001 - val_accuracy: 0.9719 - lr: 3.5787e-06\n",
      "\n",
      "Epoch 378: LearningRateScheduler setting learning rate to 3.575052163182492e-06.\n",
      "Epoch 378/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9995    \n",
      "Epoch 378: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 11.6668 - val_accuracy: 0.9726 - lr: 3.5751e-06\n",
      "\n",
      "Epoch 379: LearningRateScheduler setting learning rate to 3.571386519672147e-06.\n",
      "Epoch 379/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9995    \n",
      "Epoch 379: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 6.9012 - val_accuracy: 0.9719 - lr: 3.5714e-06\n",
      "\n",
      "Epoch 380: LearningRateScheduler setting learning rate to 3.5677246346922317e-06.\n",
      "Epoch 380/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9981    \n",
      "Epoch 380: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.1013 - accuracy: 0.9981 - val_loss: 7.3477 - val_accuracy: 0.9740 - lr: 3.5677e-06\n",
      "\n",
      "Epoch 381: LearningRateScheduler setting learning rate to 3.564066504388976e-06.\n",
      "Epoch 381/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9963\n",
      "Epoch 381: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0298 - accuracy: 0.9963 - val_loss: 7.0653 - val_accuracy: 0.9635 - lr: 3.5641e-06\n",
      "\n",
      "Epoch 382: LearningRateScheduler setting learning rate to 3.5604121249125596e-06.\n",
      "Epoch 382/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9974\n",
      "Epoch 382: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0611 - accuracy: 0.9974 - val_loss: 8.3598 - val_accuracy: 0.9635 - lr: 3.5604e-06\n",
      "\n",
      "Epoch 383: LearningRateScheduler setting learning rate to 3.55676149241711e-06.\n",
      "Epoch 383/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9986    \n",
      "Epoch 383: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0780 - accuracy: 0.9986 - val_loss: 11.0592 - val_accuracy: 0.9670 - lr: 3.5568e-06\n",
      "\n",
      "Epoch 384: LearningRateScheduler setting learning rate to 3.553114603060699e-06.\n",
      "Epoch 384/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0262e-04 - accuracy: 1.0000\n",
      "Epoch 384: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 1.0262e-04 - accuracy: 1.0000 - val_loss: 6.7127 - val_accuracy: 0.9691 - lr: 3.5531e-06\n",
      "\n",
      "Epoch 385: LearningRateScheduler setting learning rate to 3.5494714530053365e-06.\n",
      "Epoch 385/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9998    \n",
      "Epoch 385: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 268ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 5.2846 - val_accuracy: 0.9712 - lr: 3.5495e-06\n",
      "\n",
      "Epoch 386: LearningRateScheduler setting learning rate to 3.545832038416968e-06.\n",
      "Epoch 386/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998    \n",
      "Epoch 386: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 7.5142 - val_accuracy: 0.9677 - lr: 3.5458e-06\n",
      "\n",
      "Epoch 387: LearningRateScheduler setting learning rate to 3.54219635546547e-06.\n",
      "Epoch 387/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9991    \n",
      "Epoch 387: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0146 - accuracy: 0.9991 - val_loss: 13.1100 - val_accuracy: 0.9691 - lr: 3.5422e-06\n",
      "\n",
      "Epoch 388: LearningRateScheduler setting learning rate to 3.5385644003246473e-06.\n",
      "Epoch 388/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9995    \n",
      "Epoch 388: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 11.6474 - val_accuracy: 0.9691 - lr: 3.5386e-06\n",
      "\n",
      "Epoch 389: LearningRateScheduler setting learning rate to 3.534936169172227e-06.\n",
      "Epoch 389/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1484e-04 - accuracy: 1.0000\n",
      "Epoch 389: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 1.1484e-04 - accuracy: 1.0000 - val_loss: 7.7613 - val_accuracy: 0.9705 - lr: 3.5349e-06\n",
      "\n",
      "Epoch 390: LearningRateScheduler setting learning rate to 3.5313116581898537e-06.\n",
      "Epoch 390/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9998    \n",
      "Epoch 390: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 10.3679 - val_accuracy: 0.9719 - lr: 3.5313e-06\n",
      "\n",
      "Epoch 391: LearningRateScheduler setting learning rate to 3.5276908635630903e-06.\n",
      "Epoch 391/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 391: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 38s 270ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 11.7805 - val_accuracy: 0.9712 - lr: 3.5277e-06\n",
      "\n",
      "Epoch 392: LearningRateScheduler setting learning rate to 3.5240737814814086e-06.\n",
      "Epoch 392/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9998    \n",
      "Epoch 392: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 6.3288 - val_accuracy: 0.9719 - lr: 3.5241e-06\n",
      "\n",
      "Epoch 393: LearningRateScheduler setting learning rate to 3.5204604081381883e-06.\n",
      "Epoch 393/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9995    \n",
      "Epoch 393: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 11.7913 - val_accuracy: 0.9719 - lr: 3.5205e-06\n",
      "\n",
      "Epoch 394: LearningRateScheduler setting learning rate to 3.5168507397307123e-06.\n",
      "Epoch 394/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0417e-05 - accuracy: 1.0000\n",
      "Epoch 394: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 1.0417e-05 - accuracy: 1.0000 - val_loss: 8.4198 - val_accuracy: 0.9726 - lr: 3.5169e-06\n",
      "\n",
      "Epoch 395: LearningRateScheduler setting learning rate to 3.513244772460162e-06.\n",
      "Epoch 395/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998    \n",
      "Epoch 395: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 7.0463 - val_accuracy: 0.9712 - lr: 3.5132e-06\n",
      "\n",
      "Epoch 396: LearningRateScheduler setting learning rate to 3.509642502531614e-06.\n",
      "Epoch 396/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9988    \n",
      "Epoch 396: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0279 - accuracy: 0.9988 - val_loss: 9.8471 - val_accuracy: 0.9726 - lr: 3.5096e-06\n",
      "\n",
      "Epoch 397: LearningRateScheduler setting learning rate to 3.5060439261540358e-06.\n",
      "Epoch 397/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9993    \n",
      "Epoch 397: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 38s 270ms/step - loss: 0.0450 - accuracy: 0.9993 - val_loss: 6.4852 - val_accuracy: 0.9698 - lr: 3.5060e-06\n",
      "\n",
      "Epoch 398: LearningRateScheduler setting learning rate to 3.502449039540283e-06.\n",
      "Epoch 398/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998    \n",
      "Epoch 398: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 40s 289ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 10.8293 - val_accuracy: 0.9719 - lr: 3.5024e-06\n",
      "\n",
      "Epoch 399: LearningRateScheduler setting learning rate to 3.498857838907094e-06.\n",
      "Epoch 399/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.5286e-06 - accuracy: 1.0000\n",
      "Epoch 399: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 4.5286e-06 - accuracy: 1.0000 - val_loss: 2.9751 - val_accuracy: 0.9726 - lr: 3.4989e-06\n",
      "\n",
      "Epoch 400: LearningRateScheduler setting learning rate to 3.4952703204750852e-06.\n",
      "Epoch 400/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.8617e-06 - accuracy: 1.0000\n",
      "Epoch 400: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 3.8617e-06 - accuracy: 1.0000 - val_loss: 5.2429 - val_accuracy: 0.9733 - lr: 3.4953e-06\n",
      "\n",
      "Epoch 401: LearningRateScheduler setting learning rate to 3.491686480468749e-06.\n",
      "Epoch 401/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.3906e-06 - accuracy: 1.0000\n",
      "Epoch 401: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 3.3906e-06 - accuracy: 1.0000 - val_loss: 7.8433 - val_accuracy: 0.9705 - lr: 3.4917e-06\n",
      "\n",
      "Epoch 402: LearningRateScheduler setting learning rate to 3.4881063151164495e-06.\n",
      "Epoch 402/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.9149e-06 - accuracy: 1.0000\n",
      "Epoch 402: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 2.9149e-06 - accuracy: 1.0000 - val_loss: 3.4716 - val_accuracy: 0.9726 - lr: 3.4881e-06\n",
      "\n",
      "Epoch 403: LearningRateScheduler setting learning rate to 3.4845298206504163e-06.\n",
      "Epoch 403/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.0179e-06 - accuracy: 1.0000\n",
      "Epoch 403: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 3.0179e-06 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.9733 - lr: 3.4845e-06\n",
      "\n",
      "Epoch 404: LearningRateScheduler setting learning rate to 3.480956993306745e-06.\n",
      "Epoch 404/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9995    \n",
      "Epoch 404: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 3.1114 - val_accuracy: 0.9712 - lr: 3.4810e-06\n",
      "\n",
      "Epoch 405: LearningRateScheduler setting learning rate to 3.477387829325387e-06.\n",
      "Epoch 405/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.4592e-04 - accuracy: 0.9998\n",
      "Epoch 405: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 8.4592e-04 - accuracy: 0.9998 - val_loss: 2.7700 - val_accuracy: 0.9733 - lr: 3.4774e-06\n",
      "\n",
      "Epoch 406: LearningRateScheduler setting learning rate to 3.473822324950152e-06.\n",
      "Epoch 406/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995    \n",
      "Epoch 406: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 3.8854 - val_accuracy: 0.9726 - lr: 3.4738e-06\n",
      "\n",
      "Epoch 407: LearningRateScheduler setting learning rate to 3.4702604764287e-06.\n",
      "Epoch 407/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9995    \n",
      "Epoch 407: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 8.4351 - val_accuracy: 0.9740 - lr: 3.4703e-06\n",
      "\n",
      "Epoch 408: LearningRateScheduler setting learning rate to 3.4667022800125378e-06.\n",
      "Epoch 408/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995    \n",
      "Epoch 408: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 10.0970 - val_accuracy: 0.9698 - lr: 3.4667e-06\n",
      "\n",
      "Epoch 409: LearningRateScheduler setting learning rate to 3.4631477319570167e-06.\n",
      "Epoch 409/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9993    \n",
      "Epoch 409: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0275 - accuracy: 0.9993 - val_loss: 11.0059 - val_accuracy: 0.9628 - lr: 3.4631e-06\n",
      "\n",
      "Epoch 410: LearningRateScheduler setting learning rate to 3.4595968285213266e-06.\n",
      "Epoch 410/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9988\n",
      "Epoch 410: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 13.5650 - val_accuracy: 0.9621 - lr: 3.4596e-06\n",
      "\n",
      "Epoch 411: LearningRateScheduler setting learning rate to 3.4560495659684947e-06.\n",
      "Epoch 411/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9965\n",
      "Epoch 411: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 16.5474 - val_accuracy: 0.9705 - lr: 3.4560e-06\n",
      "\n",
      "Epoch 412: LearningRateScheduler setting learning rate to 3.4525059405653766e-06.\n",
      "Epoch 412/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9993    \n",
      "Epoch 412: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0175 - accuracy: 0.9993 - val_loss: 8.6992 - val_accuracy: 0.9698 - lr: 3.4525e-06\n",
      "\n",
      "Epoch 413: LearningRateScheduler setting learning rate to 3.4489659485826592e-06.\n",
      "Epoch 413/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9988    \n",
      "Epoch 413: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0260 - accuracy: 0.9988 - val_loss: 7.2293 - val_accuracy: 0.9684 - lr: 3.4490e-06\n",
      "\n",
      "Epoch 414: LearningRateScheduler setting learning rate to 3.4454295862948518e-06.\n",
      "Epoch 414/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9995    \n",
      "Epoch 414: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0195 - accuracy: 0.9995 - val_loss: 10.5005 - val_accuracy: 0.9684 - lr: 3.4454e-06\n",
      "\n",
      "Epoch 415: LearningRateScheduler setting learning rate to 3.441896849980283e-06.\n",
      "Epoch 415/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993    \n",
      "Epoch 415: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 11.2483 - val_accuracy: 0.9691 - lr: 3.4419e-06\n",
      "\n",
      "Epoch 416: LearningRateScheduler setting learning rate to 3.4383677359210974e-06.\n",
      "Epoch 416/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9986    \n",
      "Epoch 416: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0671 - accuracy: 0.9986 - val_loss: 7.3035 - val_accuracy: 0.9719 - lr: 3.4384e-06\n",
      "\n",
      "Epoch 417: LearningRateScheduler setting learning rate to 3.4348422404032534e-06.\n",
      "Epoch 417/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9991    \n",
      "Epoch 417: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0370 - accuracy: 0.9991 - val_loss: 7.8351 - val_accuracy: 0.9684 - lr: 3.4348e-06\n",
      "\n",
      "Epoch 418: LearningRateScheduler setting learning rate to 3.4313203597165153e-06.\n",
      "Epoch 418/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998    \n",
      "Epoch 418: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 8.9000 - val_accuracy: 0.9705 - lr: 3.4313e-06\n",
      "\n",
      "Epoch 419: LearningRateScheduler setting learning rate to 3.427802090154453e-06.\n",
      "Epoch 419/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0531e-05 - accuracy: 1.0000\n",
      "Epoch 419: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 1.0531e-05 - accuracy: 1.0000 - val_loss: 2.0165 - val_accuracy: 0.9726 - lr: 3.4278e-06\n",
      "\n",
      "Epoch 420: LearningRateScheduler setting learning rate to 3.424287428014436e-06.\n",
      "Epoch 420/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.8666e-06 - accuracy: 1.0000\n",
      "Epoch 420: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 8.8666e-06 - accuracy: 1.0000 - val_loss: 9.3768 - val_accuracy: 0.9712 - lr: 3.4243e-06\n",
      "\n",
      "Epoch 421: LearningRateScheduler setting learning rate to 3.420776369597631e-06.\n",
      "Epoch 421/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0278e-04 - accuracy: 1.0000\n",
      "Epoch 421: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 1.0278e-04 - accuracy: 1.0000 - val_loss: 11.4703 - val_accuracy: 0.9698 - lr: 3.4208e-06\n",
      "\n",
      "Epoch 422: LearningRateScheduler setting learning rate to 3.417268911208997e-06.\n",
      "Epoch 422/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998    \n",
      "Epoch 422: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 12.6436 - val_accuracy: 0.9670 - lr: 3.4173e-06\n",
      "\n",
      "Epoch 423: LearningRateScheduler setting learning rate to 3.413765049157282e-06.\n",
      "Epoch 423/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9993    \n",
      "Epoch 423: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 0.0241 - accuracy: 0.9993 - val_loss: 12.7258 - val_accuracy: 0.9677 - lr: 3.4138e-06\n",
      "\n",
      "Epoch 424: LearningRateScheduler setting learning rate to 3.4102647797550177e-06.\n",
      "Epoch 424/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9998    \n",
      "Epoch 424: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 26.9031 - val_accuracy: 0.9663 - lr: 3.4103e-06\n",
      "\n",
      "Epoch 425: LearningRateScheduler setting learning rate to 3.4067680993185176e-06.\n",
      "Epoch 425/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.9311e-04 - accuracy: 0.9998\n",
      "Epoch 425: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 9.9311e-04 - accuracy: 0.9998 - val_loss: 15.6680 - val_accuracy: 0.9677 - lr: 3.4068e-06\n",
      "\n",
      "Epoch 426: LearningRateScheduler setting learning rate to 3.403275004167872e-06.\n",
      "Epoch 426/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998    \n",
      "Epoch 426: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 12.7839 - val_accuracy: 0.9705 - lr: 3.4033e-06\n",
      "\n",
      "Epoch 427: LearningRateScheduler setting learning rate to 3.399785490626944e-06.\n",
      "Epoch 427/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.6124e-06 - accuracy: 1.0000\n",
      "Epoch 427: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 3.6124e-06 - accuracy: 1.0000 - val_loss: 15.5926 - val_accuracy: 0.9691 - lr: 3.3998e-06\n",
      "\n",
      "Epoch 428: LearningRateScheduler setting learning rate to 3.3962995550233673e-06.\n",
      "Epoch 428/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9993    \n",
      "Epoch 428: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 14.6043 - val_accuracy: 0.9691 - lr: 3.3963e-06\n",
      "\n",
      "Epoch 429: LearningRateScheduler setting learning rate to 3.392817193688539e-06.\n",
      "Epoch 429/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9995    \n",
      "Epoch 429: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0145 - accuracy: 0.9995 - val_loss: 7.8232 - val_accuracy: 0.9705 - lr: 3.3928e-06\n",
      "\n",
      "Epoch 430: LearningRateScheduler setting learning rate to 3.38933840295762e-06.\n",
      "Epoch 430/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9995    \n",
      "Epoch 430: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0126 - accuracy: 0.9995 - val_loss: 5.7145 - val_accuracy: 0.9712 - lr: 3.3893e-06\n",
      "\n",
      "Epoch 431: LearningRateScheduler setting learning rate to 3.385863179169527e-06.\n",
      "Epoch 431/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9986    \n",
      "Epoch 431: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0300 - accuracy: 0.9986 - val_loss: 7.9840 - val_accuracy: 0.9712 - lr: 3.3859e-06\n",
      "\n",
      "Epoch 432: LearningRateScheduler setting learning rate to 3.382391518666931e-06.\n",
      "Epoch 432/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9951\n",
      "Epoch 432: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0372 - accuracy: 0.9951 - val_loss: 8.3430 - val_accuracy: 0.9663 - lr: 3.3824e-06\n",
      "\n",
      "Epoch 433: LearningRateScheduler setting learning rate to 3.3789234177962543e-06.\n",
      "Epoch 433/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9991    \n",
      "Epoch 433: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0155 - accuracy: 0.9991 - val_loss: 12.1085 - val_accuracy: 0.9677 - lr: 3.3789e-06\n",
      "\n",
      "Epoch 434: LearningRateScheduler setting learning rate to 3.3754588729076636e-06.\n",
      "Epoch 434/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998    \n",
      "Epoch 434: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 17.4999 - val_accuracy: 0.9684 - lr: 3.3755e-06\n",
      "\n",
      "Epoch 435: LearningRateScheduler setting learning rate to 3.3719978803550694e-06.\n",
      "Epoch 435/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5201e-05 - accuracy: 1.0000\n",
      "Epoch 435: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 2.5201e-05 - accuracy: 1.0000 - val_loss: 7.1409 - val_accuracy: 0.9677 - lr: 3.3720e-06\n",
      "\n",
      "Epoch 436: LearningRateScheduler setting learning rate to 3.3685404364961192e-06.\n",
      "Epoch 436/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.2970e-06 - accuracy: 1.0000\n",
      "Epoch 436: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 9.2970e-06 - accuracy: 1.0000 - val_loss: 7.0995 - val_accuracy: 0.9698 - lr: 3.3685e-06\n",
      "\n",
      "Epoch 437: LearningRateScheduler setting learning rate to 3.3650865376921965e-06.\n",
      "Epoch 437/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.0633e-06 - accuracy: 1.0000\n",
      "Epoch 437: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 7.0633e-06 - accuracy: 1.0000 - val_loss: 11.6880 - val_accuracy: 0.9684 - lr: 3.3651e-06\n",
      "\n",
      "Epoch 438: LearningRateScheduler setting learning rate to 3.3616361803084145e-06.\n",
      "Epoch 438/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9998    \n",
      "Epoch 438: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 14.3800 - val_accuracy: 0.9670 - lr: 3.3616e-06\n",
      "\n",
      "Epoch 439: LearningRateScheduler setting learning rate to 3.358189360713615e-06.\n",
      "Epoch 439/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.4283e-06 - accuracy: 1.0000\n",
      "Epoch 439: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 5.4283e-06 - accuracy: 1.0000 - val_loss: 8.6075 - val_accuracy: 0.9705 - lr: 3.3582e-06\n",
      "\n",
      "Epoch 440: LearningRateScheduler setting learning rate to 3.3547460752803605e-06.\n",
      "Epoch 440/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.5050e-06 - accuracy: 1.0000\n",
      "Epoch 440: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 3.5050e-06 - accuracy: 1.0000 - val_loss: 20.5621 - val_accuracy: 0.9677 - lr: 3.3547e-06\n",
      "\n",
      "Epoch 441: LearningRateScheduler setting learning rate to 3.3513063203849354e-06.\n",
      "Epoch 441/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995    \n",
      "Epoch 441: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 7.9839 - val_accuracy: 0.9726 - lr: 3.3513e-06\n",
      "\n",
      "Epoch 442: LearningRateScheduler setting learning rate to 3.3478700924073382e-06.\n",
      "Epoch 442/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.7036e-06 - accuracy: 1.0000\n",
      "Epoch 442: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 6.7036e-06 - accuracy: 1.0000 - val_loss: 12.9824 - val_accuracy: 0.9726 - lr: 3.3479e-06\n",
      "\n",
      "Epoch 443: LearningRateScheduler setting learning rate to 3.344437387731279e-06.\n",
      "Epoch 443/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4981e-05 - accuracy: 1.0000\n",
      "Epoch 443: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 1.4981e-05 - accuracy: 1.0000 - val_loss: 7.4048 - val_accuracy: 0.9726 - lr: 3.3444e-06\n",
      "\n",
      "Epoch 444: LearningRateScheduler setting learning rate to 3.3410082027441766e-06.\n",
      "Epoch 444/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.6420e-04 - accuracy: 0.9998\n",
      "Epoch 444: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 3.6420e-04 - accuracy: 0.9998 - val_loss: 12.8198 - val_accuracy: 0.9719 - lr: 3.3410e-06\n",
      "\n",
      "Epoch 445: LearningRateScheduler setting learning rate to 3.3375825338371537e-06.\n",
      "Epoch 445/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.8754e-05 - accuracy: 1.0000\n",
      "Epoch 445: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 9.8754e-05 - accuracy: 1.0000 - val_loss: 16.4672 - val_accuracy: 0.9705 - lr: 3.3376e-06\n",
      "\n",
      "Epoch 446: LearningRateScheduler setting learning rate to 3.334160377405033e-06.\n",
      "Epoch 446/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.0646e-05 - accuracy: 1.0000\n",
      "Epoch 446: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 8.0646e-05 - accuracy: 1.0000 - val_loss: 11.0012 - val_accuracy: 0.9705 - lr: 3.3342e-06\n",
      "\n",
      "Epoch 447: LearningRateScheduler setting learning rate to 3.330741729846334e-06.\n",
      "Epoch 447/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998    \n",
      "Epoch 447: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 9.3191 - val_accuracy: 0.9726 - lr: 3.3307e-06\n",
      "\n",
      "Epoch 448: LearningRateScheduler setting learning rate to 3.3273265875632687e-06.\n",
      "Epoch 448/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9988    \n",
      "Epoch 448: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0620 - accuracy: 0.9988 - val_loss: 23.5619 - val_accuracy: 0.9698 - lr: 3.3273e-06\n",
      "\n",
      "Epoch 449: LearningRateScheduler setting learning rate to 3.3239149469617393e-06.\n",
      "Epoch 449/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9981    \n",
      "Epoch 449: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.1244 - accuracy: 0.9981 - val_loss: 13.2674 - val_accuracy: 0.9719 - lr: 3.3239e-06\n",
      "\n",
      "Epoch 450: LearningRateScheduler setting learning rate to 3.3205068044513304e-06.\n",
      "Epoch 450/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9981    \n",
      "Epoch 450: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0561 - accuracy: 0.9981 - val_loss: 14.6299 - val_accuracy: 0.9698 - lr: 3.3205e-06\n",
      "\n",
      "Epoch 451: LearningRateScheduler setting learning rate to 3.3171021564453116e-06.\n",
      "Epoch 451/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9988    \n",
      "Epoch 451: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0571 - accuracy: 0.9988 - val_loss: 12.9509 - val_accuracy: 0.9684 - lr: 3.3171e-06\n",
      "\n",
      "Epoch 452: LearningRateScheduler setting learning rate to 3.313700999360627e-06.\n",
      "Epoch 452/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9993    \n",
      "Epoch 452: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0214 - accuracy: 0.9993 - val_loss: 21.9044 - val_accuracy: 0.9698 - lr: 3.3137e-06\n",
      "\n",
      "Epoch 453: LearningRateScheduler setting learning rate to 3.3103033296178953e-06.\n",
      "Epoch 453/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.8055e-06 - accuracy: 1.0000\n",
      "Epoch 453: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 3.8055e-06 - accuracy: 1.0000 - val_loss: 9.1844 - val_accuracy: 0.9719 - lr: 3.3103e-06\n",
      "\n",
      "Epoch 454: LearningRateScheduler setting learning rate to 3.306909143641407e-06.\n",
      "Epoch 454/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.2034e-06 - accuracy: 1.0000\n",
      "Epoch 454: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 3.2034e-06 - accuracy: 1.0000 - val_loss: 12.0220 - val_accuracy: 0.9719 - lr: 3.3069e-06\n",
      "\n",
      "Epoch 455: LearningRateScheduler setting learning rate to 3.3035184378591172e-06.\n",
      "Epoch 455/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.7590e-06 - accuracy: 1.0000\n",
      "Epoch 455: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 2.7590e-06 - accuracy: 1.0000 - val_loss: 12.8601 - val_accuracy: 0.9719 - lr: 3.3035e-06\n",
      "\n",
      "Epoch 456: LearningRateScheduler setting learning rate to 3.3001312087026444e-06.\n",
      "Epoch 456/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998    \n",
      "Epoch 456: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 19.2545 - val_accuracy: 0.9698 - lr: 3.3001e-06\n",
      "\n",
      "Epoch 457: LearningRateScheduler setting learning rate to 3.2967474526072653e-06.\n",
      "Epoch 457/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9995    \n",
      "Epoch 457: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 19.0933 - val_accuracy: 0.9691 - lr: 3.2967e-06\n",
      "\n",
      "Epoch 458: LearningRateScheduler setting learning rate to 3.2933671660119103e-06.\n",
      "Epoch 458/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9993    \n",
      "Epoch 458: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 8.1589 - val_accuracy: 0.9691 - lr: 3.2934e-06\n",
      "\n",
      "Epoch 459: LearningRateScheduler setting learning rate to 3.289990345359166e-06.\n",
      "Epoch 459/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9991    \n",
      "Epoch 459: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 269ms/step - loss: 0.0238 - accuracy: 0.9991 - val_loss: 8.1305 - val_accuracy: 0.9775 - lr: 3.2900e-06\n",
      "\n",
      "Epoch 460: LearningRateScheduler setting learning rate to 3.28661698709526e-06.\n",
      "Epoch 460/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9998    \n",
      "Epoch 460: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 13.3317 - val_accuracy: 0.9768 - lr: 3.2866e-06\n",
      "\n",
      "Epoch 461: LearningRateScheduler setting learning rate to 3.2832470876700695e-06.\n",
      "Epoch 461/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.6907e-06 - accuracy: 1.0000\n",
      "Epoch 461: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 5.6907e-06 - accuracy: 1.0000 - val_loss: 13.4972 - val_accuracy: 0.9747 - lr: 3.2832e-06\n",
      "\n",
      "Epoch 462: LearningRateScheduler setting learning rate to 3.2798806435371077e-06.\n",
      "Epoch 462/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4533e-06 - accuracy: 1.0000\n",
      "Epoch 462: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 2.4533e-06 - accuracy: 1.0000 - val_loss: 5.5522 - val_accuracy: 0.9747 - lr: 3.2799e-06\n",
      "\n",
      "Epoch 463: LearningRateScheduler setting learning rate to 3.276517651153526e-06.\n",
      "Epoch 463/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9995    \n",
      "Epoch 463: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0124 - accuracy: 0.9995 - val_loss: 12.1799 - val_accuracy: 0.9761 - lr: 3.2765e-06\n",
      "\n",
      "Epoch 464: LearningRateScheduler setting learning rate to 3.2731581069801096e-06.\n",
      "Epoch 464/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9998    \n",
      "Epoch 464: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 8.3632 - val_accuracy: 0.9747 - lr: 3.2732e-06\n",
      "\n",
      "Epoch 465: LearningRateScheduler setting learning rate to 3.2698020074812687e-06.\n",
      "Epoch 465/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.0177e-04 - accuracy: 0.9998\n",
      "Epoch 465: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 4.0177e-04 - accuracy: 0.9998 - val_loss: 7.3166 - val_accuracy: 0.9726 - lr: 3.2698e-06\n",
      "\n",
      "Epoch 466: LearningRateScheduler setting learning rate to 3.2664493491250428e-06.\n",
      "Epoch 466/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.7516e-06 - accuracy: 1.0000\n",
      "Epoch 466: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 4.7516e-06 - accuracy: 1.0000 - val_loss: 10.0365 - val_accuracy: 0.9747 - lr: 3.2664e-06\n",
      "\n",
      "Epoch 467: LearningRateScheduler setting learning rate to 3.2631001283830903e-06.\n",
      "Epoch 467/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.2374e-06 - accuracy: 1.0000\n",
      "Epoch 467: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 4.2374e-06 - accuracy: 1.0000 - val_loss: 6.9568 - val_accuracy: 0.9747 - lr: 3.2631e-06\n",
      "\n",
      "Epoch 468: LearningRateScheduler setting learning rate to 3.259754341730689e-06.\n",
      "Epoch 468/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 6.9140e-06 - accuracy: 1.0000\n",
      "Epoch 468: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 6.9140e-06 - accuracy: 1.0000 - val_loss: 8.5202 - val_accuracy: 0.9754 - lr: 3.2598e-06\n",
      "\n",
      "Epoch 469: LearningRateScheduler setting learning rate to 3.25641198564673e-06.\n",
      "Epoch 469/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.4835e-06 - accuracy: 1.0000\n",
      "Epoch 469: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 40s 289ms/step - loss: 2.4835e-06 - accuracy: 1.0000 - val_loss: 18.9774 - val_accuracy: 0.9740 - lr: 3.2564e-06\n",
      "\n",
      "Epoch 470: LearningRateScheduler setting learning rate to 3.253073056613714e-06.\n",
      "Epoch 470/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.6929e-06 - accuracy: 1.0000\n",
      "Epoch 470: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 270ms/step - loss: 2.6929e-06 - accuracy: 1.0000 - val_loss: 6.0082 - val_accuracy: 0.9768 - lr: 3.2531e-06\n",
      "\n",
      "Epoch 471: LearningRateScheduler setting learning rate to 3.2497375511177494e-06.\n",
      "Epoch 471/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.8572e-04 - accuracy: 0.9998\n",
      "Epoch 471: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.8572e-04 - accuracy: 0.9998 - val_loss: 9.2454 - val_accuracy: 0.9754 - lr: 3.2497e-06\n",
      "\n",
      "Epoch 472: LearningRateScheduler setting learning rate to 3.246405465648547e-06.\n",
      "Epoch 472/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9998    \n",
      "Epoch 472: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 266ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 13.4683 - val_accuracy: 0.9698 - lr: 3.2464e-06\n",
      "\n",
      "Epoch 473: LearningRateScheduler setting learning rate to 3.243076796699418e-06.\n",
      "Epoch 473/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9998    \n",
      "Epoch 473: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 13.5388 - val_accuracy: 0.9712 - lr: 3.2431e-06\n",
      "\n",
      "Epoch 474: LearningRateScheduler setting learning rate to 3.2397515407672664e-06.\n",
      "Epoch 474/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5063e-06 - accuracy: 1.0000\n",
      "Epoch 474: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 2.5063e-06 - accuracy: 1.0000 - val_loss: 3.8031 - val_accuracy: 0.9726 - lr: 3.2398e-06\n",
      "\n",
      "Epoch 475: LearningRateScheduler setting learning rate to 3.2364296943525914e-06.\n",
      "Epoch 475/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.9970e-06 - accuracy: 1.0000\n",
      "Epoch 475: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 1.9970e-06 - accuracy: 1.0000 - val_loss: 12.1217 - val_accuracy: 0.9712 - lr: 3.2364e-06\n",
      "\n",
      "Epoch 476: LearningRateScheduler setting learning rate to 3.2331112539594783e-06.\n",
      "Epoch 476/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.7221e-06 - accuracy: 1.0000\n",
      "Epoch 476: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 1.7221e-06 - accuracy: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.9754 - lr: 3.2331e-06\n",
      "\n",
      "Epoch 477: LearningRateScheduler setting learning rate to 3.229796216095597e-06.\n",
      "Epoch 477/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9995    \n",
      "Epoch 477: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0158 - accuracy: 0.9995 - val_loss: 11.3942 - val_accuracy: 0.9740 - lr: 3.2298e-06\n",
      "\n",
      "Epoch 478: LearningRateScheduler setting learning rate to 3.2264845772721985e-06.\n",
      "Epoch 478/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9981    \n",
      "Epoch 478: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0596 - accuracy: 0.9981 - val_loss: 8.1077 - val_accuracy: 0.9432 - lr: 3.2265e-06\n",
      "\n",
      "Epoch 479: LearningRateScheduler setting learning rate to 3.223176334004112e-06.\n",
      "Epoch 479/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9977\n",
      "Epoch 479: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 14.2519 - val_accuracy: 0.9635 - lr: 3.2232e-06\n",
      "\n",
      "Epoch 480: LearningRateScheduler setting learning rate to 3.219871482809739e-06.\n",
      "Epoch 480/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.3571e-04 - accuracy: 1.0000\n",
      "Epoch 480: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 1.3571e-04 - accuracy: 1.0000 - val_loss: 6.1454 - val_accuracy: 0.9712 - lr: 3.2199e-06\n",
      "\n",
      "Epoch 481: LearningRateScheduler setting learning rate to 3.2165700202110505e-06.\n",
      "Epoch 481/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 4.4454e-06 - accuracy: 1.0000\n",
      "Epoch 481: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 4.4454e-06 - accuracy: 1.0000 - val_loss: 16.0654 - val_accuracy: 0.9691 - lr: 3.2166e-06\n",
      "\n",
      "Epoch 482: LearningRateScheduler setting learning rate to 3.2132719427335846e-06.\n",
      "Epoch 482/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9993    \n",
      "Epoch 482: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0138 - accuracy: 0.9993 - val_loss: 20.9128 - val_accuracy: 0.9691 - lr: 3.2133e-06\n",
      "\n",
      "Epoch 483: LearningRateScheduler setting learning rate to 3.2099772469064417e-06.\n",
      "Epoch 483/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9991    \n",
      "Epoch 483: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0259 - accuracy: 0.9991 - val_loss: 10.2973 - val_accuracy: 0.9684 - lr: 3.2100e-06\n",
      "\n",
      "Epoch 484: LearningRateScheduler setting learning rate to 3.20668592926228e-06.\n",
      "Epoch 484/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9995    \n",
      "Epoch 484: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 15.2719 - val_accuracy: 0.9670 - lr: 3.2067e-06\n",
      "\n",
      "Epoch 485: LearningRateScheduler setting learning rate to 3.203397986337316e-06.\n",
      "Epoch 485/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9995    \n",
      "Epoch 485: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 40s 288ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 9.6325 - val_accuracy: 0.9698 - lr: 3.2034e-06\n",
      "\n",
      "Epoch 486: LearningRateScheduler setting learning rate to 3.2001134146713137e-06.\n",
      "Epoch 486/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9998    \n",
      "Epoch 486: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 7.9229 - val_accuracy: 0.9677 - lr: 3.2001e-06\n",
      "\n",
      "Epoch 487: LearningRateScheduler setting learning rate to 3.196832210807587e-06.\n",
      "Epoch 487/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.1980e-04 - accuracy: 0.9998\n",
      "Epoch 487: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 9.1980e-04 - accuracy: 0.9998 - val_loss: 9.6476 - val_accuracy: 0.9712 - lr: 3.1968e-06\n",
      "\n",
      "Epoch 488: LearningRateScheduler setting learning rate to 3.1935543712929938e-06.\n",
      "Epoch 488/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9995    \n",
      "Epoch 488: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 13.8496 - val_accuracy: 0.9712 - lr: 3.1936e-06\n",
      "\n",
      "Epoch 489: LearningRateScheduler setting learning rate to 3.190279892677934e-06.\n",
      "Epoch 489/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9995    \n",
      "Epoch 489: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 260ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 6.2861 - val_accuracy: 0.9733 - lr: 3.1903e-06\n",
      "\n",
      "Epoch 490: LearningRateScheduler setting learning rate to 3.1870087715163427e-06.\n",
      "Epoch 490/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9998    \n",
      "Epoch 490: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 264ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 8.8275 - val_accuracy: 0.9726 - lr: 3.1870e-06\n",
      "\n",
      "Epoch 491: LearningRateScheduler setting learning rate to 3.1837410043656885e-06.\n",
      "Epoch 491/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9995    \n",
      "Epoch 491: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 5.6566 - val_accuracy: 0.9726 - lr: 3.1837e-06\n",
      "\n",
      "Epoch 492: LearningRateScheduler setting learning rate to 3.180476587786971e-06.\n",
      "Epoch 492/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9993    \n",
      "Epoch 492: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0245 - accuracy: 0.9993 - val_loss: 14.9974 - val_accuracy: 0.9705 - lr: 3.1805e-06\n",
      "\n",
      "Epoch 493: LearningRateScheduler setting learning rate to 3.1772155183447145e-06.\n",
      "Epoch 493/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9995    \n",
      "Epoch 493: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0152 - accuracy: 0.9995 - val_loss: 21.2049 - val_accuracy: 0.9698 - lr: 3.1772e-06\n",
      "\n",
      "Epoch 494: LearningRateScheduler setting learning rate to 3.1739577926069675e-06.\n",
      "Epoch 494/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9995    \n",
      "Epoch 494: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 0.0193 - accuracy: 0.9995 - val_loss: 6.7626 - val_accuracy: 0.9726 - lr: 3.1740e-06\n",
      "\n",
      "Epoch 495: LearningRateScheduler setting learning rate to 3.170703407145296e-06.\n",
      "Epoch 495/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9988    \n",
      "Epoch 495: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 263ms/step - loss: 0.0251 - accuracy: 0.9988 - val_loss: 4.8111 - val_accuracy: 0.9719 - lr: 3.1707e-06\n",
      "\n",
      "Epoch 496: LearningRateScheduler setting learning rate to 3.167452358534781e-06.\n",
      "Epoch 496/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9991    \n",
      "Epoch 496: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0120 - accuracy: 0.9991 - val_loss: 10.7759 - val_accuracy: 0.9733 - lr: 3.1675e-06\n",
      "\n",
      "Epoch 497: LearningRateScheduler setting learning rate to 3.1642046433540176e-06.\n",
      "Epoch 497/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995    \n",
      "Epoch 497: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 12.9468 - val_accuracy: 0.9698 - lr: 3.1642e-06\n",
      "\n",
      "Epoch 498: LearningRateScheduler setting learning rate to 3.160960258185106e-06.\n",
      "Epoch 498/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7.0308e-04 - accuracy: 0.9998\n",
      "Epoch 498: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 267ms/step - loss: 7.0308e-04 - accuracy: 0.9998 - val_loss: 33.6914 - val_accuracy: 0.9684 - lr: 3.1610e-06\n",
      "\n",
      "Epoch 499: LearningRateScheduler setting learning rate to 3.157719199613652e-06.\n",
      "Epoch 499/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.6604e-04 - accuracy: 1.0000\n",
      "Epoch 499: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 264ms/step - loss: 1.6604e-04 - accuracy: 1.0000 - val_loss: 16.2265 - val_accuracy: 0.9719 - lr: 3.1577e-06\n",
      "\n",
      "Epoch 500: LearningRateScheduler setting learning rate to 3.1544814642287643e-06.\n",
      "Epoch 500/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998    \n",
      "Epoch 500: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 9.8927 - val_accuracy: 0.9719 - lr: 3.1545e-06\n",
      "\n",
      "Epoch 501: LearningRateScheduler setting learning rate to 3.1512470486230457e-06.\n",
      "Epoch 501/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.1433e-06 - accuracy: 1.0000\n",
      "Epoch 501: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 262ms/step - loss: 5.1433e-06 - accuracy: 1.0000 - val_loss: 11.4816 - val_accuracy: 0.9705 - lr: 3.1512e-06\n",
      "\n",
      "Epoch 502: LearningRateScheduler setting learning rate to 3.1480159493925954e-06.\n",
      "Epoch 502/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 9.1823e-07 - accuracy: 1.0000\n",
      "Epoch 502: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 9.1823e-07 - accuracy: 1.0000 - val_loss: 13.9771 - val_accuracy: 0.9740 - lr: 3.1480e-06\n",
      "\n",
      "Epoch 503: LearningRateScheduler setting learning rate to 3.1447881631370007e-06.\n",
      "Epoch 503/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 8.8398e-04 - accuracy: 0.9995\n",
      "Epoch 503: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 36s 261ms/step - loss: 8.8398e-04 - accuracy: 0.9995 - val_loss: 14.6445 - val_accuracy: 0.9698 - lr: 3.1448e-06\n",
      "\n",
      "Epoch 504: LearningRateScheduler setting learning rate to 3.141563686459337e-06.\n",
      "Epoch 504/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9998    \n",
      "Epoch 504: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 263ms/step - loss: 0.0197 - accuracy: 0.9998 - val_loss: 4.8735 - val_accuracy: 0.9698 - lr: 3.1416e-06\n",
      "\n",
      "Epoch 505: LearningRateScheduler setting learning rate to 3.138342515966161e-06.\n",
      "Epoch 505/1000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5.1402e-06 - accuracy: 1.0000\n",
      "Epoch 505: val_accuracy did not improve from 0.97965\n",
      "134/134 [==============================] - 37s 265ms/step - loss: 5.1402e-06 - accuracy: 1.0000 - val_loss: 14.8602 - val_accuracy: 0.9670 - lr: 3.1383e-06\n",
      "Epoch 505: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model_history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=1000,\n",
    "        callbacks=[\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                model.name + '.keras',\n",
    "                monitor='val_accuracy',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode='auto',\n",
    "                save_freq=\"epoch\",\n",
    "            ),\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                min_delta=0,\n",
    "                patience=200,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            keras.callbacks.LearningRateScheduler(\n",
    "                learning_rate_schedule,\n",
    "                verbose=1,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Save history\n",
    "    dataframe = pd.DataFrame(model_history.history)\n",
    "    dataframe.to_csv(\"history.csv\", index_label=\"model_name\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d099da",
   "metadata": {
    "papermill": {
     "duration": 6.078568,
     "end_time": "2024-06-08T21:01:34.430145",
     "exception": false,
     "start_time": "2024-06-08T21:01:28.351577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testando o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da42f8c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T21:01:47.148085Z",
     "iopub.status.busy": "2024-06-08T21:01:47.147679Z",
     "iopub.status.idle": "2024-06-08T21:02:17.791825Z",
     "shell.execute_reply": "2024-06-08T21:02:17.790753Z"
    },
    "papermill": {
     "duration": 37.135066,
     "end_time": "2024-06-08T21:02:17.794146",
     "exception": false,
     "start_time": "2024-06-08T21:01:40.659080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      COVID19       0.97      0.96      0.97       116\n",
      "       NORMAL       0.95      0.95      0.95       318\n",
      "    PNEUMONIA       0.98      0.98      0.98       856\n",
      "TURBERCULOSIS       0.98      0.99      0.98       140\n",
      "\n",
      "     accuracy                           0.97      1430\n",
      "    macro avg       0.97      0.97      0.97      1430\n",
      " weighted avg       0.97      0.97      0.97      1430\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = keras.saving.load_model(\"model.keras\")\n",
    "y_true, y_pred = get_true_and_predicted_labels(model, test_dataset)\n",
    "\n",
    "model_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Saving confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true, y_pred,\n",
    "    display_labels=classes\n",
    ")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "plot_model_history(model_history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1592399,
     "sourceId": 2619910,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18900.284951,
   "end_time": "2024-06-08T21:02:27.268131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-08T15:47:26.983180",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
